{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALE Framework Tests",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tinynja/Sarsa-phi-EB/blob/main/notebooks/ALE_Framework_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z3aqLItDvig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252ab534-0fa3-4cd8-abe5-cd403cef913b"
      },
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    !rm -rf *\n",
        "    !git clone https://github.com/Tinynja/Sarsa-phi-EB\n",
        "    !mv Sarsa-phi-EB/* .\n",
        "    !rm -rf Sarsa-phi-EB\n",
        "    # DON'T install packages defined in Pipfile_Colab_exclude\n",
        "    !sed -ri \"/$(tr '\\n' '|' < Pipfile_Colab_exclude)/d\" Pipfile\n",
        "else:\n",
        "    print('Skipping GitHub cloning since not running in Colab.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sarsa-phi-EB'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (285/285), done.\u001b[K\n",
            "remote: Total 336 (delta 112), reused 204 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 798.62 KiB | 10.94 MiB/s, done.\n",
            "Resolving deltas: 100% (112/112), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdficWqDDviq",
        "outputId": "b753d8c0-4ab9-4347-af3a-9b68bbdef147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install required dependencies\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Some dependencies required for displaying episode\n",
        "    !apt install -y python-opengl xvfb\n",
        "    !pip install pyvirtualdisplay\n",
        "    # Colab doesn't support pipenv, hence we convert Pipfile into requirements.txt\n",
        "    if 'requirements_Colab.txt' not in os.listdir():\n",
        "        !pip install pipenv\n",
        "        !pipenv lock -r > requirements.txt\n",
        "    !pip install -r requirements_Colab.txt 1> /dev/null\n",
        "else:\n",
        "    !pipenv install 1> /dev/null"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl xvfb\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 1,281 kB of archives.\n",
            "After this operation, 7,686 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.9 [784 kB]\n",
            "Fetched 1,281 kB in 1s (1,404 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.9_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.9) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-2.2-py3-none-any.whl (15 kB)\n",
            "Collecting EasyProcess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "arviz 0.11.4 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.0.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_YFCigY7Dvis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e159d9-bbe8-45d3-911e-5a1b28c39299",
        "collapsed": true
      },
      "source": [
        "# Import all supported ROMs into ALE\n",
        "!ale-import-roms ROMS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUPPORTED]    \u001b[0m       kung_fu_master ROMS/Kung-Fu Master (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       tic_tac_toe_3d ROMS/3-D Tic-Tac-Toe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          road_runner    ROMS/Road Runner (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            ms_pacman    ROMS/Ms. Pac-Man (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           beam_rider      ROMS/Beamrider (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert        ROMS/Q. Bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            atlantis2    ROMS/Atlantis II (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             trondead ROMS/TRON - Deadly Discs (TRON Joystick) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             superman       ROMS/Superman (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         flag_capture ROMS/Flag Capture - Capture (Capture the Flag) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            blackjack ROMS/Blackjack - Black Jack (Gambling) (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             seaquest       ROMS/Seaquest (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               skiing ROMS/Skiing - Le Ski (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              turmoil        ROMS/Turmoil (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            tutankham      ROMS/Tutankham (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               casino ROMS/Casino - Poker Plus (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               amidar         ROMS/Amidar (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         darkchambers ROMS/Dark Chambers (Dungeon, Dungeon Masters) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              freeway        ROMS/Freeway (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              venture        ROMS/Venture (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             carnival       ROMS/Carnival (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             air_raid ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              bowling        ROMS/Bowling (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        crazy_climber  ROMS/Crazy Climber (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           bank_heist ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             breakout ROMS/Breakout - Breakaway IV (Paddle) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              phoenix        ROMS/Phoenix (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       name_this_game ROMS/Name This Game (Guardians of Treasure) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               boxing ROMS/Boxing - La Boxe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pacman        ROMS/Pac-Man (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m    montezuma_revenge ROMS/Montezuma's Revenge - Featuring Panama Joe (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Fun with Numbers (AKA Basic Math) (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          word_zapper ROMS/Word Zapper (Word Grabber) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       space_invaders ROMS/Space Invaders (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          star_gunner     ROMS/Stargunner (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         yars_revenge ROMS/Yars' Revenge (Time Freeze) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           earthworld ROMS/SwordQuest - EarthWorld (Adventure I, SwordQuest I - EarthWorld) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           videochess ROMS/Video Chess (Computer Chess) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              hangman ROMS/Hangman - Spelling (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        fishing_derby  ROMS/Fishing Derby (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            jamesbond ROMS/James Bond 007 (James Bond Agent 007) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       miniature_golf ROMS/Miniature Golf - Arcade Golf (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          battle_zone     ROMS/Battlezone (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              berzerk        ROMS/Berzerk (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         lost_luggage ROMS/Lost Luggage (Airport Mayhem) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               enduro         ROMS/Enduro (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           ice_hockey ROMS/Ice Hockey - Le Hockey Sur Glace (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            up_n_down     ROMS/Up 'n Down (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround - Chase (Blockade) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               zaxxon         ROMS/Zaxxon (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             gravitar       ROMS/Gravitar (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Pinball (AKA Video Pinball) (Zellers).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            asteroids      ROMS/Asteroids (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             robotank ROMS/Robot Tank (Robotank) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            king_kong      ROMS/King Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               kaboom ROMS/Kaboom! (Paddle) (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 klax           ROMS/Klax (1991).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             entombed ROMS/Entombed (Maze Chase, Pharaoh's Tomb, Zombie) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      elevator_action ROMS/Elevator Action (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           time_pilot     ROMS/Time Pilot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             crossbow       ROMS/Crossbow (1988).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          double_dunk ROMS/Double Dunk (Super Basketball) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              solaris ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           mario_bros    ROMS/Mario Bros. (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       journey_escape ROMS/Journey Escape (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                mr_do        ROMS/Mr. Do! (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            frostbite      ROMS/Frostbite (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          private_eye    ROMS/Private Eye (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                   et ROMS/E.T. - The Extra-Terrestrial (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             pitfall2 ROMS/Pitfall II - Lost Caverns (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             galaxian       ROMS/Galaxian (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              assault ROMS/Assault (AKA Sky Alien) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                krull          ROMS/Krull (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m     human_cannonball ROMS/Human Cannonball - Cannon Man (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      keystone_kapers ROMS/Keystone Kapers - Raueber und Gendarm (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              koolaid ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              othello        ROMS/Othello (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        haunted_house ROMS/Haunted House (Mystery Mansion, Graves' Manor, Nightmare Manor) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             atlantis ROMS/Atlantis (Lost City of Atlantis) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       video_checkers ROMS/Video Checkers - Checkers - Atari Video Checkers (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              pitfall ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               tennis ROMS/Tennis - Le Tennis (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          laser_gates ROMS/Laser Gates (AKA Innerspace) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Basic Math - Math (Math Pack) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Video Pinball - Arcade Pinball (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            riverraid     ROMS/River Raid (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              frogger        ROMS/Frogger (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      chopper_command ROMS/Chopper Command (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             kangaroo       ROMS/Kangaroo (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            videocube ROMS/Atari Video Cube (Atari Cube, Video Cube) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            centipede      ROMS/Centipede (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pooyan         ROMS/Pooyan (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 hero       ROMS/H.E.R.O. (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            adventure      ROMS/Adventure (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 pong ROMS/Video Olympics - Pong Sports (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        wizard_of_wor  ROMS/Wizard of Wor (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                alien          ROMS/Alien (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             defender       ROMS/Defender (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           backgammon ROMS/Backgammon (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         sir_lancelot   ROMS/Sir Lancelot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               gopher ROMS/Gopher (Gopher Attack) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         demon_attack ROMS/Demon Attack (Death from Above) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            space_war ROMS/Space War - Space Star (32 in 1) (1988).bin\n",
            "\n",
            "\n",
            "\n",
            "Imported 110 / 110 ROMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SfKRFx8Dvit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a48153-bb31-4d5d-c4a4-459883f023ad"
      },
      "source": [
        "#### ALE-related imports ####\n",
        "\n",
        "# Built-in libraries\n",
        "import re\n",
        "import sys\n",
        "import base64\n",
        "import pickle\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Pypi libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from ale_py import ALEInterface, SDL_SUPPORT\n",
        "import ale_py.roms as ROMS\n",
        "\n",
        "# Episode display\n",
        "from PIL import Image\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "# Configuration\n",
        "CUDA = 'cuda' if torch.cuda.device_count() else 'cpu'\n",
        "CPU = 'cpu'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for external in metadata.entry_points().get(self.group, []):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EnvRecorder:\n",
        "    def __init__(self, env, out_dir='./results'):\n",
        "        self.out_dir = Path(out_dir)\n",
        "        self.out_dir.mkdir(exist_ok=True)\n",
        "        self.out_dir = self.out_dir.resolve()\n",
        "        self.env = env\n",
        "\n",
        "        # Workspace variables\n",
        "        self.__frame_count_padding = 0\n",
        "        self.__timestep = 0\n",
        "    \n",
        "    def __call__(self, choose_action=None, max_steps=-1, height=300):\n",
        "        self.record_episode_and_show(choose_action=choose_action, max_steps=max_steps, height=height)\n",
        "    \n",
        "    def record_episode_and_show(self, choose_action=None, max_steps=-1, height=300):\n",
        "        self.record_episode(choose_action=choose_action, max_steps=max_steps)\n",
        "        self.show_recording(height=height)\n",
        "    \n",
        "    def record_episode(self, choose_action=None, max_steps=-1):\n",
        "        \"\"\"Generate an episode and record it as record.mp4\n",
        "        Args:\n",
        "        choose_action -- callable method that returns the next action based on the current observation\n",
        "        max_steps     -- maximum number of steps after which force end episode\n",
        "        \"\"\"\n",
        "        choose_action = choose_action or (lambda _: self.env.action_space.sample())\n",
        "\n",
        "        self._clear_recording()\n",
        "        self.__timestep, done, observation =  0, False, self.env.reset()\n",
        "        self._record_frame()\n",
        "        while not done and self.__timestep != max_steps:\n",
        "            print(f'\\rRecording episode, timestep {self.__timestep+1}...', end='')\n",
        "            action = choose_action(observation)\n",
        "            observation, _, done, _ = self.env.step(action)\n",
        "            self.__timestep += 1\n",
        "            self._record_frame()\n",
        "\n",
        "        if self.__timestep == max_steps and not done:\n",
        "            print('\\nWarning: `max_steps` reached before episode terminated')\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "        self._export_as_mp4()\n",
        "\n",
        "    def show_recording(self, height=300):\n",
        "        \"\"\"Show a .mp4 video in html format of the recorded episode\"\"\"\n",
        "        filepath = self.out_dir.joinpath('record.mp4')\n",
        "        video_b64 = base64.b64encode(filepath.read_bytes())\n",
        "        html = f'''<video alt=\"{filepath}\" autoplay loop controls style=\"height:{height}px\">\n",
        "                        <source src=\"data:video/mp4;base64,{video_b64.decode('ascii')}\" type=\"video/mp4\" />\n",
        "                   </video>'''\n",
        "        ipythondisplay.display(ipythondisplay.HTML(data=html))\n",
        "\n",
        "    def _clear_recording(self):\n",
        "        # This is a new episode, delete previously recorded steps\n",
        "        self.out_dir.joinpath('record').mkdir(exist_ok=True)\n",
        "        for step_png in self.out_dir.glob('record/step_*.png'):\n",
        "            step_png.unlink()\n",
        "        if self.out_dir.joinpath('record.mp4').exists():\n",
        "            self.out_dir.joinpath('record.mp4').unlink()\n",
        "    \n",
        "    def _record_frame(self):\n",
        "        # Record current timestep png\n",
        "        img = Image.fromarray(env.render('rgb_array'))\n",
        "        out_path = self.out_dir.joinpath(f'record/step_{self.__timestep}.png')\n",
        "        img.save(str(out_path))\n",
        "\n",
        "    def _export_as_mp4(self):\n",
        "        \"\"\"Convert the recorded set of png files into an mp4 video\"\"\"\n",
        "        self._standardize_frame_count_padding()\n",
        "        in_dir = self.out_dir.joinpath('record')\n",
        "        in_pattern = f'step_%0{self.__frame_count_padding}d.png'\n",
        "        out_file = self.out_dir.joinpath('record.mp4')\n",
        "        !cd $in_dir; ffmpeg -hide_banner -loglevel error -r 60 -i $in_pattern -vcodec libx264 -crf 25 -pix_fmt yuv420p -y $out_file\n",
        "    \n",
        "    def _standardize_frame_count_padding(self):\n",
        "        self.__frame_count_padding = len(str(self.__timestep))\n",
        "        number_pattern = re.compile('\\d+')\n",
        "        png_abs_glob = 'step_*.png'\n",
        "        for png_path in self.out_dir.joinpath('record').glob(png_abs_glob):\n",
        "            ts = int(number_pattern.search(png_path.stem).group(0))\n",
        "            new_name = png_path.parent.joinpath(f'step_{ts:0{self.__frame_count_padding}d}.png')\n",
        "            png_path.rename(new_name)"
      ],
      "metadata": {
        "id": "ZFF_G0wToLuO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs6_UzuKGjz"
      },
      "source": [
        "class features:\n",
        "    @staticmethod\n",
        "    def basic(frame, palette, background, crop_size=torch.Tensor([15,10]), flatten=True):\n",
        "        # For each color in palette, tell if each pixel is that color (e.g. 210,160,128)\n",
        "        colors_in_pixels = ((frame-background).unsqueeze(-2) == palette).all(-1)\n",
        "        # Split the image into n tiles, each with dimension `crop_size` (e.g. 14,16,15,10,128)\n",
        "        cropped_colors_in_pixels = torch.stack(torch.stack(colors_in_pixels.split(crop_size[1],dim=-2)).split(crop_size[0],dim=-3))\n",
        "        # Apply logical or inside each cropped image (e.g. 14,16,128)\n",
        "        cropped_features = cropped_colors_in_pixels.any(3).any(2)\n",
        "        # Flatten the features (e.g. 28672)\n",
        "        return cropped_features.flatten() if flatten else cropped_features\n",
        "    \n",
        "    @staticmethod\n",
        "    def b_pros(frame, palette, background, crop_size=torch.Tensor([15,10])):\n",
        "        raise NotImplementedError()\n",
        "        basic_features = features.basic(frame, palette, background, crop_size=crop_size)\n",
        "        b_pros_features = torch.combinations(basic_features)\n",
        "        return b_pros_features"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0fNQ7lIlEdl"
      },
      "source": [
        "from gym.spaces import Discrete\n",
        "\n",
        "class EnvALE:\n",
        "    def __init__(self, rom, out_dir='results', seed=0, feature_type='ScreenRGB',\n",
        "                 regen_bg=False, bg_samples=18000, device=CUDA):\n",
        "        self.rom = rom\n",
        "        self.rom_name = rom.stem\n",
        "        self.feature_type = feature_type\n",
        "        self.device = device\n",
        "\n",
        "        self.out_dir = Path(out_dir)\n",
        "        self.out_dir.mkdir(exist_ok=True)\n",
        "        self.out_dir = self.out_dir.resolve()\n",
        "\n",
        "        # ALE\n",
        "        self.ale = ALEInterface()\n",
        "        self.ale.setInt(\"random_seed\", seed)\n",
        "        self.ale.loadROM(rom)\n",
        "\n",
        "        # gym action_space compatibility\n",
        "        action_set = self.ale.getMinimalActionSet()\n",
        "        self.action_space = Discrete(len(action_set))\n",
        "        self.action_space.action_set = action_set\n",
        "\n",
        "        # color palette\n",
        "        self.color_palette = self._get_color_palette().to(self.device)\n",
        "\n",
        "        self._bg_path = Path(f'./backgrounds/{self.rom_name}.pickle')\n",
        "        if regen_bg or not self._bg_path.exists() or not self._bg_path.is_file():\n",
        "            self.background = self._get_background(n_samples=bg_samples)\n",
        "        else:\n",
        "            with open(self._bg_path, 'rb') as file:\n",
        "                self.background = pickle.load(file).to(self.device)\n",
        "        \n",
        "        self._set_observe_method(feature_type)\n",
        "        self.observation_space = self._observe().shape\n",
        "\n",
        "        # Default values\n",
        "        self._timestep = 0\n",
        "        self._do_record = False\n",
        "        self._record_padding = None\n",
        "\n",
        "    def reset(self, do_record=False):\n",
        "        self.ale.reset_game()\n",
        "        observation = self._observe()\n",
        "        self._timestep = 0\n",
        "        return observation\n",
        "        \n",
        "    def step(self, action, repeat=1):\n",
        "        if not isinstance(repeat, int) or repeat <= 0: raise ValueError(f'`repeat` must be an integer greater than 0 (got `{repeat}`)')\n",
        "\n",
        "        if isinstance(action, int):\n",
        "            action = self.action_space.action_set[action]\n",
        "\n",
        "        done, sub_timestep, reward = False, 0, 0\n",
        "        while sub_timestep < repeat and not done:\n",
        "            reward += self.ale.act(action)\n",
        "            self._timestep += 1\n",
        "            sub_timestep += 1\n",
        "            done = self.ale.game_over()\n",
        "        observation = self._observe()\n",
        "                \n",
        "        return observation, reward, done, None\n",
        "\n",
        "    def render(self, mode='rgb_array'):\n",
        "        if mode == 'rgb_array':\n",
        "            return self.ale.getScreenRGB()\n",
        "        else:\n",
        "            raise ValueError(f'render mode `{mode}` is not supported')\n",
        "\n",
        "    def _set_observe_method(self, feature_type):\n",
        "        if feature_type == 'ScreenRGB':\n",
        "            self._observe = lambda: torch.from_numpy(self.ale.getScreenRGB()).to(self.device)\n",
        "        elif feature_type == 'ScreenGrayscale':\n",
        "            self._observe = lambda: torch.from_numpy(self.ale.getScreenGrayscale()).to(self.device)\n",
        "        elif feature_type == 'Basic':\n",
        "            self._observe = lambda: features.basic(frame=torch.from_numpy(self.ale.getScreenRGB()).to(self.device),\n",
        "                                                   palette=self.color_palette,\n",
        "                                                   background=self.background)\n",
        "        elif feature_type == 'B-PROS':\n",
        "            self._observe = lambda: features.b_pros(frame=torch.from_numpy(self.ale.getScreenRGB()).to(self.device),\n",
        "                                                    palette=self.color_palette,\n",
        "                                                    background=self.background)\n",
        "        else:\n",
        "            raise NotImplementedError(f'Feature type `{feature_type}` is not supported')\n",
        "        \n",
        "    def _observe(self):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def _get_color_palette(self):\n",
        "        result = subprocess.run(['python', '-c', f'__import__(\"ale_py\").ALEInterface().loadROM(\"{str(self.rom)}\")'], capture_output=True)\n",
        "        palette_name = result.stderr.decode().splitlines()[6].strip().split()[-1]\n",
        "        with open(f'palettes/{palette_name}_Palette.pickle', 'rb') as file:\n",
        "            palette = pickle.load(file)\n",
        "        return palette\n",
        "    \n",
        "    def _get_background(self, n_samples):\n",
        "        bg_feature_type = 'ScreenRGB' if self.feature_type not in ['ScreenGrayscale',] else 'ScreenGrayscale'\n",
        "        self._set_observe_method(bg_feature_type)\n",
        "        \n",
        "        sample_i = 0\n",
        "        pixel_histogram = torch.zeros((*self.ale.getScreenDims(), self.color_palette.shape[0]), dtype=int).to(self.device)\n",
        "        while sample_i < n_samples:\n",
        "            done, observation = False, self.reset()\n",
        "            while not done and sample_i < n_samples:\n",
        "                if not sample_i%10:\n",
        "                    print(f'\\rGenerating background... {sample_i}/{n_samples} samples ({sample_i/n_samples:.0%})', end='')\n",
        "                action = random.choice(self.action_space)\n",
        "                observation, reward, done, info = self.step(action)\n",
        "                observation = torch.from_numpy(observation).to(self.device)\n",
        "                colors_in_pixels = (observation.unsqueeze(-2) == self.color_palette).all(-1)\n",
        "                # for i in range(colors_in_pixels.shape[-1]):\n",
        "                #     print(colors_in_pixels.reshape(-1, 128))\n",
        "                pixel_histogram += colors_in_pixels\n",
        "                sample_i += 1\n",
        "        background_ids = pixel_histogram.argmax(axis=-1)\n",
        "        background = self.color_palette[background_ids]\n",
        "        \n",
        "        self._bg_path.parent.mkdir(exist_ok=True)\n",
        "        with open(self._bg_path, 'wb') as file:\n",
        "            pickle.dump(background.cpu(), file)\n",
        "        \n",
        "        return background"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped background regeneration.\"):\n",
        "# if True:\n",
        "\n",
        "    from ale_py.roms import *\n",
        "    games_to_generate_bg = [Breakout, MontezumaRevenge, Venture, Qbert, Frostbite, Freeway]\n",
        "\n",
        "    for game in games_to_generate_bg:\n",
        "        print(game.stem)\n",
        "        env = EnvALE(game, regen_bg=True)\n",
        "        plt.imshow(env.background.cpu().numpy())\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-jjm2aZ9oMGb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped displaying stored backgrounds to reduce ouptuts.\"):\n",
        "# if True:\n",
        "\n",
        "    for filepath in Path('backgrounds').iterdir():\n",
        "        print(f'Background in `{filepath.resolve()}`')\n",
        "        with open(filepath, 'rb') as file:\n",
        "            bg = pickle.load(file)\n",
        "        plt.imshow(bg)\n",
        "        plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DT3TM-u1ISRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh8WdcHh4Z8M",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped manual test.\"):\n",
        "# if True:\n",
        "\n",
        "    env = EnvALE(ROMS.Breakout)\n",
        "    recorder = EnvRecorder(env)\n",
        "    recorder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2017-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "# import matplotlib.pyplot as plt\n",
        "# from math import floor\n",
        "# from tqdm import tqdm\n",
        "\n",
        "\n",
        "# all possible actions\n",
        "ACTIONS = range(4)\n",
        "\n",
        "# discount is always 1.0 in these experiments\n",
        "DISCOUNT = 0.99\n",
        "\n",
        "# use optimistic initial value, so it's ok to set epsilon to 0\n",
        "EPSILON = 0.01\n",
        "\n",
        "# maximum steps per episode\n",
        "STEP_LIMIT = 5000\n",
        "\n",
        "\n",
        "# get action at @position and @velocity based on epsilon greedy policy and @valueFunction  #########################    use our own get_action. modified it, may work as intended\n",
        "def get_action(observation, valueFunction):\n",
        "    if np.random.binomial(1, EPSILON) == 1:\n",
        "        return np.random.choice(ACTIONS)\n",
        "    values = []\n",
        "    for action in ACTIONS:\n",
        "        values.append(valueFunction.value(observation))  \n",
        "    maxi = np.max(values)\n",
        "    bestactions = np.where(values==maxi,1.0,0.0)\n",
        "    for i in range(len(ACTIONS)):\n",
        "      bestactions[i] = bestactions[i]*np.random.uniform()\n",
        "    action = np.argmax(bestactions)\n",
        "    return action\n",
        "\n",
        "\n",
        "\n",
        "# replacing trace update rule\n",
        "# @trace: old trace (will be modified)\n",
        "# @activeTiles: current active tile indices\n",
        "# @lam: lambda\n",
        "# @return: new trace for convenience\n",
        "def replacing_trace(trace, activeTiles, lam):\n",
        "    active = (torch.arange(len(trace)).to(device)[None,...] == activeTiles.flatten()[...,None]).any(0)\n",
        "    trace[active] = 1\n",
        "    trace[~active] *= lam * DISCOUNT\n",
        "    return trace\n",
        "\n",
        "\n",
        "\n",
        "# wrapper class for Sarsa(lambda)\n",
        "class Sarsa:\n",
        "    # In this example I use the tiling software instead of implementing standard tiling by myself\n",
        "    # One important thing is that tiling is only a map from (state, action) to a series of indices\n",
        "    # It doesn't matter whether the indices have meaning, only if this map satisfy some property\n",
        "    # View the following webpage for more information\n",
        "    # http://incompleteideas.net/sutton/tiles/tiles3.html\n",
        "    # @maxSize: the maximum # of indices\n",
        "    #the hashing is a lfa?\n",
        "    def __init__(self, step_size, lam, trace_update=replacing_trace, max_size=28672, initial_weights=0):\n",
        "        self.max_size = max_size\n",
        "        self.trace_update = trace_update\n",
        "        self.lam = lam\n",
        "\n",
        "        # divide step size equally to each tiling\n",
        "        self.step_size = step_size/10\n",
        "\n",
        "        # weight for each tile\n",
        "        if initial_weights == 0:\n",
        "          self.weights =torch.zeros(max_size).to(device) #max size is the number of features?\n",
        "        else:\n",
        "          self.weights = initial_weights.to(device)\n",
        "\n",
        "        # trace for each tile\n",
        "        self.trace = torch.zeros(max_size).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    # estimate the value of given state and action\n",
        "    def value(self, observation):\n",
        "        active_tiles = np.nonzero(observation)\n",
        "        return self.weights[active_tiles].sum()\n",
        "\n",
        "    # learn with given state, action and target\n",
        "    def learn(self, observation, target):\n",
        "        active_tiles = np.nonzero(observation)\n",
        "        estimation = self.weights[active_tiles].sum()\n",
        "        delta = target - estimation\n",
        "        #print('estimation array: ' + str(self.weights[active_tiles]))\n",
        "        # print('estimation: ' + str(self.weights[active_tiles].sum()))\n",
        "        if self.trace_update == replacing_trace:\n",
        "            self.trace_update(self.trace, active_tiles, self.lam)\n",
        "        else:\n",
        "            raise Exception('Unexpected Trace Type')\n",
        "        self.weights += self.step_size * delta * self.trace\n",
        "        # print('delta: ' + str(delta))\n",
        "        # print('weights: ' +  str(self.weights))\n",
        "\n",
        "\n",
        "# play Mountain Car for one episode based on given method `evaluator`\n",
        "# return: total steps in this episode\n",
        "def play(evaluator, env):\n",
        "\n",
        "    action = random.choice(ACTIONS)\n",
        "    steps = 0\n",
        "    while True:\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "        next_action = get_action(next_observation, evaluator)    #########################    use our own get_action  ??? modified it, may work as intented\n",
        "        steps += 1\n",
        "        target = reward + DISCOUNT * evaluator.value(next_observation)          ############# use our own value function ??? modified it, may work as intented\n",
        "        evaluator.learn(observation, target)\n",
        "        observation = next_observation\n",
        "        action = next_action\n",
        "        if done:\n",
        "            break\n",
        "        if steps >= STEP_LIMIT:\n",
        "            print('Step Limit Exceeded!')\n",
        "            break\n",
        "    return steps\n",
        "\n",
        "class BaseAgent:\n",
        "  \"\"\" The base agent class function.\n",
        "  \"\"\"\n",
        "  def __init__(self, nb_features=28672):\n",
        "    #nothing for now\n",
        "    self.gamma = 1\n",
        "    self.features = nb_features\n",
        "    self.rhos = torch.ones(self.features).to(device) #stores the rho_i values\n",
        "\n",
        "\n",
        "  def takeAction(self, t):\n",
        "    phis = [[0,1,0],[0,1,0],[0,1,0],[1,0,1]]\n",
        "    return phis[t]\n",
        "\n",
        "\n",
        "  def updateRho_i(self, counts, t):\n",
        "    M = self.features\n",
        "    self.rhos = (counts+1.5)/(t+1)\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def PHI_EB(self, evaluator, env, beta=0.05, t_end=200):\n",
        "    t = 0\n",
        "    M = self.features #number of features\n",
        "    counts = torch.zeros(M).to(device)\n",
        "    states = torch.zeros(t_end,M).to(device) #stores the previous phis for all timesteps\n",
        "\n",
        "    action = 1 #starting the game for the agent on the first game\n",
        "    old_phi = env._observe()\n",
        "    print('starting iterations')\n",
        "    print('rhos: ' + str(self.rhos))\n",
        "    while t < t_end:\n",
        "    #   print(\"Iteration #{}\".format(t))\n",
        "      #observe phi(s), reward\n",
        "    #   phi, reward, done, info = obs.clone(), 0, False, None\n",
        "      phi, reward, done, info = env.step(action)\n",
        "    #   print(phi.shape)\n",
        "    #   print('--------------------------------------------------------------')\n",
        "    #   print('took action: ', env.action_space[action])\n",
        "      next_action = get_action(phi, evaluator)\n",
        "    #   print('phi: ' + str(phi))\n",
        "      \n",
        "      #compute rho_t(phi) (feature visit-density)\n",
        "      if t > 0:\n",
        "        counts = (phi==states[0:t]).sum(0)\n",
        "        # print(counts)\n",
        "        self.rhos = (counts+0.5)/(t+1)\n",
        "        # print('rhos: ' + str(self.rhos))\n",
        "        rho_t = torch.prod(self.rhos)\n",
        "      else:\n",
        "        rho_t = 0.5**M\n",
        "    #   print('rho_t ' + str(rho_t))\n",
        "      #update all rho_i with observed phi\n",
        "      states[t] = phi\n",
        "      self.updateRho_i(counts, t+1)\n",
        "    #   print('min rho_i_t: ' + str(min(self.rhos)))\n",
        "      \n",
        "      #compute rho_t+1(phi)\n",
        "      new_rho_t = 1\n",
        "      # THIS IS A BOTTLENECK (tested in CPU mode: 74ms -> 178ms)\n",
        "      for i in range(M):\n",
        "        new_rho_t = new_rho_t*self.rhos[i]\n",
        "      if new_rho_t <= 1e-323: #this is to avoid division by zero, might need to be tweaked\n",
        "        new_rho_t = 1e-323\n",
        "    #   print('new_rho_t ' + str(new_rho_t))\n",
        "\n",
        "      #compute Nhat_t(s)\n",
        "      Nhat_t = rho_t*(1-new_rho_t)/(new_rho_t-rho_t)\n",
        "    #   print('Nhat_t: ',   Nhat_t)\n",
        "      if Nhat_t <= 1e-323: #this is to avoid division by zero again, might need to be tweaked\n",
        "        Nhat_t = torch.tensor([1e-323]).to(device)\n",
        "\n",
        "      #compute R(s,a) (empirical reward)\n",
        "      explorationBonus = beta/torch.sqrt(Nhat_t)\n",
        "      if torch.isnan(explorationBonus) or explorationBonus >= 1e3:\n",
        "        explorationBonus = 1e3\n",
        "\n",
        "      reward = reward + explorationBonus\n",
        "    #   print('reward: ',reward)\n",
        "\n",
        "    #   print('state value: ' + str(evaluator.value(phi)))\n",
        "      #pass phi(s) and reward to RL algo to update theta_t\n",
        "      target = reward + self.gamma * evaluator.value(phi)          ############# use our own value function ??? modified it, may work as intented\n",
        "      # THIS IS A BOTTLENECK (tested in CPU mode: 190ms -> 207ms)\n",
        "      evaluator.learn(old_phi, target)\n",
        "\n",
        "      if done:\n",
        "        #break\n",
        "        env.reset()\n",
        "        action = 1\n",
        "        old_phi = env._observe()\n",
        "        print('episode ended on step ', t, 'starting a new one')\n",
        "      else:\n",
        "        old_phi = phi\n",
        "        action = next_action\n",
        "      t += 1\n",
        "      continue\n",
        "\n",
        "\n",
        "    return evaluator.weights\n",
        "\n",
        "# from ale_py.roms import Breakout\n",
        "# import timeit\n",
        "# env = EnvALE(Breakout, feature_type='Basic')\n",
        "# print(env.action_space)\n",
        "# alpha = 0.5\n",
        "# lam = 0.9\n",
        "# #we can upload previous weights as as tensor, or initialize at 0\n",
        "# previous_weights = 0\n",
        "# obs = torch.randint(0,2,(28672,), dtype=bool).to(device)\n",
        "# t_end = 10\n",
        "\n",
        "# evaluator = Sarsa(alpha, lam, replacing_trace, 28672, previous_weights)\n",
        "# agent = BaseAgent()\n",
        "# env.reset(do_record=False)\n",
        "# start_time = timeit.default_timer()\n",
        "# weights = agent.PHI_EB(evaluator, env, beta=0.05, t_end=t_end)\n",
        "# print(f'{1000*(timeit.default_timer()-start_time)/t_end}ms per timestep')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import timeit\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import numpy\n",
        "\n",
        "class SarsaPhiEBAgent:\n",
        "    def __init__(self, env, epsilon=0.01, beta=0.05, init_action=None, step_repeat=4, device=CUDA, debug=False):\n",
        "        \"\"\"An agent using Sarsa(lambda) algorithm with:\n",
        "            - Linear Function Approximation (SGD)\n",
        "            - Replacing Traces\n",
        "            - Exploration-Bonus\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.init_action = init_action\n",
        "        self.epsilon = epsilon\n",
        "        self.beta = beta\n",
        "        self.step_repeat = step_repeat\n",
        "        self.device = device\n",
        "\n",
        "        self.__log = logging.Logger(name=self.__class__.__name__,\n",
        "                                    level=(logging.DEBUG if debug else logging.WARNING))\n",
        "\n",
        "        # TO REWORK\n",
        "        self.evaluator = Sarsa(step_size=0.5, lam=0.9, trace_update=replacing_trace, max_size=28672, initial_weights=0)\n",
        "        self.gamma = 1\n",
        "\n",
        "        # Init some workspace variables\n",
        "        self.weights = torch.zeros(self.env.observation_space.shape).to(self.device)\n",
        "        self._counts = torch.zeros(self.env.observation_space.shape).to(self.device)\n",
        "        self._total_steps = 0\n",
        "        self._done = True\n",
        "    \n",
        "    def _env_reset(self, do_record=False):\n",
        "        observation = self.env.reset(do_record=do_record)\n",
        "        if self.init_action:\n",
        "            observation = self.env.step(self.init_action)\n",
        "        return observation\n",
        "    \n",
        "    def _env_step_continuous(self, action):\n",
        "        if self._done:\n",
        "            self._env_reset()\n",
        "        observation, reward, self._done, info = self.env.step(action, repeat=self.step_repeat)\n",
        "        return observation, reward\n",
        "    \n",
        "    def choose_action(self, phi):\n",
        "        if torch.rand(1) > self.epsilon:\n",
        "            action = self.weights@phi\n",
        "        else:\n",
        "            action = torch.randint(self.env.action_space.n, (1,))\n",
        "        return action.item()\n",
        "    \n",
        "    def visualize_episode(self):\n",
        "        # Play an episode\n",
        "        total_reward, done, phi = 0, False, self._env_reset(do_record=True)\n",
        "        while not done:\n",
        "            old_phi = phi # TODO: REWORK\n",
        "            action = get_action(old_phi, self.evaluator) # TODO: REWORK\n",
        "            phi, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            print(f'\\rTimestep {env._timestep}...', end='')\n",
        "        print('\\n\\r' + f'Total reward: {total_reward}')\n",
        "\n",
        "        # Show episode\n",
        "        self.env.show_video()\n",
        "\n",
        "    def learn(self, n_steps):\n",
        "        phi = self._env_reset()\n",
        "        start_time = timeit.default_timer()\n",
        "        for i in range(n_steps):\n",
        "            # Information display\n",
        "            avg_time = (timeit.default_timer()-start_time)/(i or 1)\n",
        "            print(f'\\rSarsaPhiEB learning iteration {self._total_steps+1}/{self._total_steps-i+n_steps} ({1000*avg_time:.2f}ms/iter, remaining {(n_steps-i)*avg_time:.0f}s)    ', end='')\n",
        "\n",
        "            # Take an action\n",
        "            old_phi = phi.cpu() # TODO: REWORK\n",
        "            action = self.choose_action(old_phi) # TODO: REWORK\n",
        "            phi, reward = self._env_step_continuous(action)\n",
        "            self._total_steps += 1\n",
        "            \n",
        "            # Compute the exploration bonus\n",
        "            phi_occ = torch.cat((self._counts[phi], self._total_steps-self._counts[~phi])).to(self.device)\n",
        "            rho = ((phi_occ+1/2) / (self._total_steps+1)).prod()\n",
        "            rho_prime = ((phi_occ+1+1/2) / (self._total_steps+1+1)).prod()\n",
        "            pseudocount = (rho*(1-rho_prime)) / (rho_prime-rho)\n",
        "            exploration_bonus = self.beta/pseudocount.sqrt()\n",
        "\n",
        "            reward_augmented = reward + exploration_bonus\n",
        "\n",
        "            # RL Algorithm\n",
        "            # TODO: REWORK\n",
        "            target = reward + self.gamma * self.evaluator.value(phi) ############# use our own value function ??? modified it, may work as intented\n",
        "            self.evaluator.learn(old_phi, target)\n",
        "            self.weights = self.evaluator.weights\n",
        "        print(f'\\nTotal elapsed time: {datetime.utcfromtimestamp(timeit.default_timer()-start_time).strftime(\"%H:%M:%S.%f\")}')\n",
        "\n",
        "device = 'cpu'\n",
        "env = EnvALE(ROMS.Breakout, feature_type='Basic', device=CUDA)\n",
        "\n",
        "import gym\n",
        "env = gym.make('CartPole-v1')\n",
        "agent = SarsaPhiEBAgent(env)"
      ],
      "metadata": {
        "id": "mcbOFfQxr5Ut"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get install python-opengl -y\n",
        "\n",
        "# !apt install xvfb -y\n",
        "\n",
        "# !pip install pyvirtualdisplay\n",
        "\n",
        "# !pip install piglet\n",
        "\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "import gym\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "# env = gym.make('CartPole-v0')\n",
        "# env.reset()\n",
        "# img = Image.fromarray(env.render('rgb_array')) # only call this once\n",
        "# img.save('frames/0.png')\n",
        "# for i in range(40):\n",
        "#     # display.display(plt.gcf())\n",
        "#     # display.clear_output(wait=True)\n",
        "#     action = env.action_space.sample()\n",
        "#     env.step(action)\n",
        "#     img = Image.fromarray(env.render('rgb_array')) # just update the data\n",
        "#     img.save(f'frames/{i+1}.png')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "env = gym.make('MountainCar-v0')\n",
        "recorder = EnvRecorder(env)\n",
        "recorder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "b4F2FGf4Uosr",
        "outputId": "6de81869-74a1-49b1-ad32-be75b1f2df24"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording episode, timestep 200...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"/content/results/record.mp4\" autoplay loop controls style=\"height:300px\">\n",
              "                        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                   </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd results/record; ffmpeg -hide_banner -loglevel error -r 60 -i step_%02d.png -vcodec libx264 -crf 25 -pix_fmt yuv420p -y record.mp4"
      ],
      "metadata": {
        "id": "-6vLiHV2m2zA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "env.render('rgb_array').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXsBkgiUc8g0",
        "outputId": "cca56104-a2ae-4fa0-ef32-508b6b55462a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 600, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.visualize_episode()"
      ],
      "metadata": {
        "id": "Hi2HLDz9cgQB",
        "outputId": "3a8ab9c0-ecbc-47c5-b240-9af85ad4bffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-b4dd9ad43f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-7735b85a4078>\u001b[0m in \u001b[0;36mvisualize_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvisualize_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Play an episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mtotal_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_env_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_record\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mold_phi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;31m# TODO: REWORK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-7735b85a4078>\u001b[0m in \u001b[0;36m_env_reset\u001b[0;34m(self, do_record)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_env_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_record\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_record\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_action\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: reset() got an unexpected keyword argument 'do_record'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.learn(99000)\n",
        "agent.visualize_episode()"
      ],
      "metadata": {
        "id": "tg7itS3jcewP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "for i in range(50):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "\n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "OvynJRXKS1an"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}