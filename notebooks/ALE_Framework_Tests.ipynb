{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALE Framework Tests",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tinynja/Sarsa-phi-EB/blob/main/notebooks/ALE_Framework_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z3aqLItDvig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dbaed0-2bf1-4558-aea2-b94e290bc7e8"
      },
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    !rm -rf *\n",
        "    !git clone https://github.com/Tinynja/Sarsa-phi-EB\n",
        "    !mv Sarsa-phi-EB/* .\n",
        "    !rm -rf Sarsa-phi-EB\n",
        "    # DON'T install packages defined in Pipfile_Colab_exclude\n",
        "    !sed -ri \"/$(tr '\\n' '|' < Pipfile_Colab_exclude)/d\" Pipfile\n",
        "else:\n",
        "    print('Skipping GitHub cloning since not running in Colab.')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sarsa-phi-EB'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Counting objects: 100% (340/340), done.\u001b[K\n",
            "remote: Compressing objects: 100% (289/289), done.\u001b[K\n",
            "remote: Total 340 (delta 114), reused 204 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (340/340), 830.78 KiB | 5.58 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdficWqDDviq",
        "outputId": "fdda9da1-838b-4ac2-c1e5-4727f112a8f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Install required dependencies\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Some dependencies required for displaying episode\n",
        "    !apt install -y python-opengl xvfb\n",
        "    !pip install pyvirtualdisplay\n",
        "    # Colab doesn't support pipenv, hence we convert Pipfile into requirements.txt\n",
        "    if 'requirements_Colab.txt' not in os.listdir():\n",
        "        !pip install pipenv\n",
        "        !pipenv lock -r > requirements.txt\n",
        "    !pip install -r requirements_Colab.txt 1> /dev/null\n",
        "else:\n",
        "    !pipenv install 1> /dev/null"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_YFCigY7Dvis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce19bcc6-020a-442c-d73d-48479c158a7b",
        "collapsed": true
      },
      "source": [
        "# Import all supported ROMs into ALE\n",
        "!ale-import-roms ROMS"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m[SUPPORTED]    \u001b[0m       kung_fu_master ROMS/Kung-Fu Master (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       tic_tac_toe_3d ROMS/3-D Tic-Tac-Toe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          road_runner    ROMS/Road Runner (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            ms_pacman    ROMS/Ms. Pac-Man (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           beam_rider      ROMS/Beamrider (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert        ROMS/Q. Bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            atlantis2    ROMS/Atlantis II (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             trondead ROMS/TRON - Deadly Discs (TRON Joystick) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             superman       ROMS/Superman (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         flag_capture ROMS/Flag Capture - Capture (Capture the Flag) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            blackjack ROMS/Blackjack - Black Jack (Gambling) (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             seaquest       ROMS/Seaquest (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               skiing ROMS/Skiing - Le Ski (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              turmoil        ROMS/Turmoil (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            tutankham      ROMS/Tutankham (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               casino ROMS/Casino - Poker Plus (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               amidar         ROMS/Amidar (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         darkchambers ROMS/Dark Chambers (Dungeon, Dungeon Masters) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              freeway        ROMS/Freeway (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              venture        ROMS/Venture (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             carnival       ROMS/Carnival (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             air_raid ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              bowling        ROMS/Bowling (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        crazy_climber  ROMS/Crazy Climber (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           bank_heist ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             breakout ROMS/Breakout - Breakaway IV (Paddle) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              phoenix        ROMS/Phoenix (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       name_this_game ROMS/Name This Game (Guardians of Treasure) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               boxing ROMS/Boxing - La Boxe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pacman        ROMS/Pac-Man (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m    montezuma_revenge ROMS/Montezuma's Revenge - Featuring Panama Joe (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Fun with Numbers (AKA Basic Math) (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          word_zapper ROMS/Word Zapper (Word Grabber) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       space_invaders ROMS/Space Invaders (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          star_gunner     ROMS/Stargunner (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         yars_revenge ROMS/Yars' Revenge (Time Freeze) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           earthworld ROMS/SwordQuest - EarthWorld (Adventure I, SwordQuest I - EarthWorld) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           videochess ROMS/Video Chess (Computer Chess) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              hangman ROMS/Hangman - Spelling (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        fishing_derby  ROMS/Fishing Derby (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            jamesbond ROMS/James Bond 007 (James Bond Agent 007) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       miniature_golf ROMS/Miniature Golf - Arcade Golf (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          battle_zone     ROMS/Battlezone (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              berzerk        ROMS/Berzerk (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         lost_luggage ROMS/Lost Luggage (Airport Mayhem) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               enduro         ROMS/Enduro (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           ice_hockey ROMS/Ice Hockey - Le Hockey Sur Glace (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            up_n_down     ROMS/Up 'n Down (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround - Chase (Blockade) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               zaxxon         ROMS/Zaxxon (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             gravitar       ROMS/Gravitar (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Pinball (AKA Video Pinball) (Zellers).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            asteroids      ROMS/Asteroids (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             robotank ROMS/Robot Tank (Robotank) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            king_kong      ROMS/King Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               kaboom ROMS/Kaboom! (Paddle) (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 klax           ROMS/Klax (1991).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             entombed ROMS/Entombed (Maze Chase, Pharaoh's Tomb, Zombie) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      elevator_action ROMS/Elevator Action (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           time_pilot     ROMS/Time Pilot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             crossbow       ROMS/Crossbow (1988).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          double_dunk ROMS/Double Dunk (Super Basketball) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              solaris ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           mario_bros    ROMS/Mario Bros. (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       journey_escape ROMS/Journey Escape (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                mr_do        ROMS/Mr. Do! (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            frostbite      ROMS/Frostbite (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          private_eye    ROMS/Private Eye (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                   et ROMS/E.T. - The Extra-Terrestrial (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             pitfall2 ROMS/Pitfall II - Lost Caverns (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             galaxian       ROMS/Galaxian (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              assault ROMS/Assault (AKA Sky Alien) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                krull          ROMS/Krull (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m     human_cannonball ROMS/Human Cannonball - Cannon Man (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      keystone_kapers ROMS/Keystone Kapers - Raueber und Gendarm (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              koolaid ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              othello        ROMS/Othello (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        haunted_house ROMS/Haunted House (Mystery Mansion, Graves' Manor, Nightmare Manor) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             atlantis ROMS/Atlantis (Lost City of Atlantis) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       video_checkers ROMS/Video Checkers - Checkers - Atari Video Checkers (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              pitfall ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               tennis ROMS/Tennis - Le Tennis (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          laser_gates ROMS/Laser Gates (AKA Innerspace) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Basic Math - Math (Math Pack) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Video Pinball - Arcade Pinball (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            riverraid     ROMS/River Raid (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              frogger        ROMS/Frogger (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      chopper_command ROMS/Chopper Command (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             kangaroo       ROMS/Kangaroo (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            videocube ROMS/Atari Video Cube (Atari Cube, Video Cube) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            centipede      ROMS/Centipede (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pooyan         ROMS/Pooyan (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 hero       ROMS/H.E.R.O. (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            adventure      ROMS/Adventure (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 pong ROMS/Video Olympics - Pong Sports (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        wizard_of_wor  ROMS/Wizard of Wor (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                alien          ROMS/Alien (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             defender       ROMS/Defender (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           backgammon ROMS/Backgammon (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         sir_lancelot   ROMS/Sir Lancelot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               gopher ROMS/Gopher (Gopher Attack) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         demon_attack ROMS/Demon Attack (Death from Above) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            space_war ROMS/Space War - Space Star (32 in 1) (1988).bin\n",
            "\n",
            "\n",
            "\n",
            "Imported 110 / 110 ROMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SfKRFx8Dvit"
      },
      "source": [
        "#### ALE-related imports ####\n",
        "\n",
        "# Built-in libraries\n",
        "import re\n",
        "import sys\n",
        "import base64\n",
        "import pickle\n",
        "import random\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# Pypi libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from ale_py import ALEInterface, SDL_SUPPORT\n",
        "import ale_py.roms as ROMS\n",
        "\n",
        "# Episode display\n",
        "from PIL import Image\n",
        "from pyvirtualdisplay import Display\n",
        "Display().start()\n",
        "\n",
        "# Configuration\n",
        "CUDA = 'cuda' if torch.cuda.device_count() else 'cpu'\n",
        "CPU = 'cpu'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnvRecorder:\n",
        "    def __init__(self, env, out_dir='./results'):\n",
        "        self.out_dir = Path(out_dir)\n",
        "        self.out_dir.mkdir(exist_ok=True)\n",
        "        self.out_dir = self.out_dir.resolve()\n",
        "        self.env = env\n",
        "\n",
        "        # Workspace variables\n",
        "        self.__frame_count_padding = 0\n",
        "        self.__timestep = 0\n",
        "    \n",
        "    def __call__(self, choose_action=None, max_steps=-1, height=300):\n",
        "        self.record_episode_and_show(choose_action=choose_action, max_steps=max_steps, height=height)\n",
        "    \n",
        "    def record_episode_and_show(self, choose_action=None, max_steps=-1, height=300):\n",
        "        self.record_episode(choose_action=choose_action, max_steps=max_steps)\n",
        "        self.show_recording(height=height)\n",
        "    \n",
        "    def record_episode(self, choose_action=None, max_steps=-1):\n",
        "        \"\"\"Generate an episode and record it as record.mp4\n",
        "        Args:\n",
        "        choose_action -- callable method that returns the next action based on the current observation\n",
        "        max_steps     -- maximum number of steps after which force end episode\n",
        "        \"\"\"\n",
        "        choose_action = choose_action or (lambda _: self.env.action_space.sample())\n",
        "\n",
        "        self._clear_recording()\n",
        "        self.__timestep, done, observation =  0, False, self.env.reset()\n",
        "        self._record_frame()\n",
        "        while not done and self.__timestep != max_steps:\n",
        "            print(f'\\rRecording episode, timestep {self.__timestep+1}...', end='')\n",
        "            action = choose_action(observation)\n",
        "            observation, _, done, _ = self.env.step(action)\n",
        "            self.__timestep += 1\n",
        "            self._record_frame()\n",
        "\n",
        "        if self.__timestep == max_steps and not done:\n",
        "            print('\\nWarning: `max_steps` reached before episode terminated')\n",
        "        else:\n",
        "            print()\n",
        "\n",
        "        self._export_as_mp4()\n",
        "\n",
        "    def show_recording(self, height=300):\n",
        "        \"\"\"Show a .mp4 video in html format of the recorded episode\"\"\"\n",
        "        filepath = self.out_dir.joinpath('record.mp4')\n",
        "        video_b64 = base64.b64encode(filepath.read_bytes())\n",
        "        html = f'''<video alt=\"{filepath}\" autoplay loop controls style=\"height:{height}px\">\n",
        "                        <source src=\"data:video/mp4;base64,{video_b64.decode('ascii')}\" type=\"video/mp4\" />\n",
        "                   </video>'''\n",
        "        ipythondisplay.display(ipythondisplay.HTML(data=html))\n",
        "\n",
        "    def _clear_recording(self):\n",
        "        # This is a new episode, delete previously recorded steps\n",
        "        self.out_dir.joinpath('record').mkdir(exist_ok=True)\n",
        "        for step_png in self.out_dir.glob('record/step_*.png'):\n",
        "            step_png.unlink()\n",
        "        if self.out_dir.joinpath('record.mp4').exists():\n",
        "            self.out_dir.joinpath('record.mp4').unlink()\n",
        "    \n",
        "    def _record_frame(self):\n",
        "        # Record current timestep png\n",
        "        img = Image.fromarray(env.render('rgb_array'))\n",
        "        out_path = self.out_dir.joinpath(f'record/step_{self.__timestep}.png')\n",
        "        img.save(str(out_path))\n",
        "\n",
        "    def _export_as_mp4(self):\n",
        "        \"\"\"Convert the recorded set of png files into an mp4 video\"\"\"\n",
        "        self._standardize_frame_count_padding()\n",
        "        in_dir = self.out_dir.joinpath('record')\n",
        "        in_pattern = f'step_%0{self.__frame_count_padding}d.png'\n",
        "        out_file = self.out_dir.joinpath('record.mp4')\n",
        "        !cd $in_dir; ffmpeg -hide_banner -loglevel error -r 60 -i $in_pattern -vcodec libx264 -crf 25 -pix_fmt yuv420p -y $out_file\n",
        "    \n",
        "    def _standardize_frame_count_padding(self):\n",
        "        self.__frame_count_padding = len(str(self.__timestep))\n",
        "        number_pattern = re.compile('\\d+')\n",
        "        png_abs_glob = 'step_*.png'\n",
        "        for png_path in self.out_dir.joinpath('record').glob(png_abs_glob):\n",
        "            ts = int(number_pattern.search(png_path.stem).group(0))\n",
        "            new_name = png_path.parent.joinpath(f'step_{ts:0{self.__frame_count_padding}d}.png')\n",
        "            png_path.rename(new_name)"
      ],
      "metadata": {
        "id": "ZFF_G0wToLuO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAs6_UzuKGjz"
      },
      "source": [
        "class features:\n",
        "    @staticmethod\n",
        "    def basic(frame, palette, background, crop_size=torch.Tensor([15,10]), flatten=True):\n",
        "        # For each color in palette, tell if each pixel is that color (e.g. 210,160,128)\n",
        "        colors_in_pixels = ((frame-background).unsqueeze(-2) == palette).all(-1)\n",
        "        # Split the image into n tiles, each with dimension `crop_size` (e.g. 14,16,15,10,128)\n",
        "        cropped_colors_in_pixels = torch.stack(torch.stack(colors_in_pixels.split(crop_size[1],dim=-2)).split(crop_size[0],dim=-3))\n",
        "        # Apply logical or inside each cropped image (e.g. 14,16,128)\n",
        "        cropped_features = cropped_colors_in_pixels.any(3).any(2)\n",
        "        # Flatten the features (e.g. 28672)\n",
        "        return cropped_features.flatten() if flatten else cropped_features\n",
        "    \n",
        "    @staticmethod\n",
        "    def b_pros(frame, palette, background, crop_size=torch.Tensor([15,10])):\n",
        "        raise NotImplementedError()\n",
        "        basic_features = features.basic(frame, palette, background, crop_size=crop_size)\n",
        "        b_pros_features = torch.combinations(basic_features)\n",
        "        return b_pros_features"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0fNQ7lIlEdl"
      },
      "source": [
        "from gym.spaces import Discrete, Box\n",
        "\n",
        "class EnvALE:\n",
        "    def __init__(self, rom, out_dir='results', seed=0, feature_type='ScreenRGB',\n",
        "                 regen_bg=False, bg_samples=18000, device=CUDA):\n",
        "        self.rom = rom\n",
        "        self.rom_name = rom.stem\n",
        "        self.feature_type = feature_type\n",
        "        self.device = device\n",
        "\n",
        "        self.out_dir = Path(out_dir)\n",
        "        self.out_dir.mkdir(exist_ok=True)\n",
        "        self.out_dir = self.out_dir.resolve()\n",
        "\n",
        "        # ALE\n",
        "        self.ale = ALEInterface()\n",
        "        self.ale.setInt(\"random_seed\", seed)\n",
        "        self.ale.loadROM(rom)\n",
        "\n",
        "        # gym action_space compatibility\n",
        "        action_set = self.ale.getMinimalActionSet()\n",
        "        self.action_space = Discrete(len(action_set))\n",
        "        self.action_space.action_set = action_set\n",
        "\n",
        "        # color palette\n",
        "        self.color_palette = self._get_color_palette().to(self.device)\n",
        "\n",
        "        self._bg_path = Path(f'./backgrounds/{self.rom_name}.pickle')\n",
        "        if regen_bg or not self._bg_path.exists() or not self._bg_path.is_file():\n",
        "            self.background = self._get_background(n_samples=bg_samples)\n",
        "        else:\n",
        "            with open(self._bg_path, 'rb') as file:\n",
        "                self.background = pickle.load(file).to(self.device)\n",
        "        \n",
        "        self._set_observe_method(feature_type)\n",
        "        self.observation_space = Box(low=0, high=1, shape=self._observe().shape, dtype=bool)\n",
        "\n",
        "        # Default values\n",
        "        self._timestep = 0\n",
        "        self._do_record = False\n",
        "        self._record_padding = None\n",
        "\n",
        "    def reset(self, do_record=False):\n",
        "        self.ale.reset_game()\n",
        "        observation = self._observe()\n",
        "        self._timestep = 0\n",
        "        return observation\n",
        "        \n",
        "    def step(self, action, repeat=1):\n",
        "        if not isinstance(repeat, int) or repeat <= 0: raise ValueError(f'`repeat` must be an integer greater than 0 (got `{repeat}`)')\n",
        "\n",
        "        if isinstance(action, int):\n",
        "            action = self.action_space.action_set[action]\n",
        "\n",
        "        done, sub_timestep, reward = False, 0, 0\n",
        "        while sub_timestep < repeat and not done:\n",
        "            reward += self.ale.act(action)\n",
        "            self._timestep += 1\n",
        "            sub_timestep += 1\n",
        "            done = self.ale.game_over()\n",
        "        observation = self._observe()\n",
        "                \n",
        "        return observation, reward, done, None\n",
        "\n",
        "    def render(self, mode='rgb_array'):\n",
        "        if mode == 'rgb_array':\n",
        "            return self.ale.getScreenRGB()\n",
        "        else:\n",
        "            raise ValueError(f'render mode `{mode}` is not supported')\n",
        "\n",
        "    def _set_observe_method(self, feature_type):\n",
        "        if feature_type == 'ScreenRGB':\n",
        "            self._observe = lambda: torch.from_numpy(self.ale.getScreenRGB()).to(self.device)\n",
        "        elif feature_type == 'ScreenGrayscale':\n",
        "            self._observe = lambda: torch.from_numpy(self.ale.getScreenGrayscale()).to(self.device)\n",
        "        elif feature_type == 'Basic':\n",
        "            self._observe = lambda: features.basic(frame=torch.from_numpy(self.ale.getScreenRGB()).to(self.device),\n",
        "                                                   palette=self.color_palette,\n",
        "                                                   background=self.background)\n",
        "        elif feature_type == 'B-PROS':\n",
        "            self._observe = lambda: features.b_pros(frame=torch.from_numpy(self.ale.getScreenRGB()).to(self.device),\n",
        "                                                    palette=self.color_palette,\n",
        "                                                    background=self.background)\n",
        "        else:\n",
        "            raise NotImplementedError(f'Feature type `{feature_type}` is not supported')\n",
        "        \n",
        "    def _observe(self):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def _get_color_palette(self):\n",
        "        result = subprocess.run(['python', '-c', f'__import__(\"ale_py\").ALEInterface().loadROM(\"{str(self.rom)}\")'], capture_output=True)\n",
        "        palette_name = result.stderr.decode().splitlines()[6].strip().split()[-1]\n",
        "        with open(f'palettes/{palette_name}_Palette.pickle', 'rb') as file:\n",
        "            palette = pickle.load(file)\n",
        "        return palette\n",
        "    \n",
        "    def _get_background(self, n_samples):\n",
        "        bg_feature_type = 'ScreenRGB' if self.feature_type not in ['ScreenGrayscale',] else 'ScreenGrayscale'\n",
        "        self._set_observe_method(bg_feature_type)\n",
        "        \n",
        "        sample_i = 0\n",
        "        pixel_histogram = torch.zeros((*self.ale.getScreenDims(), self.color_palette.shape[0]), dtype=int).to(self.device)\n",
        "        while sample_i < n_samples:\n",
        "            done, observation = False, self.reset()\n",
        "            while not done and sample_i < n_samples:\n",
        "                if not sample_i%10:\n",
        "                    print(f'\\rGenerating background... {sample_i}/{n_samples} samples ({sample_i/n_samples:.0%})', end='')\n",
        "                action = random.choice(self.action_space)\n",
        "                observation, reward, done, info = self.step(action)\n",
        "                observation = torch.from_numpy(observation).to(self.device)\n",
        "                colors_in_pixels = (observation.unsqueeze(-2) == self.color_palette).all(-1)\n",
        "                # for i in range(colors_in_pixels.shape[-1]):\n",
        "                #     print(colors_in_pixels.reshape(-1, 128))\n",
        "                pixel_histogram += colors_in_pixels\n",
        "                sample_i += 1\n",
        "        background_ids = pixel_histogram.argmax(axis=-1)\n",
        "        background = self.color_palette[background_ids]\n",
        "        \n",
        "        self._bg_path.parent.mkdir(exist_ok=True)\n",
        "        with open(self._bg_path, 'wb') as file:\n",
        "            pickle.dump(background.cpu(), file)\n",
        "        \n",
        "        return background"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped background regeneration.\"):\n",
        "# if True:\n",
        "\n",
        "    from ale_py.roms import *\n",
        "    games_to_generate_bg = [Breakout, MontezumaRevenge, Venture, Qbert, Frostbite, Freeway]\n",
        "\n",
        "    for game in games_to_generate_bg:\n",
        "        print(game.stem)\n",
        "        env = EnvALE(game, regen_bg=True)\n",
        "        plt.imshow(env.background.cpu().numpy())\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "-jjm2aZ9oMGb",
        "cellView": "form",
        "outputId": "41862f9f-e49f-4cae-e690-0ab5a319f5c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped background regeneration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped displaying stored backgrounds to reduce ouptuts.\"):\n",
        "# if True:\n",
        "\n",
        "    for filepath in Path('backgrounds').iterdir():\n",
        "        print(f'Background in `{filepath.resolve()}`')\n",
        "        with open(filepath, 'rb') as file:\n",
        "            bg = pickle.load(file)\n",
        "        plt.imshow(bg)\n",
        "        plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DT3TM-u1ISRJ",
        "outputId": "8b6b764a-6a7e-4c50-93f9-572edd4e642b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped displaying stored backgrounds to reduce ouptuts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh8WdcHh4Z8M",
        "cellView": "form",
        "outputId": "abe6067d-5b85-44d5-af83-ffd7c82b7fc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title\n",
        "\n",
        "if print(\"Skipped manual test.\"):\n",
        "# if True:\n",
        "\n",
        "    env = EnvALE(ROMS.Breakout)\n",
        "    recorder = EnvRecorder(env)\n",
        "    recorder()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipped manual test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SarsaPhiEBAgent:\n",
        "    def __init__(self, env, alpha=0.5, gamma=0.99, lam=0.9, beta=0.05, init_action=None, step_repeat_count=1, device=CUDA, debug=False):\n",
        "        \"\"\"An agent using Sarsa(lambda) algorithm with:\n",
        "            - Linear Function Approximation (SGD)\n",
        "            - Replacing Traces\n",
        "            - Exploration-Bonus\n",
        "        \n",
        "        Args:\n",
        "                      env -- gym-like environment\n",
        "                    alpha -- step size\n",
        "                    gamma -- discount factor\n",
        "                      lam -- trace decay\n",
        "                     beta -- exploration bonus parameter\n",
        "              init_action -- action to take after an environment reset\n",
        "        step_repeat_count -- numer of times to repeat an action every timestep (under-the-hood) \n",
        "                   device -- device on which to store tensors\n",
        "                    debug -- enable debug output\n",
        "        \"\"\"\n",
        "        self.env = env\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.lam = lam\n",
        "        self.beta = beta\n",
        "        self.init_action = init_action\n",
        "        self.step_repeat_count = step_repeat_count\n",
        "        self.device = device\n",
        "\n",
        "        self.__log = logging.Logger(name=self.__class__.__name__,\n",
        "                                    level=(logging.DEBUG if debug else logging.WARNING))\n",
        "\n",
        "        # Workspace variables\n",
        "        self.feature_space_shape = (self.env.action_space.n, *self.env.observation_space.shape)\n",
        "        self.weights = torch.zeros(self.feature_space_shape).to(self.device)\n",
        "        self._counts = torch.zeros(self.feature_space_shape).to(self.device)\n",
        "        self._total_steps = 0\n",
        "\n",
        "    def learn(self, n_steps):\n",
        "        start_time, done = timeit.default_timer(), True\n",
        "        for i in range(n_steps):\n",
        "            # Information display\n",
        "            avg_time = (timeit.default_timer()-start_time)/(i or 1)\n",
        "            print(f'\\rSarsaPhiEB learning iteration {self._total_steps+1}/{self._total_steps-i+n_steps} ({1000*avg_time:.2f}ms/iter, remaining {(n_steps-i)*avg_time:.0f}s)    ', end='')\n",
        "\n",
        "            # Reset env when episode ends\n",
        "            if done:\n",
        "                next_phi = self.env.reset()\n",
        "                if self.init_action is not None:\n",
        "                    next_phi, _, _, _ = self.env.step(self.init_action)\n",
        "                next_action = self.choose_action(next_phi)\n",
        "                traces = torch.zeros(self.feature_space_shape).to(self.device)\n",
        "\n",
        "            # Advance to next timestep\n",
        "            phi, action = next_phi, next_action\n",
        "            active_features = phi.nonzero()\n",
        "            self._total_steps += 1\n",
        "\n",
        "            # Take an action\n",
        "            next_phi, reward, done, _ = self._step_repeat(action)\n",
        "            next_action = self._choose_action(next_phi)\n",
        "\n",
        "            # Apply exploration bonus\n",
        "            self._counts[action,active_features] += 1\n",
        "            reward += self._calc_exploration_bonus(phi)\n",
        "\n",
        "            # RL Algorithm : Sarsa(lambda) LFA(SGD) Replacing Traces\n",
        "            traces*= self.gamma*self.lam\n",
        "            traces[action,active_features] = phi[active_features]\n",
        "            if not done:\n",
        "                delta = reward + self.gamma*self._action_value(next_phi, next_action) - self._action_value(phi, action)\n",
        "            else:\n",
        "                # In terminal state, all state-action values are 0\n",
        "                delta = reward + 0 - self._action_value(phi, action)\n",
        "            self.weights += self.alpha * delta * traces\n",
        "\n",
        "        print(f'\\nTotal elapsed time: {datetime.utcfromtimestamp(timeit.default_timer()-start_time).strftime(\"%H:%M:%S.%f\")}')\n",
        "    \n",
        "    def _step_repeat(self, action):\n",
        "        for i in range(self.step_repeat_count):\n",
        "            observation, reward, done, info = self.env.step(action)\n",
        "            if done: break\n",
        "        return observation, reward, done, info\n",
        "    \n",
        "    def _action_value(self, phi, action):\n",
        "        return (self.weights[action]@phi).item()\n",
        "    \n",
        "    def _choose_action(self, phi):\n",
        "        return (self.weights@phi).argmax().item()\n",
        "    \n",
        "    def _calc_exploration_bonus(self, phi, action):\n",
        "        # Compute the exploration bonus\n",
        "        phi_occ = torch.cat((self._counts[phi], self._total_steps-self._counts[~phi])).to(self.device)\n",
        "        rho = ((phi_occ+1/2) / (self._total_steps+1)).prod()\n",
        "        rho_prime = ((phi_occ+1+1/2) / (self._total_steps+1+1)).prod()\n",
        "        pseudocount = (rho*(1-rho_prime)) / (rho_prime-rho)\n",
        "        exploration_bonus = self.beta/pseudocount.sqrt()\n",
        "        return exploration_bonus"
      ],
      "metadata": {
        "id": "5kQC-tTUHgFl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "# env = gym.make('CartPole-v1')\n",
        "env = EnvALE(ROMS.Breakout, feature_type='Basic', device=CUDA)\n",
        "agent = SarsaPhiEBAgent(env, init_action=env.action_space.action_set)\n",
        "recorder = EnvRecorder(env)\n",
        "recorder()"
      ],
      "metadata": {
        "id": "ZyjGd3iWHV6H",
        "outputId": "72cc5f8a-65ad-4014-bc1e-0a313965f585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording episode, timestep 510...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"/content/results/record.mp4\" autoplay loop controls style=\"height:300px\">\n",
              "                        <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAP8VtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiByMjg1NCBlOWE1OTAzIC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxNyAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yNS4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAB32WIhAAv//71sXwKaunqiXVOGaYIMAdNAfruTNfrGwYhk+DxpZScsziWQgfGLXjVJKqqRdSxA/2Kz0RBPXyYktQhY888x+iNuwyDcObrmdr7BdpXkDikYGYnVcqmnJSn+cK25yvi5+TukyKs0HO8B/jVIxfbnYV5lTcU8IhcWAnQ1mkqQhqkCDBFlqXLz6LEDAsZzEqOO+sG6x4kBUnSw6ZP+AxRPSK0+3vR1e0s8UvJUb8E820AQrbCysEqvo+dKutcgoL7/S7xC1Szux/R36xbPy1Z/0AAGukyDfPcCsZdGtiV3rAAZpwna5jaA+Z+2n3G4EwAAKKYYk+zWZYtltWsjdA3rpEFeh9TANpZnM/ROs/YUYNd7OSA0bhCkbNFYAZBeUTgcfEBWa3mBFA3bEajkvqLqV1xP0Inw57w5PjEC6bIM4fDwF/3nm9Fr0Sf0WV2hehp0yxjlvjyvFvziQdq9ZXGNz4/QPWo5133xDyEDTpFkbIZ8mieEJOjtfWqhBvMD/uoFgXyMt9bcC38jaqNiuuGzlua+j5xs8FoAUN/zRdl293E9MRrgbv5EZRzMtTP5dYwybY6jSgqkyvLMPjaU0MmeTEvxdsYSXUmjBB2QnVlMldB1l7I495yyDmhAAAAMkGaJGxCv/3hAKJS1ACD7ejiI5OYcByrbOemdMFZYcmFAnxCZj9wXP2vsiE0iCD6UzfAAAAAEEGeQniEfwDzVXf5oiI9pLkAAAAJAZ5hdEf/AKmAAAAADQGeY2pH/wE18p6GwIcAAAAsQZpoSahBaJlMCFf//eEAPxzEQAJinHamo/jSl2Hi51FqrW7IF0UgO/gBwaEAAAARQZ6GRREsI/8Cv5DQP3moz/EAAAAQAZ6ldEf/AT7RkmMhi6J6EQAAABMBnqdqR/8DczVjIYAfKCiREpzQAAAASUGaqkmoQWyZTBRMK//94QA/eoZ4yxqABYJTO3RHq4wigNViz1B6SUDa7Mg1gOsAwt46Ps2pabU/QQVty49Vmy+JkgFN8+TDwYgAAAAUAZ7Jakf/A3M1YhzMNh5WqqTuXG0AAAAZQZrMSeEKUmUwUsJ//IQA91vZtSDnhLoTyAAAABUBnutqR/8DczViHUELavfXdJmBG0gAAAAlQZrtSeEOiZTAhX/94QA/fo4L62LK6YAn+MY6PyXbdHOlsQyT4QAAAB9Bmw5J4Q8mUwIV//3hADHj4UoxD5Pc6v5hCTjrzFZBAAAAH0GbMEnhDyZTBRE8K//94QAyAJZu4sHvTjT6G1ueGUEAAAATAZ9Pakf/ArAc5Yf2+eelN7NcwAAAABxBm1JJ4Q8mUwU8K//94QAx4vokDDhRtVsYahRaAAAAEgGfcWpH/wKxz4AQopG/s+q8QQAAACJBm3RJ4Q8mUwU8K//94QAx4vokDDjTR+6wAvwmu8RCtvrgAAAAEQGfk2pH/wKxz4AQsDwf/HfgAAAAJ0GblknhDyZTBTwv//3xAB7rukTaPDGaA1nNrSisq9p6c/ZwQxtjgQAAABUBn7VqR/8Csc9/h2ivXOubFIuZ86AAAAAgQZu6SeEPJlMCFf/94QAyPoxBQ5A7alxx+DeG7AvJCtsAAAAXQZ/YRRE8I/8CFtzjNoJgWj3UmO8Tl98AAAAZAZ/3dEf/ArG4j4FMABm3vhh2U2Zja8GOaAAAABMBn/lqR/8Cn89/+I10lCs8NurRAAAAHkGb/EmoQWiZTBTwv/3xAB47ukVN4uJhsH0JYGY0QAAAABQBnhtqR/8Cn89/58OL0itEYwOM0QAAACBBmgBJ4QpSZTAhX/3hADD7/tkS018H/dajWeS8HTavgQAAABVBnj5FNEwj/wIG5+5m0Rliu0TMSsQAAAAZAZ5ddEf/Ap/A0Dh6UAPp/tYTll9MisGOaAAAABkBnl9qR/8B+iEuA4QAP90+nxxTZRYiwyOBAAAAJkGaQkmoQWiZTBTwr/3hACWa+iQMy8nucNqnjoA0KNgdojdMtEFAAAAAFAGeYWpH/wH5mWWIHFlVplO6rhBhAAAAHUGaZEnhClJlMFLC//3xABfHxRHOpbhZ4P4YjJZQAAAAEAGeg2pH/wH7N9Ag3J59DUkAAAAeQZqISeEOiZTAhX/94QAl3unD50UHH5yVJcCSybE1AAAAFkGepkUVPCP/AZmfdWK+xHeN8a4s+0MAAAAXAZ7FdEf/AfyJE5CAB/Ye0wOd9SuUVo0AAAAYAZ7Hakf/Aft5AselAD48W9Dv8Q87dYZnAAAAHkGaykmoQWiZTBTwr/3hACSa+iQIoJUNSeSGWexzQAAAABIBnulqR/8B8DfQBrBrcYG1T3EAAAAsQZrsSeEKUmUwUsL//fEAFzfFEczxcpVC8KgDkRFGxSjY6TuE5Kbo9pSqj3YAAAAVAZ8Lakf/AfA3z/jA46u0H19ulaX0AAAAH0GbEEnhDomUwIV//eEAJN0TbGehyINK7BDhsePNKO8AAAAVQZ8uRRU8I/8Bj+Jz4sSKjSdOdjJxAAAAGQGfTXRH/wHwLYxE8YADPD91urJGbM9U8xkAAAAXAZ9Pakf/AYaNLgOEAD/dPp9QUOxVjdgAAAAVQZtSSahBaJlMFPCv/eEAHDp2cYPRAAAADQGfcWpH/wGGBWWH80EAAAAdQZt0SeEKUmUwUsL//fEAEc4pEdAJF1Cni6PaxqAAAAASAZ+Takf/AYeasRJ7qKVB7mdgAAAAJUGbmEnhDomUwIV//eEAHG3/UzQ5ERALkfOhVDC0U/KxLMIqmX8AAAAXQZ+2RRU8I/8BNUO9Yr7TMiZBWVYB2BkAAAAZAZ/VdEf/AYifOvWAB/Ye0wPf2rfeBSWKVwAAABkBn9dqR/8Bh9HVhjlAD48W9ETMVqbIlpWBAAAAF0Gb2kmoQWiZTBTwr/3hABuRfRIEUEkSAAAADgGf+WpH/wF+dwmOQICBAAAAIUGb/EnhClJlMFLC//3xABFOKRHRrYdiBAJ/0s0kL4KA8QAAABMBnhtqR/8BfncJnpJH2wiz3oRPAAAAIEGaAEnhDomUwIV//eEAG73/bdMCMjpcPIyKQS8D9ubRAAAAE0GePkUVPCP/AS112JhvnrVR96QAAAAXAZ5ddEf/AX19wcYwEbeIAIA/2rqvjaQAAAATAZ5fakf/ASR9csZDAD5dPp8XoQAAABZBmkJJqEFomUwU8L/98QANeWKI501AAAAADAGeYWpH/wElMEgP6QAAAB9BmmRJ4QpSZTBSwv/98QAOdY8wN1YdGMSN2UGe/X5AAAAAEQGeg2pH/wE+zSHOfALIkU2BAAAAKEGaiEnhDomUwIX//fEADnkeUvXTvJph0IAGZspSw4XwCtInvx+1LEEAAAAeQZ6mRRU8I/8A+EnndjtiIOwgBBu3jzUV6AHi9OTBAAAAGAGexXRH/wE9wTlEHD80CgB8Ye0tYosUsQAAAA4BnsdqR/8BJUvNQMnW8AAAADBBmsxJqEFomUwIX//98QAOddL6XzmGmYAE7ZNSrk1428p2+SNSzRR1g0dBzXoLO08AAAAgQZ7qRREsI/8A+CldNcqLenoQiwPrAAFkfzszXdgIVeEAAAAbAZ8JdEf/AT3CoWFfZP0ROADNz6MilFAt07WMAAAAHAGfC2pH/wE+uOSEJpTi1WmiBy/v4AJTw5WtHCMAAAAoQZsQSahBbJlMCF///fEADo7/rMGj4lkwCc65ynslCTusOZhurHU1wQAAABZBny5FFSwj/wD4JGME3TWhZK6+zz1fAAAAEgGfTXRH/wE+wYXJXiSa5LOvJQAAABgBn09qR/8BPhgElEi26Z/k4ALaIJzcsdwAAAAeQZtUSahBbJlMCF///fEADnoNKDanScCD0o5mApAgAAAAEkGfckUVLCP/APgu80iioLrf4QAAAA8Bn5F0R/8BPusFUGJme8kAAAANAZ+Takf/AT4Y0Ck1IAAAABxBm5hJqEFsmUwIX//98QAOjv+uXatekiuPPkkDAAAAEUGftkUVLCP/APi7dOR725DQAAAACQGf1XRH/wCpgQAAABABn9dqR/8BPhTTvSQ3kzWhAAAAGkGb3EmoQWyZTAhf//3xAA4lpqSRxuzu3n5AAAAAEUGf+kUVLCP/APMvEAQB/i29AAAADQGeGXRH/wE1IQNBrwIAAAAPAZ4bakf/ATUkiU9j/nvBAAAAGEGaAEmoQWyZTAhf//3xAA4eGCV+rIu4yQAAAA9Bnj5FFSwj/wDyydykvXgAAAANAZ5ddEf/ATUhA0GvAgAAAAkBnl9qR/8AqYEAAAAaQZpESahBbJlMCF///fEADiIMAvarDeZjV8AAAAAQQZ5iRRUsI/8A8zt35DtDgQAAAAkBnoF0R/8AqYAAAAAPAZ6Dakf/ATUbfSex/z3hAAAANUGaiEmoQWyZTAhf//3XtSgBzzn//GENBQsd8BhscZUUSmfFdLyK7Xr38OIAMkXtV4jKeRENAAAAFkGepkUVLCP/UkwoI2DeRGq8daxVQuEAAAAPAZ7FdEf/AT7rBVBiZnvJAAAAEgGex2pH/1r6ayXfIdSfIWI4UAAAABhBmsxJqEFsmUwIX//98QAOIit+KeZEwRQAAAARQZ7qRRUsI/8A8qnVNY2m9vEAAAAPAZ8JdEf/ATUJGxs7ChAgAAAADgGfC2pH/wE2VisFySt4AAAAGkGbEEmoQWyZTAhf//3xAA4dw0YhaVYtm7MhAAAAEUGfLkUVLCP/APKkYeqCE29xAAAADwGfTXRH/wE17s9DqOC8EQAAAA0Bn09qR/8BNVfAKTbgAAAAHkGbVEmoQWyZTAhX//3hABbOT3ZKDHjtWJGn6XFMkAAAABJBn3JFFSwj/wDyyUrwBg1XtGkAAAAQAZ+RdEf/ATUgxfE38R50DgAAAA8Bn5NqR/8BLeCnr62E2fgAAAArQZuYSahBbJlMCFf//eEAQP+uQARkDd1VvQTAxkNlI4uM7/jJBtDT4NUdOQAAABRBn7ZFFSwj/wLP9Gry5SO7hgEmbQAAABEBn9V0R/8Di4EAhOPZTTWoMQAAABIBn9dqR/8DiHZgMAyfWyYPgYEAAAAgQZvaSahBbJlMFEwr//3hAED11EgRQSHMCJ4/LeRFG3AAAAAVAZ/5akf/A4h2X4WWcHaXvbSYxjuhAAAAHEGb+0nhClJlMCFf/eEAQPd0lEUEhy7faUQ3jcAAAAAeQZofSeEOiZTAhX/94QBBeibYzyEQ/I4hoZkOPFPxAAAAF0GePUURPCP/AtBa/9zZZJNu3pkQFGuhAAAAEQGeXHRH/wOIWxdhrLsOErcGAAAAEgGeXmpH/wLD1CAPuKHHc+rAwAAAACtBmkFJqEFomUwU8K/94QAzIuokDCjk9zkVjTUgAnWEinTF9gjr1j/1fz15AAAAFQGeYGpH/wN2KJ7UQUFhS0/gwQascAAAAB5BmmNJ4QpSZTBSwr/94QAzIuokDB1LIHNmwfnzO/0AAAAQAZ6Cakf/AsPUIA9jKvmOgAAAACdBmoVJ4Q6JlMFEwr/94QA0YuojW7IQQaGgdo4N275JycrQAdnqTvkAAAATAZ6kakf/AteX2wKnfy0v7/5kOQAAAB1BmqdJ4Q8mUwU8K//94QA0Yuoj6hgdwtPk+wHpwQAAABABnsZqR/8C1dQfbR86guVxAAAAHEGayUnhDyZTBTwr//3hADRi6iQIoJG2XENz1KAAAAAQAZ7oakf/AtXUH/iMifu4nAAAABxBmutJ4Q8mUwU8K//94QA0YuokCKCRtlxDc9ShAAAAEgGfCmpH/wLV1B/nw4QxaWLacAAAABxBmw9J4Q8mUwIV//3hADS7/tjPIRD9yKkjeNFAAAAAFEGfLUURPCP/Ajbn7xLQsA8JeE3BAAAAEgGfTHRH/wLVwW1laGH7FuGLgQAAAA8Bn05qR/8CKmRwHgBemBUAAAAbQZtRSahBaJlMFPCv/eEAKKzqJAx23/jie3HCAAAADwGfcGpH/wIqZHAd9jkHYAAAABpBm3NJ4QpSZTBSwr/94QAorOokDHOLKapshQAAAA8Bn5JqR/8CKmRwHgBemBQAAAAfQZuVSeEOiZTBRMK//eEAKczqI1uyEEGkyAZMP3MaBgAAABEBn7RqR/8CO+LbAqmxbHAsqQAAADdBm7hJ4Q8mUwIT//yEAKKimSReHymEBIYqOAADjuPDrOpArjrvI/UAaedZiEh3yBrV1fimqjXAAAAAEkGf1kURPH8CO8DqUWG7y9oR0QAAABIBn/dqR/8COmRwHX5gob5R6dEAAAAsQZv5SahBaJlMCE///IQAoqvVkVGYOehqgiSLxUYXmgDBpOOihwZfhHEGLeAAAAAeQZoaSeEKUmUwIV/94QApzbpKIoJMY0XHDrOdDCkhAAAAJUGaO0nhDomUwIV//eEAKc26SiKFCgB9DM1n/dF2nPNHCi3+ozQAAAAiQZpfSeEPJlMCE//8hACj8cxZyirQ7SHXl/S87Li3nZ5epQAAABVBnn1FETwj/wHCnIJdit2wAnNyC4kAAAAUAZ6cdEf/AjpKbWVqdb+mwYrjYFYAAAAWAZ6eakf/Abp14chABABEH5WtpNEqDwAAABxBmoFJqEFomUwU8J/8hACCedgABWeIPnFZsOTdAAAADAGeoGpH/wG5nYD8+AAAABVBmqNJ4QpSZTBSwj/6WADzqKMSG3EAAAAMAZ7Cakf/AbmdgPz4AAAAF0Gax0nhDomUwIV//eEAIJpIRAWGB3B7AAAAFkGe5UUVPCP/AWn6NWK+xWLdaz0QSnUAAAATAZ8EdEf/AcW2d3CHkyaLYB8/8QAAABkBnwZqR/8BxDswywAP6JI+gOhiKbjeJc+BAAAAHkGbCUmoQWiZTBTwr/3hACCa6iQIoJyvNmE8CgaN8wAAABQBnyhqR/8BxU3anyZ8Gb9IoDpyQAAAABdBmytJ4QpSZTBSwv/98QAU970RzPFw1QAAABQBn0pqR/8BxU3al4EytWjvcYIDoAAAAB5Bm09J4Q6JlMCFf/3hACDclQsUOdK3AMFa9S+z9IwAAAAWQZ9tRRU8I/8BajEJBWojZMvs1GOCJQAAABMBn4x0R/8BxC2LsN1NU6nXd1fRAAAAGAGfjmpH/wFh6hBwgAgAiD8xvIkgRkknZQAAACFBm5FJqEFomUwU8L/98QAP1ddirSzCYZ2vh4qB0hlzHrIAAAATAZ+wakf/AWK5pVtlzeEj36q69AAAABxBm7NJ4QpSZTBSwv/98QAP1ddirS1GlA9An8RNAAAAEQGf0mpH/wFh6hAmSiF64aidAAAALUGb10nhDomUwIX//fEAEFEKGgAaBCpSwnvgFaRkYdXICeSs9yMiefuKKJFFnwAAACFBn/VFFTwj/wEe9roACGdvHmoGpoVnuyH+vttGRGl/HuUAAAARAZ4UdEf/AWwdCLltyido+ZEAAAAUAZ4Wakf/AWbZFLpldFa+PdS7sfkAAAAyQZobSahBaJlMCF///fEAEFSSOYAD9orAEaHrK/GhZdhsnpmZ8dNSmqf1W63HUk+jP+EAAAAhQZ45RREsI/8BGcL98ab4I19Lt/mEALaIk7s+IAuKPOLUAAAAGwGeWHRH/wFqQTMnNwAH9N4GoRSV0GWpKj71hwAAABIBnlpqR/8BZtkRJwI2T4ft6PgAAAAwQZpfSahBbJlMCF///fEAEEpKn3JTc40uaO/QB+W35Lps5O4cT2VkaFF0ovZ9BQklAAAAHkGefUUVLCP/AR2Y7AJ9I/C/V4Ag+wdU3MBXeKb+bQAAABQBnpx0R/8Ba3vHYOz5hVmC9uxgEAAAAA8Bnp5qR/8BT9q/V7b0wsAAAAAhQZqDSahBbJlMCF///fEADz7/rl2rYVb1oyZAXtpJgkrzAAAAEkGeoUUVLCP/AQVu+9pItCJ3CAAAABIBnsB0R/8BT94PXxjcIJmqntUAAAAJAZ7Cakf/AKmAAAAAGEGax0moQWyZTAhf//3xAA7N2Lpdndu4uQAAABRBnuVFFSwj/wEF3zfIxvNOuCh1gQAAABABnwR0R/8BT8KhXZlcd5bRAAAAEQGfBmpH/wFP0MbePpUhGlrBAAAAGUGbC0moQWyZTAhf//3xAA7NsUxFXZdF3BQAAAARQZ8pRRUsI/8A/aIu9lprKIQAAAAPAZ9IdEf/AUfJ9ixZmAYRAAAADwGfSmpH/wFG2r9XtvTFQAAAACJBm09JqEFsmUwIX//98QAjwhA0ALPoR2O16//Qn8UjIkNwAAAAEkGfbUUVLCP/AP4oOqsz10VnVQAAAA8Bn4x0R/8BRsKhX9tZl0EAAAAPAZ+Oakf/AUgyindWunOhAAAAJEGbk0moQWyZTAhf//3xAC7fnEAA4TFQjUqG9V5HmKEaFWd2qAAAABFBn7FFFSwj/wD9sBtn9rKIQAAAAA0Bn9B0R/8BRtyDQa7DAAAAEAGf0mpH/wFP2roJVh2WqEAAAAAuQZvXSahBbJlMCFf//co24/sAFqx//+EJAJlnRwL1Gh9Cv6GYpcBmtV1VbhjyoQAAABJBn/VFFSwj/1JMKCh9+iPiJxsAAAAOAZ4UdEf/AUdv1g81d0AAAAARAZ4Wakf/WvprLeAZ5FB9VcEAAAAoQZobSahBbJlMCE///IQBE+mdQArRBstYO+mPlCKycDxWUMDxL4ZkbQAAABZBnjlFFSwj/wMHPurvRdubldMC2TzgAAAAEAGeWHRH/wPNgQGw/LdQGQ8AAAARAZ5aakf/A8pvoDAciGQq6cAAAAAdQZpdSahBbJlMFEwj//pYAh80ZiPYV8vSirZLspMAAAATAZ58akf/A8pvn/GBZk0JZjNffQAAACRBmn5J4QpSZTAhH/pYAh9CEyihTUOajxO+QE09ceZOiFySCkIAAAAdQZqfSeEOiZTAj//6WAIj0FFU/DEycekWg8Ul+rwAAAAnQZqhSeEPJlMFETwr//3tWcyXAaUXRV/Fps8ygrU5Dpy3Coc7b2HhAAAAFAGewGpH/wL7NWH9zGwuEsBZH4noAAAAIkGaxEnhDyZTAhP//IQA1nzLpJ2HeTscAuHM3yFria5DcdUAAAATQZ7iRRE8fwLyM5tmFIZafDetkgAAABIBnwNqR/8C+zVh/bzaZmYPW4EAAAAVQZsGSahBaJlMFPH/+lgBp8U2JpyRAAAADAGfJWpH/wL7NWHx6QAAABdBmyhJ4QpSZTBSwr/94QA24vojW7MfUwAAABMBn0dqR/8C/O4TkIAH9h7SmsgmAAAAJEGbTEnhDomUwIT//IQA1/lCeMBsRqWru3IgV/cX4e0/yq2LXAAAABlBn2pFFTwj/wJW3OM2b2qdkeRdkCJfBjpRAAAAFQGfiXRH/wL8T4kTXPhDazdZo4+fgAAAABUBn4tqR/8C+54ThTZvMoUHZeer+hgAAAAjQZuOSahBaJlMFPCP+lgBndiGI9hX9TEjsAiUFkW2+lnXp7cAAAASAZ+takf/AufPf+fDi7mcKDkxAAAAHkGbsknhClJlMCEf+lgBoN/xwiG4YW/UX2I9qjOn6QAAABZBn9BFNEwj/wJG6GKZir9ltARoUFXAAAAAGQGf73RH/wLnwW5dlcAEAf7WE6rHMPX4h1MAAAARAZ/xakf/AjNxSgpkIas3Hv0AAAAcQZv2SahBaJlMCFf//eEAKdl50NukvJ/9zbWQaAAAABVBnhRFESwj/wHCU3V6ZAU1RfjeaXgAAAASAZ4zdEf/AjoRwAvxaYXtHdbNAAAAEQGeNWpH/wI6YJAhvsYJD69KAAAAOEGaOEmoQWyZTBRMJ//8hACiqDGhkw3T2b4a4AFSdcysIj4EGbrthEy7vT5dgkcTZA+PalmTscChAAAAGwGeV2pH/wI6YJDLAA/sPaUfxBX4Rpl7L/GBgQAAACJBmllJ4QpSZTAj//pYAULmZITq8Lpim1G20gA53gT0O/icAAAB5GWIggAM//72c3wKa22wlLnnDNMFaAWxC/v4xPDBJCuQIzDsXaAd44reGkApSmfcxP2z3GYsO1vNqtZWjJJhvgbwR9nI9N3fBj4uaihHhk7gW6shZIZjkhr5+1ItxXi5QIYaZ3KjWUU1UG40E4ujEd/iVrviDgwtGLkPz8qHBh3FryvS+NOIm8iKT7fYGhEV/cv9udynZWZUMm7f7mUgCl0svfYfIrMCJNSbUqg5CfdbUu8r5Qykt4OGGW692p4ant1CSrZP6y7Tn3g8aKsTmRBAO9AAGOMwxnZ/dE1nmIfpozR0hyQUnPZmwYnVpoB5LQhw8e8yT0A8dGxoCjU+yfTKvw0t5rdoCBxNmhSc3wmbFjV6r445V2HJH5DAcEhl2PE8cjWhIcU5VrgXdHYtjY6I887RZpd7XjHGHhZVKgI07+53JyLCoea25F72Vw9gd/p1S/vDc0aq2FFFFTatdEUYq8RCBuh+AbSkYSfWyqRtcUvyRsRZygcKUvtyMDtsL9EtsHuk1BdSy4wAaIpUgTfvdHfgJPSQY4cF8Nn+1CLxm/lNNvvaFk84x06pCvm0vnld2cVFvB2HMO1a+tMWAuC7tIVT9gIPuj8q3YuA2qZhchVbPVfxr6kd5NFe5PY3pjBixsMAAAAmQZoibEf/+lgEj0/QFKZoPJjQoaQDkT0tHbMKsdZ335CpCleQJGAAAAAPAZ5BeR//AipgkAiq2e9BAAAALEGaRDwhkymEK//94QAorPokCKCYlXzgAWukV6pH+dvsL+EfvoyXkAKIKcN7AAAAEgGeY2pH/wIqYI/4wO1AuZfluAAAADRBmmhJ4Q8mUwIT//yEAJ9zrFXBgN480hguyAFs7UIc2NsXwlcqbs9oM7vcgAc9UdbFrsyAAAAAGEGehkURPCP/AbgrhIFJcU+NbQPp3jP80QAAABcBnqV0R/8CKkpuXZXABAH+1iWN/muNcAAAABcBnqdqR/8BsHcJyEAD/yLeWlQVbAkwgQAAAB1BmqpJqEFomUwU8J/8hAB5QsyGxVQtUh9A3HAFkAAAABEBnslqR/8BrgVliMaW3wGoawAAAB1BmsxJ4QpSZTBSwj/6WADuKRsSbuSYS8DrGdYYIQAAABABnutqR/8Br5qxEoptql4DAAAAIUGa8EnhDomUwI//+lgA7+/2bXK0IuhMZR73AFiLuNx/AwAAABhBnw5FFTwj/wFYsEMCUSgdzbIt51p8O+AAAAAXAZ8tdEf/AbCfOvWAB/Ye0wPcRZ2eI1gAAAAYAZ8vakf/Aa/PCcPSgB8m/wsE/WoBVcyBAAAAJkGbMkmoQWiZTBTx//pYAOidMxPFDp0u293RrXYfPv5qDFHmYr9AAAAAEwGfUWpH/wGlmrEdil6B710PvZoAAAAiQZtUSeEKUmUwUsI/+lgA6KkbEmqRV+yQKJssbDxYeUzXsQAAABMBn3NqR/8BpZqxF7uwr98egcJVAAAAJEGbeEnhDomUwIV//eEAHn3/bgQZu3mHgwr1TlZGi3qChObgwQAAABlBn5ZFFTwj/wFPM5bRa5b7hZ4iCZftr2EoAAAAHwGftXRH/wGlfhuq6AEJp4eSS5eumtIPuV91nVHS/0AAAAAWAZ+3akf/AWHoe8TA9KAHzkW8sTJBBQAAAC9Bm7pJqEFomUwU8K/94QAaWMEiABO3dZYmBLsCq/VRGLFYbJ5vpyhsG+78k1juEgAAABMBn9lqR/8Bag5u2CBoqYBXRquQAAAAMUGb3EnhClJlMFLC//3xABBRbawgAuoUaOqkGChTCYFo8Y8q4QqvahH796jr/B+nJZEAAAAQAZ/7akf/AWtI2GqETaVfGAAAAB9Bm+BJ4Q6JlMCFf/3hABpiFaZGVD2E1ddH1pG1wz2BAAAAHUGeHkUVPCP/ARyav0uJDZyDPCSsqH8oiiWIOxmBAAAAFwGePXRH/wFsHRrNFjGCgAGbL9yF7gD3AAAAHAGeP2pH/wFr38VWbxVfsEJAABm/KkPk7kiFUWcAAAAeQZoiSahBaJlMFPCv/eEAGmIoDqBtIOnkmkEUPMTcAAAAGgGeQWpH/wFs9TEAIUUB3p8bXyv6IOv/dILBAAAAHkGaREnhClJlMFLCv/3hABpiFaZGU/nSIyaQRQ8xNwAAABIBnmNqR/8BYeh5JMCRlI+RyRAAAAAeQZpnSeEOiZTAhX/94QAXX1svjORwA24RmDA5j8lIAAAADUGehUUVPH8BPiBbofsAAAAOAZ6makf/APJGhcxdGqAAAAAgQZqrSahBaJlMCFf//eEAGmICmlmEV0OY40qPn9JBgXEAAAAQQZ7JRREsI/8BHZe2EPQ8jgAAAA8Bnuh0R/8BavTX2oa/PIEAAAAJAZ7qakf/AKmBAAAALkGa70moQWyZTAhH//pYAMqUtycOACPc6q2S/+rzRpzf/Ji5VFm0KQnW2gQYSIEAAAATQZ8NRRUsI/8BGe9zQCDWZodl4QAAAA0Bnyx0R/8BbB0eSi0gAAAAEAGfLmpH/wFqDjF0ee5suIAAAAAiQZszSahBbJlMCEf/+lgAypTGYhQGBZm30ibZ+yMFldujgQAAABJBn1FFFSwj/wEUwFqx/2BMV6AAAAAMAZ9wdEf/AWHgcwdAAAAADgGfcmpH/wFr4AJ1UHBZAAAAGEGbd0moQWyZTAhX//3hABmxArniA0mtnQAAAA9Bn5VFFSwj/wEVbw9ku6kAAAAPAZ+0dEf/AWLJ9ixZmAOwAAAACQGftmpH/wCpgAAAABFBm7tJqEFsmUwIR//6WABeQQAAAAtBn9lFFSwj/wCDgAAAAAkBn/h0R/8AqYAAAAAJAZ/6akf/AKmBAAAAOEGb/0moQWyZTAhf//37NMB4oRoFYuknAAvrFN8IBPSpXFlZDno9H+Je36K013HSx/dkU53uOU6wAAAAFEGeHUUVLCP/AR4GZtyPN1lfMPhBAAAADQGePHRH/wFi97Yri6kAAAAWAZ4+akf/AWz1MQAhNPDyWXqy/BX+XgAAAF5BmiNJqEFsmUwIV//9wiSAA1lQP4WNjZOaaUc6OZiZwFAbTgNyzD+DDopcEd4ggPPbVvwJOLZBnHd1UVKr3LTc/8CySE53qJ61Rx/wy6dWAK3X2XNHsAfhrF+H3YShAAAAHEGeQUUVLCP/UWwtGRLvhWTz8Y02NPWtuNdbPmoAAAAaAZ5gdEf/Wk3WqGfYSD0oAfF+o+2fzpMNn8EAAAARAZ5iakf/A4h2YA1Yxr+m+qMAAAAgQZplSahBbJlMFEwr//41WRVATBLLTHpGXbX1i7q0FVoAAAAQAZ6Eakf/TovRt04DqO5/wAAAADBBmolJ4QpSZTAhX/3hAEF6JtiokjA3fPSLwWWMAC66Swfg5esr2eEle+04iu+5YVEAAAATQZ6nRTRMI/8C0GISCtChBzF/3wAAABsBnsZ0R/8DiFl3CEKYADOdsIAWohfGRsnqRIEAAAAgAZ7Iakf/AsIT0HYIADPBgc3d2szbHulQA7pHkEYq2dwAAAAfQZrLSahBaJlMFPCv/eEAMyLqJAxpYg5AcsQQxAd5EQAAABABnupqR/8Cw9QgEyia1el5AAAAFkGa7UnhClJlMFLCv/3hADMi6iQLj4EAAAAMAZ8Makf/AsPUIAj5AAAAJkGbD0nhDomUwUTCv/3hADRi6iLgzHaUBvmmBr4WZPY4UjBi8ffCAAAAGAGfLmpH/wLXlgDxCmAAzf3WQw2Ztih/oAAAADZBmzFJ4Q8mUwU8K//94QA0Yuoj6fQepw3TdfwAVF45GP0xQKbQ9sxcQTItm6HXivmblI/ViQMAAAAYAZ9Qakf/AtXUIOEAD+vjEyPMuIFVMh6AAAAAIEGbU0nhDyZTBTwr//3hADRi6iQIoJLJxos6tXIfSUZIAAAAFQGfcmpH/wLV1B/4jb0zSdbSbcNogQAAACtBm3VJ4Q8mUwU8K//94QA0YuokCKCSzMQDiAHxgnANwCgOrDo3jJZa+9nxAAAAFgGflGpH/wLV1B/nw46D0rtzsZL/JdkAAAA8QZuZSeEPJlMCFf/94QA0u/7YzyEQ/3N7IER0AcwhqNsQLPyUU9KCbdFnVD2uRXe0O3hqfJJrZPWCr2tDAAAAGEGft0URPCP/Ajbn7xLRPL/AksruDq2cgAAAABoBn9Z0R/8C1cCV2yyuAB/52EA6OIF8ojQN9QAAABcBn9hqR/8CKPMiPqYAIA6MUssuyClxCAAAABZBm9tJqEFomUwU8K/94QAorOokC72AAAAADAGf+mpH/wIqZHAXCQAAABZBm/1J4QpSZTBSwr/94QAorOokC72AAAAADAGeHGpH/wIqZHAXCQAAABxBmh9J4Q6JlMFEwr/94QApzOoi4Mx2lAb20gJ7AAAAFAGePmpH/wI74QDxCmAAzf3WQleAAAAAGEGaIUnhDyZTBTwn//yEAKKn26U+c+WH8QAAABMBnkBqR/8COmRwywAP6+MTI8lcAAAAHEGaQ0nhDyZTBTwn//yEAKKn26Y0a5gIndtZT/EAAAANAZ5iakf/AjpkcAaqzQAAACVBmmVJ4Q8mUwU8f/pYAUAQRiZMXcCvC+7Qeq2/NqhEnXGIQZVYAAAAEwGehGpH/wI6ZG/4wOPAuJpK0eAAAAAgQZqHSeEPJlMFPCv//eEAKhyfD42oknqB5kpKJpeKNhUAAAATAZ6makf/Ajq70nhBHCKT2J+lMAAAABVBmqlJ4Q8mUwU8J//8hAB73yeblj0AAAANAZ7Iakf/AbiG5zQZ8AAAABtBmstJ4Q8mUwU8J//8hAB73yebpTPCJODQStsAAAARAZ7qakf/AbmdgQ3lE8827A0AAAAbQZrtSeEPJlMFPH/6WADznLsTegkN7AUp8xDBAAAAEgGfDGpH/wG5nYEMBBDTRi1QdQAAAB5Bmw9J4Q8mUwU8K//94QAgmuoi4Mx2c5QGN6m0j7kAAAARAZ8uakf/AcVo0qECLtQ2blAAAAAYQZszSeEPJlMCP//6WAD5F5gyQ5koYR2VAAAAEUGfUUURPCP/AWqv3wYQd8RQAAAADQGfcHRH/wHFhsK/w24AAAAOAZ9yakf/AcVN2p8kzYEAAAAbQZt1SahBaJlMFPCP+lgA+SijEevTM9V+tsPRAAAAEgGflGpH/wHF/wgkiJ81eDjkcQAAACxBm5lJ4QpSZTAhH/pYAPr4v1jAqVtwARkEA2CzyVM119o12Jw/2ljyPkcngAAAABRBn7dFNEwj/wFmi7poVGSvD7mIQAAAABIBn9Z0R/8BxCzFFhpvLqvP4WEAAAAPAZ/Yakf/AcVuVOEy2r/wAAAAK0Gb3UmoQWiZTAj/+lgAxE7hEFutoAOeKJPJV68qaa7tGd1Nhx3ja3LtVmcAAAAfQZ/7RREsI/8BayqoJds4AhfAALA9Lrm1uDV+3tRDUQAAABEBnhp0R/8BxCzy1Xrco7nEwAAAABMBnhxqR/8BxW9Ky+QEs8AtL3HBAAAALUGaHkmoQWyZTAhX//3hABnSnQ/aukAFP1fvCjeQJP6VDXjcQoRE3wrcZVIHIQAAACVBmiBJ4QpSZTBRUsK//eEAIN7FVVumRVPPh882t4bEE8rTG+BAAAAAFQGeX2pH/wHEgt+Lg8FPC/Jav4d0ywAAAClBmkRJ4Q6JlMCEf/pYAMpAFEgBNCeZHs+f7ekJhMduGVtpEgq0Fnr9IAAAAB1BnmJFFTwj/wEeTbz8AEQES0oK8koK9HDG4EMChQAAABQBnoF0R/8BakEy3vxRBlWf3wMVxQAAABABnoNqR/8BYzmQepkSTtlgAAAAKkGaiEmoQWiZTAhf//3xABBf8z5+OzLYShd2TezAAUqV8wwvoz5XRUE+4AAAAB9BnqZFESwj/wEdmPqhUUPXcYQgBYNYai8rscizPFmtAAAADwGexXRH/wFi/Tinu7tfgAAAABMBnsdqR/8BYhfipTu3TXrw0BdPAAAAIUGazEmoQWyZTAhf//3xAA8mGD3+Ifq3npky1p4yaFNjgAAAABFBnupFFSwj/wEFbxZK9vYq4QAAAA0Bnwl0R/8BT9yDQa6rAAAACQGfC2pH/wCpgQAAABFBmxBJqEFsmUwIV//94QAMWQAAAAtBny5FFSwj/wCDgAAAAAkBn010R/8AqYAAAAAJAZ9Pakf/AKmBAAAAIkGbVEmoQWyZTAhX//3hABkQ/kr+cQBx/RViGIZgo9RECCIAAAARQZ9yRRUsI/8BDfV2dnuhXaAAAAAJAZ+RdEf/AKmBAAAADwGfk2pH/wFZzRq7DVsnQQAAABhBm5hJqEFsmUwIR//6WAC/6aL0fBnqZL8AAAAQQZ+2RRUsI/8BDfV55wofgAAAABABn9V0R/8BVS64vHAe+p38AAAADwGf12pH/wFY0VPisb0v8QAAABxBm9xJqEFsmUwI//pYAMTf1c8Zz/9BrtwOIG0gAAAAEkGf+kUVLCP/ARVD60snLp39EAAAABABnhl0R/8BYvQ8yWU87chrAAAADgGeG2pH/wFh6Doae9L1AAAAHEGaHkmoQWyZTBRMK//94QAZ3f34JXtifk5JT/0AAAAOAZ49akf/AWHl6dV70vUAAAAuQZohSeEKUmUwIV/931TkRKiABt7ur83GxsnOFQi7fezCHRS4DXUp8ksliNct4AAAABJBnl9FNEx/WvprPdNjoS//1RMAAAARAZ5gakf/WvprPdWBqa//1RIAAAAdQZpiSahBaJlMCF///fEAD5b/rLvPgdVRNEVXW8EAAAAvQZqGSeEKUmUwIV/94QA/HNaQAba1je/zAQImxl8aauxZQbmfMAkXAwyRcg0+DN8AAAATQZ6kRTRMI/8Cv5DUsG5KlHAwQAAAAA8BnsN0R/8BS+peEGKOFUAAAAAYAZ7Fakf/A3M1YyGAHybRGY1w4oEnrFKBAAAAH0GayEmoQWiZTBTwr/3hAD8U7OMBpdHm6J4/LeRFGFAAAAASAZ7nakf/A3M1Ydr1kVx/6ZFBAAAAH0Ga6knhClJlMFLCv/3hAD8U7OMBpdHkNLePPobEbSQAAAAUAZ8Jakf/A3M1YcJtgNi5qvHw/t0AAAAiQZsOSeEOiZTAhP/8hAD4b/irgwG7wAcVgkdGBr1jM3ZcgQAAABdBnyxFFTwj/wK+YhFC0I5R6fs7G/RnYwAAABsBn0t0R/8DcvcYieMABnYG5ZlrQcpmuuMGc6EAAAAYAZ9Nakf/ArN1OvWAB/45F8Qsd+pkYDqEAAAAHEGbUEmoQWiZTBTwn/yEAMK8+A2Hd65YcschYzwAAAASAZ9vakf/Aq8+HACVMFBLpn1vAAAAG0GbcknhClJlMFLCP/pYAX/YhiRCWLDQndXSgAAAABEBn5FqR/8Csc+AErA8H/xyYAAAACFBm5ZJ4Q6JlMCP//pYAYLf7NrlaB9tnowzKfIQ6quExz0AAAAVQZ+0RRU8I/8CFod6xX2G+KgI3QHhAAAAGwGf03RH/wKvMY7gCAB/SVpUqVvtPCv9sVtFwQAAABMBn9VqR/8CsjAThVNiEC/IrDugAAAAIkGb2EmoQWiZTBTwr/3hADCi+iQIoJMnf5Ew86+xAvS8H4wAAAAVAZ/3akf/Ap/Pf/iOQeSzhTBqD65RAAAAH0Gb+knhClJlMFLC//3xAB47ukVN4uKo9vFXSY1ny7AAAAAUAZ4Zakf/Ap/Pf+fDkEuxM0O2BMAAAAAhQZoeSeEOiZTAhX/94QAw+/7Yz0OQ/8YGBOEyYQtyDnRbAAAAFUGePEUVPCP/Agbn7mbRWHoZloCcvAAAABkBnlt0R/8Cn8FuXZXABACMB5h79QKZlGQ5AAAAEwGeXWpH/wH7N9AkKvVJOSy1Qv0AAAAdQZpASahBaJlMFPCv/eEAJZr6JAz0FBsk/lZ7oagAAAATAZ5/akf/AfmZZYgnmIDUBtPigQAAABxBmmJJ4QpSZTBSwv/98QAXx8URzrtyIY0ad++IAAAAEgGegWpH/wH7N9AjQ3vB8RTWoQAAAB5BmoZJ4Q6JlMCFf/3hACXdE1M0ORCtm5t/JBDhMikAAAAXQZ6kRRU8I/8BmZ91Yr7FGKg5JDjSi6AAAAAZAZ7DdEf/AfmRMNgGAHxJWlSpl5ceVKvZggAAABIBnsVqR/8B+3kCxVsZ1Vu67oEAAAAqQZrISahBaJlMFPCv/eEAJJr6JAignK8GGwBEiYY0TAQOg1I1b9FznBzAAAAAFAGe52pH/wHwN9AGtSkeoyh9nOGBAAAAIEGa6knhClJlMFLC//3xABc3xRHM8XTG21orkMXRYkrAAAAAEwGfCWpH/wHwN8/4wQAYW6Hv06cAAAAeQZsOSeEOiZTAhX/94QAk3RNsZ6HIiElANqX2fnSBAAAAE0GfLEUVPCP/AY/ic+LFsRx80HsAAAAZAZ9LdEf/AfAtjETxgAM7A3LZ8S0x9GUcwQAAAAwBn01qR/8Bh5qw/mgAAAAVQZtQSahBaJlMFPCv/eEAHDp2cYPRAAAADQGfb2pH/wGGBWWH80EAAAAdQZtySeEKUmUwUsL//fEAEc4pEdI6lVAPmdsM/RAAAAASAZ+Rakf/AYeasSOSY6ZQS79gAAAAF0GblknhDomUwIV//eEAHG3/UzQ5EKrdAAAAGEGftEUVPCP/ATVDvWK+3Fju9kYcXvrR4QAAABkBn9N0R/8Bhf0w2AYAfElaVK16n/gU1DVdAAAAEgGf1WpH/wGHzwnC69aK/ML6BAAAAB5Bm9hJqEFomUwU8K/94QAbkX0SDEGHcNkR3ecY00AAAAATAZ/3akf/AX2asStwgjmj+IXn0QAAACRBm/pJ4QpSZTBSwv/98QARTikR04SfXla48NLspg9UQJTRVuAAAAAVAZ4Zakf/AX2asSreh/nzrGGm9XwRAAAAF0GaHknhDomUwIV//eEAG73/bGehyH8vAAAAFUGePEUVPCP/AS12SzH1/ei5SC3aQAAAABkBnlt0R/8BfX5cnUWDMKk2gAgBGA8I1JkRAAAAEAGeXWpH/wFQGOfTZCBOX9EAAAAWQZpASahBaJlMFPCv/eEAFYZ9EgZOgAAAAA0Bnn9qR/8BJCEyxAhhAAAAFkGaYknhClJlMFLC//3xAA15YojnTUAAAAAMAZ6Bakf/ASUwSA/pAAAAK0GahknhDomUwIV//eEAGHFJg59B8Fum64OADggR2pqP4zKkW5XYfnPTziEAAAAgQZ6kRRU8I/8BBeK0dpjb/iNB2EAIN28eaivQBZ5E4BgAAAAZAZ7DdEf/AU/BOUOy4vXTWAGa4Nxryp7sXAAAABMBnsVqR/8BT9FQ0+ZK+67QR86vAAAAL0GaykmoQWiZTAhX//3hABkRIMt/ws+CMABO2MR2ohlPpRNNMzroePod3ASitTNwAAAAIEGe6EURLCP/AQ1NQ1cgfNt1nXG/rAAFzESd2fFM8ciBAAAAGwGfB3RH/wFZyS4j0OvEhrYAM3PoyLnKVLm8jAAAABUBnwlqR/8BWRjjKhhPK85VT6yk2Y0AAAAdQZsOSahBbJlMCEf/+lgAv+nT39D788D8tP8FL+cAAAAVQZ8sRRUsI/8BDd2txJAm3fC4x5UhAAAAEAGfS3RH/wFZ974nMlDB+aMAAAAXAZ9Nakf/AVjbqU9j/w/6vACUlIrT89wAAAAcQZtSSahBbJlMCEf/+lgAxOeHxU4w/8u81J8v0gAAABJBn3BFFSwj/wEVQyNLJy6d/REAAAAPAZ+PdEf/AWJv1B2zSvhEAAAADwGfkWpH/wFiuOSDrYTXqAAAAB9Bm5ZJqEFsmUwIR//6WADE7+woDNYfCZyfof+ctYrBAAAAE0GftEUVLCP/ARYjuj+z58nysU0AAAAQAZ/TdEf/AWHeD17aPNxtSwAAAA8Bn9VqR/8BYs0auw1bI0AAAAAWQZvZSahBbJlMCP/6WADE5uB8CgzTSAAAABBBn/dFFSx/AWM3laokdR1BAAAADgGeGGpH/wFjOftgxVfQAAABu2WIhAAv//71sXwKaunqiXVOGaYIMAdNAfruTNfrGwYhk+DxpZScsziWQgfGLXjVJKqqRdSxA/2Kz0RBPXyYktQhY888x+iNuwyDcObrmdr7BdpXkDikYGYnVcqmnJSn+cK25yvi5+TukyKs0HO8B/coCEMsypvSkS9YcB9Fh648LaUhcOXtZjMhQIQ2JQHIP0GKLKUt9kq8qEpVx3zeTEtZ9Dv3NHdSyj60fDe93gDj0PYSBcNpYzUK7HBgOss/LxGLfAAApblUU4Thj48F17yZ3v48nRVe8U01pvDeb93rP237OngTbJ7pMtsAgS3xQgg6kGc+tylHYnXkgowExmNb1IC51uqCb6nMeRtJ2Qg6Wb/sdQgDqljWbkXyvbBY5RCEQ2rdxNumWo40na29W4fHT2/fMOtfGhH/JcbcOBiJFRMjWVzHDBLT8YJr+HKUVffJI0emeFg8RLCrA/O3yrrzSHxFA8tattLxhVqM4ohcE8Msn2/eB9HnszSsINaJOsCN6izNdFMKJ1Bt8/FalXizXOJPQj3OAaSWwo+F43R+xBUF4ZUHz4+zYEcWhsWScSAVx3lfT9xglHFgAAAAGkGaJGxCP/pYAMUFcoyjlec2gCSj/MhU04+BAAAAD0GeQniEfwEWHMoxxeFfQAAAAAkBnmF0R/8AqYEAAAAOAZ5jakf/AWHl6dV70vUAAAAbQZpnSahBaJlMCE///IQAZPfyIN8vA29xO6jYAAAAEEGehUURLH8BYrncj62E16kAAAAQAZ6makf/AWHaugo1Z1TIQAAAABZBmqtJqEFsmUwI//pYAL/d9WCU5E+zAAAAEUGeyUUVLCP/AQ1LkyYA25+BAAAADwGe6HRH/wFYwTlCW1mRwAAAAA0BnupqR/8BWRjQKTDgAAAawW1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAACFWAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAABnrdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAACFWAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAACgAAAA0gAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAhVgAAAgAAAQAAAAAZY21kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAPAAAAgAAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAGQ5taW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAABjOc3RibAAAAJZzdHNkAAAAAAAAAAEAAACGYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAACgANIASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADBhdmNDAWQADf/hABhnZAANrNlCh34iEAAAAwAQAAAHgPFCmWABAAVo6+csiwAAABhzdHRzAAAAAAAAAAEAAAIAAAABAAAAABxzdHNzAAAAAAAAAAMAAAABAAAA+wAAAfUAAA+4Y3R0cwAAAAAAAAH1AAAAAQAAAgAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAACAAACAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAADAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAIAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAgAAAgAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAIAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAIAAAAAAQAACBRzdHN6AAAAAAAAAAAAAAIAAAAElQAAADYAAAAUAAAADQAAABEAAAAwAAAAFQAAABQAAAAXAAAATQAAABgAAAAdAAAAGQAAACkAAAAjAAAAIwAAABcAAAAgAAAAFgAAACYAAAAVAAAAKwAAABkAAAAkAAAAGwAAAB0AAAAXAAAAIgAAABgAAAAkAAAAGQAAAB0AAAAdAAAAKgAAABgAAAAhAAAAFAAAACIAAAAaAAAAGwAAABwAAAAiAAAAFgAAADAAAAAZAAAAIwAAABkAAAAdAAAAGwAAABkAAAARAAAAIQAAABYAAAApAAAAGwAAAB0AAAAdAAAAGwAAABIAAAAlAAAAFwAAACQAAAAXAAAAGwAAABcAAAAaAAAAEAAAACMAAAAVAAAALAAAACIAAAAcAAAAEgAAADQAAAAkAAAAHwAAACAAAAAsAAAAGgAAABYAAAAcAAAAIgAAABYAAAATAAAAEQAAACAAAAAVAAAADQAAABQAAAAeAAAAFQAAABEAAAATAAAAHAAAABMAAAARAAAADQAAAB4AAAAUAAAADQAAABMAAAA5AAAAGgAAABMAAAAWAAAAHAAAABUAAAATAAAAEgAAAB4AAAAVAAAAEwAAABEAAAAiAAAAFgAAABQAAAATAAAALwAAABgAAAAVAAAAFgAAACQAAAAZAAAAIAAAACIAAAAbAAAAFQAAABYAAAAvAAAAGQAAACIAAAAUAAAAKwAAABcAAAAhAAAAFAAAACAAAAAUAAAAIAAAABYAAAAgAAAAGAAAABYAAAATAAAAHwAAABMAAAAeAAAAEwAAACMAAAAVAAAAOwAAABYAAAAWAAAAMAAAACIAAAApAAAAJgAAABkAAAAYAAAAGgAAACAAAAAQAAAAGQAAABAAAAAbAAAAGgAAABcAAAAdAAAAIgAAABgAAAAbAAAAGAAAACIAAAAaAAAAFwAAABwAAAAlAAAAFwAAACAAAAAVAAAAMQAAACUAAAAVAAAAGAAAADYAAAAlAAAAHwAAABYAAAA0AAAAIgAAABgAAAATAAAAJQAAABYAAAAWAAAADQAAABwAAAAYAAAAFAAAABUAAAAdAAAAFQAAABMAAAATAAAAJgAAABYAAAATAAAAEwAAACgAAAAVAAAAEQAAABQAAAAyAAAAFgAAABIAAAAVAAAALAAAABoAAAAUAAAAFQAAACEAAAAXAAAAKAAAACEAAAArAAAAGAAAACYAAAAXAAAAFgAAABkAAAAQAAAAGwAAABcAAAAoAAAAHQAAABkAAAAZAAAAJwAAABYAAAAiAAAAGgAAAB0AAAAVAAAAIAAAABkAAAAWAAAAFQAAADwAAAAfAAAAJgAAAegAAAAqAAAAEwAAADAAAAAWAAAAOAAAABwAAAAbAAAAGwAAACEAAAAVAAAAIQAAABQAAAAlAAAAHAAAABsAAAAcAAAAKgAAABcAAAAmAAAAFwAAACgAAAAdAAAAIwAAABoAAAAzAAAAFwAAADUAAAAUAAAAIwAAACEAAAAbAAAAIAAAACIAAAAeAAAAIgAAABYAAAAiAAAAEQAAABIAAAAkAAAAFAAAABMAAAANAAAAMgAAABcAAAARAAAAFAAAACYAAAAWAAAAEAAAABIAAAAcAAAAEwAAABMAAAANAAAAFQAAAA8AAAANAAAADQAAADwAAAAYAAAAEQAAABoAAABiAAAAIAAAAB4AAAAVAAAAJAAAABQAAAA0AAAAFwAAAB8AAAAkAAAAIwAAABQAAAAaAAAAEAAAACoAAAAcAAAAOgAAABwAAAAkAAAAGQAAAC8AAAAaAAAAQAAAABwAAAAeAAAAGwAAABoAAAAQAAAAGgAAABAAAAAgAAAAGAAAABwAAAAXAAAAIAAAABEAAAApAAAAFwAAACQAAAAXAAAAGQAAABEAAAAfAAAAFQAAAB8AAAAWAAAAIgAAABUAAAAcAAAAFQAAABEAAAASAAAAHwAAABYAAAAwAAAAGAAAABYAAAATAAAALwAAACMAAAAVAAAAFwAAADEAAAApAAAAGQAAAC0AAAAhAAAAGAAAABQAAAAuAAAAIwAAABMAAAAXAAAAJQAAABUAAAARAAAADQAAABUAAAAPAAAADQAAAA0AAAAmAAAAFQAAAA0AAAATAAAAHAAAABQAAAAUAAAAEwAAACAAAAAWAAAAFAAAABIAAAAgAAAAEgAAADIAAAAWAAAAFQAAACEAAAAzAAAAFwAAABMAAAAcAAAAIwAAABYAAAAjAAAAGAAAACYAAAAbAAAAHwAAABwAAAAgAAAAFgAAAB8AAAAVAAAAJQAAABkAAAAfAAAAFwAAACYAAAAZAAAAIwAAABgAAAAlAAAAGQAAAB0AAAAXAAAAIQAAABcAAAAgAAAAFgAAACIAAAAbAAAAHQAAABYAAAAuAAAAGAAAACQAAAAXAAAAIgAAABcAAAAdAAAAEAAAABkAAAARAAAAIQAAABYAAAAbAAAAHAAAAB0AAAAWAAAAIgAAABcAAAAoAAAAGQAAABsAAAAZAAAAHQAAABQAAAAaAAAAEQAAABoAAAAQAAAALwAAACQAAAAdAAAAFwAAADMAAAAkAAAAHwAAABkAAAAhAAAAGQAAABQAAAAbAAAAIAAAABYAAAATAAAAEwAAACMAAAAXAAAAFAAAABMAAAAaAAAAFAAAABIAAAG/AAAAHgAAABMAAAANAAAAEgAAAB8AAAAUAAAAFAAAABoAAAAVAAAAEwAAABEAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTcuODMuMTAw\" type=\"video/mp4\" />\n",
              "                   </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2017-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "# import matplotlib.pyplot as plt\n",
        "# from math import floor\n",
        "# from tqdm import tqdm\n",
        "\n",
        "\n",
        "# all possible actions\n",
        "ACTIONS = range(4)\n",
        "\n",
        "# discount is always 1.0 in these experiments\n",
        "DISCOUNT = 0.99\n",
        "\n",
        "# use optimistic initial value, so it's ok to set epsilon to 0\n",
        "EPSILON = 0.01\n",
        "\n",
        "# maximum steps per episode\n",
        "STEP_LIMIT = 5000\n",
        "\n",
        "\n",
        "# get action at @position and @velocity based on epsilon greedy policy and @valueFunction  #########################    use our own get_action. modified it, may work as intended\n",
        "def get_action(observation, valueFunction):\n",
        "    if np.random.binomial(1, EPSILON) == 1:\n",
        "        return np.random.choice(ACTIONS)\n",
        "    values = []\n",
        "    for action in ACTIONS:\n",
        "        values.append(valueFunction.value(observation))  \n",
        "    maxi = np.max(values)\n",
        "    bestactions = np.where(values==maxi,1.0,0.0)\n",
        "    for i in range(len(ACTIONS)):\n",
        "      bestactions[i] = bestactions[i]*np.random.uniform()\n",
        "    action = np.argmax(bestactions)\n",
        "    return action\n",
        "\n",
        "\n",
        "\n",
        "# replacing trace update rule\n",
        "# @trace: old trace (will be modified)\n",
        "# @activeTiles: current active tile indices\n",
        "# @lam: lambda\n",
        "# @return: new trace for convenience\n",
        "def replacing_trace(trace, activeTiles, lam):\n",
        "    active = (torch.arange(len(trace)).to(device)[None,...] == activeTiles.flatten()[...,None]).any(0)\n",
        "    trace[active] = 1\n",
        "    trace[~active] *= lam * DISCOUNT\n",
        "    return trace\n",
        "\n",
        "\n",
        "\n",
        "# wrapper class for Sarsa(lambda)\n",
        "class Sarsa:\n",
        "    # In this example I use the tiling software instead of implementing standard tiling by myself\n",
        "    # One important thing is that tiling is only a map from (state, action) to a series of indices\n",
        "    # It doesn't matter whether the indices have meaning, only if this map satisfy some property\n",
        "    # View the following webpage for more information\n",
        "    # http://incompleteideas.net/sutton/tiles/tiles3.html\n",
        "    # @maxSize: the maximum # of indices\n",
        "    #the hashing is a lfa?\n",
        "    def __init__(self, step_size, lam, trace_update=replacing_trace, max_size=28672, initial_weights=0):\n",
        "        self.max_size = max_size\n",
        "        self.trace_update = trace_update\n",
        "        self.lam = lam\n",
        "\n",
        "        # divide step size equally to each tiling\n",
        "        self.step_size = step_size/10\n",
        "\n",
        "        # weight for each tile\n",
        "        if initial_weights == 0:\n",
        "          self.weights =torch.zeros(max_size).to(device) #max size is the number of features?\n",
        "        else:\n",
        "          self.weights = initial_weights.to(device)\n",
        "\n",
        "        # trace for each tile\n",
        "        self.trace = torch.zeros(max_size).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    # estimate the value of given state and action\n",
        "    def value(self, observation):\n",
        "        active_tiles = np.nonzero(observation)\n",
        "        return self.weights[active_tiles].sum()\n",
        "\n",
        "    # learn with given state, action and target\n",
        "    def learn(self, observation, target):\n",
        "        active_tiles = np.nonzero(observation)\n",
        "        estimation = self.weights[active_tiles].sum()\n",
        "        delta = target - estimation\n",
        "        #print('estimation array: ' + str(self.weights[active_tiles]))\n",
        "        # print('estimation: ' + str(self.weights[active_tiles].sum()))\n",
        "        if self.trace_update == replacing_trace:\n",
        "            self.trace_update(self.trace, active_tiles, self.lam)\n",
        "        else:\n",
        "            raise Exception('Unexpected Trace Type')\n",
        "        self.weights += self.step_size * delta * self.trace\n",
        "        # print('delta: ' + str(delta))\n",
        "        # print('weights: ' +  str(self.weights))\n",
        "\n",
        "\n",
        "# play Mountain Car for one episode based on given method `evaluator`\n",
        "# return: total steps in this episode\n",
        "def play(evaluator, env):\n",
        "\n",
        "    action = random.choice(ACTIONS)\n",
        "    steps = 0\n",
        "    while True:\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "        next_action = get_action(next_observation, evaluator)    #########################    use our own get_action  ??? modified it, may work as intented\n",
        "        steps += 1\n",
        "        target = reward + DISCOUNT * evaluator.value(next_observation)          ############# use our own value function ??? modified it, may work as intented\n",
        "        evaluator.learn(observation, target)\n",
        "        observation = next_observation\n",
        "        action = next_action\n",
        "        if done:\n",
        "            break\n",
        "        if steps >= STEP_LIMIT:\n",
        "            print('Step Limit Exceeded!')\n",
        "            break\n",
        "    return steps\n",
        "\n",
        "class BaseAgent:\n",
        "  \"\"\" The base agent class function.\n",
        "  \"\"\"\n",
        "  def __init__(self, nb_features=28672):\n",
        "    #nothing for now\n",
        "    self.gamma = 1\n",
        "    self.features = nb_features\n",
        "    self.rhos = torch.ones(self.features).to(device) #stores the rho_i values\n",
        "\n",
        "\n",
        "  def takeAction(self, t):\n",
        "    phis = [[0,1,0],[0,1,0],[0,1,0],[1,0,1]]\n",
        "    return phis[t]\n",
        "\n",
        "\n",
        "  def updateRho_i(self, counts, t):\n",
        "    M = self.features\n",
        "    self.rhos = (counts+1.5)/(t+1)\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def PHI_EB(self, evaluator, env, beta=0.05, t_end=200):\n",
        "    t = 0\n",
        "    M = self.features #number of features\n",
        "    counts = torch.zeros(M).to(device)\n",
        "    states = torch.zeros(t_end,M).to(device) #stores the previous phis for all timesteps\n",
        "\n",
        "    action = 1 #starting the game for the agent on the first game\n",
        "    old_phi = env._observe()\n",
        "    print('starting iterations')\n",
        "    print('rhos: ' + str(self.rhos))\n",
        "    while t < t_end:\n",
        "    #   print(\"Iteration #{}\".format(t))\n",
        "      #observe phi(s), reward\n",
        "    #   phi, reward, done, info = obs.clone(), 0, False, None\n",
        "      phi, reward, done, info = env.step(action)\n",
        "    #   print(phi.shape)\n",
        "    #   print('--------------------------------------------------------------')\n",
        "    #   print('took action: ', env.action_space[action])\n",
        "      next_action = get_action(phi, evaluator)\n",
        "    #   print('phi: ' + str(phi))\n",
        "      \n",
        "      #compute rho_t(phi) (feature visit-density)\n",
        "      if t > 0:\n",
        "        counts = (phi==states[0:t]).sum(0)\n",
        "        # print(counts)\n",
        "        self.rhos = (counts+0.5)/(t+1)\n",
        "        # print('rhos: ' + str(self.rhos))\n",
        "        rho_t = torch.prod(self.rhos)\n",
        "      else:\n",
        "        rho_t = 0.5**M\n",
        "    #   print('rho_t ' + str(rho_t))\n",
        "      #update all rho_i with observed phi\n",
        "      states[t] = phi\n",
        "      self.updateRho_i(counts, t+1)\n",
        "    #   print('min rho_i_t: ' + str(min(self.rhos)))\n",
        "      \n",
        "      #compute rho_t+1(phi)\n",
        "      new_rho_t = 1\n",
        "      # THIS IS A BOTTLENECK (tested in CPU mode: 74ms -> 178ms)\n",
        "      for i in range(M):\n",
        "        new_rho_t = new_rho_t*self.rhos[i]\n",
        "      if new_rho_t <= 1e-323: #this is to avoid division by zero, might need to be tweaked\n",
        "        new_rho_t = 1e-323\n",
        "    #   print('new_rho_t ' + str(new_rho_t))\n",
        "\n",
        "      #compute Nhat_t(s)\n",
        "      Nhat_t = rho_t*(1-new_rho_t)/(new_rho_t-rho_t)\n",
        "    #   print('Nhat_t: ',   Nhat_t)\n",
        "      if Nhat_t <= 1e-323: #this is to avoid division by zero again, might need to be tweaked\n",
        "        Nhat_t = torch.tensor([1e-323]).to(device)\n",
        "\n",
        "      #compute R(s,a) (empirical reward)\n",
        "      explorationBonus = beta/torch.sqrt(Nhat_t)\n",
        "      if torch.isnan(explorationBonus) or explorationBonus >= 1e3:\n",
        "        explorationBonus = 1e3\n",
        "\n",
        "      reward = reward + explorationBonus\n",
        "    #   print('reward: ',reward)\n",
        "\n",
        "    #   print('state value: ' + str(evaluator.value(phi)))\n",
        "      #pass phi(s) and reward to RL algo to update theta_t\n",
        "      target = reward + self.gamma * evaluator.value(phi)          ############# use our own value function ??? modified it, may work as intented\n",
        "      # THIS IS A BOTTLENECK (tested in CPU mode: 190ms -> 207ms)\n",
        "      evaluator.learn(old_phi, target)\n",
        "\n",
        "      if done:\n",
        "        #break\n",
        "        env.reset()\n",
        "        action = 1\n",
        "        old_phi = env._observe()\n",
        "        print('episode ended on step ', t, 'starting a new one')\n",
        "      else:\n",
        "        old_phi = phi\n",
        "        action = next_action\n",
        "      t += 1\n",
        "      continue\n",
        "\n",
        "\n",
        "    return evaluator.weights\n",
        "\n",
        "from ale_py.roms import Breakout\n",
        "import timeit\n",
        "env = EnvALE(Breakout, feature_type='Basic')\n",
        "print(env.action_space)\n",
        "alpha = 0.5\n",
        "lam = 0.9\n",
        "#we can upload previous weights as as tensor, or initialize at 0\n",
        "previous_weights = 0\n",
        "obs = torch.randint(0,2,(28672,), dtype=bool).to(device)\n",
        "t_end = 10\n",
        "\n",
        "evaluator = Sarsa(alpha, lam, replacing_trace, 28672, previous_weights)\n",
        "agent = BaseAgent()\n",
        "env.reset(do_record=False)\n",
        "start_time = timeit.default_timer()\n",
        "weights = agent.PHI_EB(evaluator, env, beta=0.05, t_end=t_end)\n",
        "print(f'{1000*(timeit.default_timer()-start_time)/t_end}ms per timestep')"
      ],
      "metadata": {
        "id": "6OmpMlK6HrOl",
        "outputId": "1ace60da-2ccb-41c6-d962-7376b1c319a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n",
            "starting iterations\n",
            "rhos: tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
            "206.69250179998926ms per timestep\n"
          ]
        }
      ]
    }
  ]
}