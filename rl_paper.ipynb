{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rl_paper.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tinynja/Sarsa-phi-EB/blob/main/rl_paper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ztbgbOZ-uJ",
        "outputId": "9c63e09b-b446-49e8-c7a4-28e3fdcacbe4"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/Tinynja/Sarsa-phi-EB/master/notebooks/ALE_Framework_Tests.ipynb\n",
        "\n",
        "%run ALE_Framework_Tests.ipynb"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Sarsa-phi-EB'...\n",
            "remote: Enumerating objects: 316, done.\u001b[K\n",
            "remote: Counting objects: 100% (316/316), done.\u001b[K\n",
            "remote: Compressing objects: 100% (265/265), done.\u001b[K\n",
            "remote: Total 316 (delta 100), reused 204 (delta 39), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (316/316), 745.14 KiB | 4.19 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            ms_pacman    ROMS/Ms. Pac-Man (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               amidar         ROMS/Amidar (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        haunted_house ROMS/Haunted House (Mystery Mansion, Graves' Manor, Nightmare Manor) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               gopher ROMS/Gopher (Gopher Attack) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            centipede      ROMS/Centipede (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           beam_rider      ROMS/Beamrider (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         demon_attack ROMS/Demon Attack (Death from Above) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          road_runner    ROMS/Road Runner (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              berzerk        ROMS/Berzerk (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           mario_bros    ROMS/Mario Bros. (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                   et ROMS/E.T. - The Extra-Terrestrial (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           time_pilot     ROMS/Time Pilot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       journey_escape ROMS/Journey Escape (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 hero       ROMS/H.E.R.O. (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              koolaid ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             robotank ROMS/Robot Tank (Robotank) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Fun with Numbers (AKA Basic Math) (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            up_n_down     ROMS/Up 'n Down (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                mr_do        ROMS/Mr. Do! (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         flag_capture ROMS/Flag Capture - Capture (Capture the Flag) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            videocube ROMS/Atari Video Cube (Atari Cube, Video Cube) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             defender       ROMS/Defender (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             galaxian       ROMS/Galaxian (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              phoenix        ROMS/Phoenix (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            blackjack ROMS/Blackjack - Black Jack (Gambling) (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          laser_gates ROMS/Laser Gates (AKA Innerspace) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            asteroids      ROMS/Asteroids (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            space_war ROMS/Space War - Space Star (32 in 1) (1988).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          battle_zone     ROMS/Battlezone (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            jamesbond ROMS/James Bond 007 (James Bond Agent 007) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                alien          ROMS/Alien (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Pinball (AKA Video Pinball) (Zellers).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            riverraid     ROMS/River Raid (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              hangman ROMS/Hangman - Spelling (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m    montezuma_revenge ROMS/Montezuma's Revenge - Featuring Panama Joe (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 klax           ROMS/Klax (1991).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              pitfall ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              solaris ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              frogger        ROMS/Frogger (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball ROMS/Video Pinball - Arcade Pinball (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              freeway        ROMS/Freeway (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             entombed ROMS/Entombed (Maze Chase, Pharaoh's Tomb, Zombie) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             gravitar       ROMS/Gravitar (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              assault ROMS/Assault (AKA Sky Alien) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             kangaroo       ROMS/Kangaroo (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m     human_cannonball ROMS/Human Cannonball - Cannon Man (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert        ROMS/Q. Bert (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                krull          ROMS/Krull (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      chopper_command ROMS/Chopper Command (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            frostbite      ROMS/Frostbite (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               enduro         ROMS/Enduro (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pacman        ROMS/Pac-Man (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          double_dunk ROMS/Double Dunk (Super Basketball) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               tennis ROMS/Tennis - Le Tennis (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          word_zapper ROMS/Word Zapper (Word Grabber) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           earthworld ROMS/SwordQuest - EarthWorld (Adventure I, SwordQuest I - EarthWorld) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             breakout ROMS/Breakout - Breakaway IV (Paddle) (1978).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             crossbow       ROMS/Crossbow (1988).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       video_checkers ROMS/Video Checkers - Checkers - Atari Video Checkers (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      elevator_action ROMS/Elevator Action (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       space_invaders ROMS/Space Invaders (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                qbert         ROMS/Q-bert (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              othello        ROMS/Othello (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             air_raid ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             pitfall2 ROMS/Pitfall II - Lost Caverns (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           backgammon ROMS/Backgammon (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            king_kong      ROMS/King Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       tic_tac_toe_3d ROMS/3-D Tic-Tac-Toe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            atlantis2    ROMS/Atlantis II (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             surround ROMS/Surround - Chase (Blockade) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong    ROMS/Donkey Kong (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               pooyan         ROMS/Pooyan (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              venture        ROMS/Venture (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              turmoil        ROMS/Turmoil (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         darkchambers ROMS/Dark Chambers (Dungeon, Dungeon Masters) (1989).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           videochess ROMS/Video Chess (Computer Chess) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         sir_lancelot   ROMS/Sir Lancelot (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       kung_fu_master ROMS/Kung-Fu Master (1987).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         yars_revenge ROMS/Yars' Revenge (Time Freeze) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             superman       ROMS/Superman (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               kaboom ROMS/Kaboom! (Paddle) (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m      keystone_kapers ROMS/Keystone Kapers - Raueber und Gendarm (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          private_eye    ROMS/Private Eye (1984).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             atlantis ROMS/Atlantis (Lost City of Atlantis) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               skiing ROMS/Skiing - Le Ski (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        crazy_climber  ROMS/Crazy Climber (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           ice_hockey ROMS/Ice Hockey - Le Hockey Sur Glace (1981).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m          star_gunner     ROMS/Stargunner (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m                 pong ROMS/Video Olympics - Pong Sports (Paddle) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       name_this_game ROMS/Name This Game (Guardians of Treasure) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             carnival       ROMS/Carnival (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              bowling        ROMS/Bowling (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m              asterix ROMS/Asterix (AKA Taz) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            tutankham      ROMS/Tutankham (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        wizard_of_wor  ROMS/Wizard of Wor (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           basic_math ROMS/Basic Math - Math (Math Pack) (1977).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m           bank_heist ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m        fishing_derby  ROMS/Fishing Derby (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m            adventure      ROMS/Adventure (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               boxing ROMS/Boxing - La Boxe (1980).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m         lost_luggage ROMS/Lost Luggage (Airport Mayhem) (1982).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             seaquest       ROMS/Seaquest (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               zaxxon         ROMS/Zaxxon (1983).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m               casino ROMS/Casino - Poker Plus (Paddle) (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m       miniature_golf ROMS/Miniature Golf - Arcade Golf (1979).bin\n",
            "\u001b[92m[SUPPORTED]    \u001b[0m             trondead ROMS/TRON - Deadly Discs (TRON Joystick) (1983).bin\n",
            "\n",
            "\n",
            "\n",
            "Imported 110 / 110 ROMs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sarsa phi eb"
      ],
      "metadata": {
        "id": "T3DHkXGnN0pt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqiqcC4RVWq7"
      },
      "source": [
        "#######################################################################\n",
        "# Copyright (C)                                                       #\n",
        "# 2017-2018 Shangtong Zhang(zhangshangtong.cpp@gmail.com)             #\n",
        "# Permission given to modify the code as long as you keep this        #\n",
        "# declaration at the top                                              #\n",
        "#######################################################################\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from math import floor\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# all possible actions\n",
        "ACTIONS = range(4)\n",
        "\n",
        "# discount is always 1.0 in these experiments\n",
        "DISCOUNT = 0.99\n",
        "\n",
        "# use optimistic initial value, so it's ok to set epsilon to 0\n",
        "EPSILON = 0.01\n",
        "\n",
        "# maximum steps per episode\n",
        "STEP_LIMIT = 5000\n",
        "\n",
        "\n",
        "# get action at @position and @velocity based on epsilon greedy policy and @valueFunction  #########################    use our own get_action. modified it, may work as intended\n",
        "def get_action(observation, valueFunction):\n",
        "    if np.random.binomial(1, EPSILON) == 1:\n",
        "        return np.random.choice(ACTIONS)\n",
        "    values = []\n",
        "    for action in ACTIONS:\n",
        "        values.append(valueFunction.value(observation))  \n",
        "    return np.argmax(values)\n",
        "\n",
        "\n",
        "\n",
        "# replacing trace update rule\n",
        "# @trace: old trace (will be modified)\n",
        "# @activeTiles: current active tile indices\n",
        "# @lam: lambda\n",
        "# @return: new trace for convenience\n",
        "def replacing_trace(trace, activeTiles, lam):\n",
        "    active = (torch.arange(len(trace)).to(device)[None,...] == activeTiles.flatten()[...,None]).any(0)\n",
        "    trace[active] = 1\n",
        "    trace[~active] *= lam * DISCOUNT\n",
        "    return trace\n",
        "\n",
        "\n",
        "\n",
        "# wrapper class for Sarsa(lambda)\n",
        "class Sarsa:\n",
        "    # In this example I use the tiling software instead of implementing standard tiling by myself\n",
        "    # One important thing is that tiling is only a map from (state, action) to a series of indices\n",
        "    # It doesn't matter whether the indices have meaning, only if this map satisfy some property\n",
        "    # View the following webpage for more information\n",
        "    # http://incompleteideas.net/sutton/tiles/tiles3.html\n",
        "    # @maxSize: the maximum # of indices\n",
        "    #the hashing is a lfa?\n",
        "    def __init__(self, step_size, lam, trace_update=replacing_trace, max_size=28672):\n",
        "        self.max_size = max_size\n",
        "        self.trace_update = trace_update\n",
        "        self.lam = lam\n",
        "\n",
        "        # divide step size equally to each tiling\n",
        "        self.step_size = step_size/10\n",
        "\n",
        "        # weight for each tile\n",
        "        self.weights =torch.zeros(max_size).to(device) #max size is the number of features?\n",
        "\n",
        "        # trace for each tile\n",
        "        self.trace = torch.zeros(max_size).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    # estimate the value of given state and action\n",
        "    def value(self, observation):\n",
        "        active_tiles = torch.nonzero(observation)\n",
        "        return self.weights[active_tiles].sum()\n",
        "\n",
        "    # learn with given state, action and target\n",
        "    def learn(self, observation, target):\n",
        "        active_tiles = torch.nonzero(observation)\n",
        "        estimation = self.weights[active_tiles].sum()\n",
        "        delta = target - estimation\n",
        "        #print('estimation array: ' + str(self.weights[active_tiles]))\n",
        "        print('estimation: ' + str(self.weights[active_tiles].sum()))\n",
        "        if self.trace_update == replacing_trace:\n",
        "            self.trace_update(self.trace, active_tiles, self.lam)\n",
        "        else:\n",
        "            raise Exception('Unexpected Trace Type')\n",
        "        self.weights += self.step_size * delta * self.trace\n",
        "        print('delta: ' + str(delta))\n",
        "        print('weights: ' +  str(self.weights))\n",
        "\n",
        "\n",
        "# play Mountain Car for one episode based on given method @evaluator\n",
        "# @return: total steps in this episode\n",
        "def play(evaluator, env):\n",
        "\n",
        "    action = random.choice(ACTIONS)\n",
        "    steps = 0\n",
        "    while True:\n",
        "        next_observation, reward, done, info = env.step(action)\n",
        "        next_action = get_action(next_observation, evaluator)    #########################    use our own get_action  ??? modified it, may work as intented\n",
        "        steps += 1\n",
        "        target = reward + DISCOUNT * evaluator.value(next_observation)          ############# use our own value function ??? modified it, may work as intented\n",
        "        evaluator.learn(observation, target)\n",
        "        observation = next_observation\n",
        "        action = next_action\n",
        "        if done:\n",
        "            break\n",
        "        if steps >= STEP_LIMIT:\n",
        "            print('Step Limit Exceeded!')\n",
        "            break\n",
        "    return steps"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMeWJRRueo1t"
      },
      "source": [
        "class BaseAgent:\n",
        "  \"\"\" The base agent class function.\n",
        "  \"\"\"\n",
        "  def __init__(self, nb_features=28672):\n",
        "    #nothing for now\n",
        "    self.gamma = 1\n",
        "    self.features = nb_features\n",
        "    self.rhos = torch.ones(self.features).to(device) #stores the rho_i values\n",
        "\n",
        "\n",
        "  def takeAction(self, t):\n",
        "    phis = [[0,1,0],[0,1,0],[0,1,0],[1,0,1]]\n",
        "    return phis[t]\n",
        "\n",
        "\n",
        "  def updateRho_i(self, counts, t):\n",
        "    M = self.features\n",
        "    self.rhos = (counts+1.5)/(t+1)\n",
        "    return 0\n",
        "\n",
        "\n",
        "  def PHI_EB(self, evaluator, env, beta=0.05, t_end=200):\n",
        "    t = 0\n",
        "    M = self.features #number of features\n",
        "    counts = torch.zeros(M).to(device)\n",
        "    states = torch.zeros(t_end,M).to(device) #stores the previous phis for all timesteps\n",
        "\n",
        "    action = 1 #starting the game for the agent on the first game\n",
        "    old_phi = env._observe()\n",
        "    print('starting iterations')\n",
        "    print('rhos: ' + str(self.rhos))\n",
        "    while t < t_end:\n",
        "      #observe phi(s), reward\n",
        "      phi, reward, done, info = env.step(action)\n",
        "      print('--------------------------------------------------------------')\n",
        "      print('took action: ', env.action_space[action])\n",
        "      next_action = get_action(phi, evaluator)\n",
        "      print('phi: ' + str(phi))\n",
        "      \n",
        "      #compute rho_t(phi) (feature visit-density)\n",
        "      if t > 0:\n",
        "        counts = (phi==states[0:t]).sum(0)\n",
        "        print(counts)\n",
        "        self.rhos = (counts+0.5)/(t+1)\n",
        "        print('rhos: ' + str(self.rhos))\n",
        "        rho_t = torch.prod(self.rhos)\n",
        "      else:\n",
        "        rho_t = 0.5**M\n",
        "      print('rho_t ' + str(rho_t))\n",
        "      #update all rho_i with observed phi\n",
        "      states[t] = phi\n",
        "      self.updateRho_i(counts, t+1)\n",
        "      print('min rho_i_t: ' + str(min(self.rhos)))\n",
        "      \n",
        "      #compute rho_t+1(phi)\n",
        "      new_rho_t = 1\n",
        "      for i in range(M):\n",
        "        new_rho_t = new_rho_t*self.rhos[i]\n",
        "      if new_rho_t <= 1e-323: #this is to avoid division by zero, might need to be tweaked\n",
        "        new_rho_t = 1e-323\n",
        "      print('new_rho_t ' + str(new_rho_t))\n",
        "\n",
        "      #compute Nhat_t(s)\n",
        "      Nhat_t = rho_t*(1-new_rho_t)/(new_rho_t-rho_t)\n",
        "      if Nhat_t <= 1e-323: #this is to avoid division by zero again, might need to be tweaked\n",
        "        Nhat_t = torch.tensor([1e-323]).to(device)\n",
        "\n",
        "      #compute R(s,a) (empirical reward)\n",
        "      explorationBonus = beta/torch.sqrt(Nhat_t)\n",
        "      if torch.isnan(explorationBonus) or explorationBonus >= 1e15:\n",
        "        explorationBonus = 1e15\n",
        "\n",
        "      reward = reward + explorationBonus\n",
        "      print('reward: ',reward)\n",
        "\n",
        "      print('state value: ' + str(evaluator.value(phi)))\n",
        "      #pass phi(s) and reward to RL algo to update theta_t\n",
        "      target = reward + self.gamma * evaluator.value(phi)          ############# use our own value function ??? modified it, may work as intented\n",
        "      evaluator.learn(old_phi, target)\n",
        "\n",
        "      if done:\n",
        "        #break\n",
        "        env.reset()\n",
        "        action = 1\n",
        "        old_phi = env.observe()\n",
        "        print('episode ended on step ', t, 'starting a new one')\n",
        "      else:\n",
        "        old_phi = phi\n",
        "        action = next_action\n",
        "\n",
        "      t += 1\n",
        "\n",
        "    return evaluator.weights\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6Wzc-9sLqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6968f914-18f3-4416-cc29-0ae07a621357"
      },
      "source": [
        "from ale_py.roms import Breakout\n",
        "env = EnvALE(Breakout, feature_type='Basic')\n",
        "print(env.action_space)\n",
        "alpha = 0.5\n",
        "lam = 0.9\n",
        "evaluator = Sarsa(alpha, lam, replacing_trace,28672)\n",
        "agent = BaseAgent()\n",
        "env.reset(do_record=False)\n",
        "weights = agent.PHI_EB(evaluator, env, beta=0.05, t_end=2000)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<Action.NOOP: 0>, <Action.FIRE: 1>, <Action.RIGHT: 3>, <Action.LEFT: 4>]\n",
            "starting iterations\n",
            "rhos: tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.FIRE\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "rho_t 0.0\n",
            "min rho_i_t: tensor(0.7500)\n",
            "new_rho_t tensor(2.8026e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
            "state value: tensor(0.)\n",
            "estimation: tensor(0.)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.0000e+13, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([1, 1, 1,  ..., 1, 1, 1])\n",
            "rhos: tensor([0.7500, 0.7500, 0.7500,  ..., 0.7500, 0.7500, 0.7500])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.5000)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.0000e+13, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1500e+16)\n",
            "estimation: tensor(1.1500e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([2, 2, 2,  ..., 2, 2, 2])\n",
            "rhos: tensor([0.8333, 0.8333, 0.8333,  ..., 0.8333, 0.8333, 0.8333])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.3750)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.3000e+16)\n",
            "estimation: tensor(2.3000e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([3, 3, 3,  ..., 3, 3, 3])\n",
            "rhos: tensor([0.8750, 0.8750, 0.8750,  ..., 0.8750, 0.8750, 0.8750])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.3000)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.4500e+16)\n",
            "estimation: tensor(3.4500e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([4, 4, 4,  ..., 4, 4, 4])\n",
            "rhos: tensor([0.9000, 0.9000, 0.9000,  ..., 0.9000, 0.9000, 0.9000])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.2500)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.6000e+16)\n",
            "estimation: tensor(4.6000e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([5, 5, 5,  ..., 5, 5, 5])\n",
            "rhos: tensor([0.9167, 0.9167, 0.9167,  ..., 0.9167, 0.9167, 0.9167])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.2143)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.7500e+16)\n",
            "estimation: tensor(5.7500e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([6, 6, 6,  ..., 6, 6, 6])\n",
            "rhos: tensor([0.9286, 0.9286, 0.9286,  ..., 0.9286, 0.9286, 0.9286])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1875)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.9000e+16)\n",
            "estimation: tensor(6.9000e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([7, 7, 7,  ..., 7, 7, 7])\n",
            "rhos: tensor([0.9375, 0.9375, 0.9375,  ..., 0.9375, 0.9375, 0.9375])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1667)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.0500e+16)\n",
            "estimation: tensor(8.0500e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([8, 8, 8,  ..., 8, 8, 8])\n",
            "rhos: tensor([0.9444, 0.9444, 0.9444,  ..., 0.9444, 0.9444, 0.9444])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1500)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.2000e+16)\n",
            "estimation: tensor(9.2000e+16)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([9, 9, 9,  ..., 9, 9, 9])\n",
            "rhos: tensor([0.9500, 0.9500, 0.9500,  ..., 0.9500, 0.9500, 0.9500])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1364)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0350e+17)\n",
            "estimation: tensor(1.0350e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([10, 10, 10,  ..., 10, 10, 10])\n",
            "rhos: tensor([0.9545, 0.9545, 0.9545,  ..., 0.9545, 0.9545, 0.9545])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1250)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1500e+17)\n",
            "estimation: tensor(1.1500e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([11, 11, 11,  ..., 11, 11, 11])\n",
            "rhos: tensor([0.9583, 0.9583, 0.9583,  ..., 0.9583, 0.9583, 0.9583])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1154)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2650e+17)\n",
            "estimation: tensor(1.2650e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([12, 12, 12,  ..., 12, 12, 12])\n",
            "rhos: tensor([0.9615, 0.9615, 0.9615,  ..., 0.9615, 0.9615, 0.9615])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1071)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3800e+17)\n",
            "estimation: tensor(1.3800e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([13, 13, 13,  ..., 13, 13, 13])\n",
            "rhos: tensor([0.9643, 0.9643, 0.9643,  ..., 0.9643, 0.9643, 0.9643])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.1000)\n",
            "new_rho_t 1e-323\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4950e+17)\n",
            "estimation: tensor(1.4950e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([7.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([14, 14, 14,  ..., 14, 14, 14])\n",
            "rhos: tensor([0.9667, 0.9667, 0.9667,  ..., 0.9667, 0.9667, 0.9667])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9062)\n",
            "new_rho_t tensor(7.0065e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([7.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.6100e+17)\n",
            "estimation: tensor(1.6100e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([7.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([15, 15, 15,  ..., 15, 15, 15])\n",
            "rhos: tensor([0.9688, 0.9688, 0.9688,  ..., 0.9688, 0.9688, 0.9688])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9118)\n",
            "new_rho_t tensor(7.0065e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([7.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.7250e+17)\n",
            "estimation: tensor(1.7250e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([8.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([16, 16, 16,  ..., 16, 16, 16])\n",
            "rhos: tensor([0.9706, 0.9706, 0.9706,  ..., 0.9706, 0.9706, 0.9706])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9167)\n",
            "new_rho_t tensor(8.4078e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([8.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.8400e+17)\n",
            "estimation: tensor(1.8400e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([8.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([17, 17, 17,  ..., 17, 17, 17])\n",
            "rhos: tensor([0.9722, 0.9722, 0.9722,  ..., 0.9722, 0.9722, 0.9722])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9211)\n",
            "new_rho_t tensor(8.4078e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([8.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.9550e+17)\n",
            "estimation: tensor(1.9550e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([9.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([18, 18, 18,  ..., 18, 18, 18])\n",
            "rhos: tensor([0.9737, 0.9737, 0.9737,  ..., 0.9737, 0.9737, 0.9737])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9250)\n",
            "new_rho_t tensor(8.4078e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([9.0000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.0700e+17)\n",
            "estimation: tensor(2.0700e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([9.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([19, 19, 19,  ..., 19, 19, 19])\n",
            "rhos: tensor([0.9750, 0.9750, 0.9750,  ..., 0.9750, 0.9750, 0.9750])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9286)\n",
            "new_rho_t tensor(8.4078e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([9.5000e+14, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.1850e+17)\n",
            "estimation: tensor(2.1850e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([20, 20, 20,  ..., 20, 20, 20])\n",
            "rhos: tensor([0.9762, 0.9762, 0.9762,  ..., 0.9762, 0.9762, 0.9762])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9318)\n",
            "new_rho_t tensor(9.8091e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.3000e+17)\n",
            "estimation: tensor(2.3000e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([21, 21, 21,  ..., 21, 21, 21])\n",
            "rhos: tensor([0.9773, 0.9773, 0.9773,  ..., 0.9773, 0.9773, 0.9773])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9348)\n",
            "new_rho_t tensor(9.8091e-45)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.4150e+17)\n",
            "estimation: tensor(2.4150e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([22, 22, 22,  ..., 22, 22, 22])\n",
            "rhos: tensor([0.9783, 0.9783, 0.9783,  ..., 0.9783, 0.9783, 0.9783])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9375)\n",
            "new_rho_t tensor(1.1210e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.5300e+17)\n",
            "estimation: tensor(2.5300e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([23, 23, 23,  ..., 23, 23, 23])\n",
            "rhos: tensor([0.9792, 0.9792, 0.9792,  ..., 0.9792, 0.9792, 0.9792])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9400)\n",
            "new_rho_t tensor(1.1210e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.6450e+17)\n",
            "estimation: tensor(2.6450e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([24, 24, 24,  ..., 24, 24, 24])\n",
            "rhos: tensor([0.9800, 0.9800, 0.9800,  ..., 0.9800, 0.9800, 0.9800])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9423)\n",
            "new_rho_t tensor(1.1210e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.7600e+17)\n",
            "estimation: tensor(2.7600e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([25, 25, 25,  ..., 25, 25, 25])\n",
            "rhos: tensor([0.9808, 0.9808, 0.9808,  ..., 0.9808, 0.9808, 0.9808])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9444)\n",
            "new_rho_t tensor(1.1210e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.8750e+17)\n",
            "estimation: tensor(2.8750e+17)\n",
            "delta: tensor(9.9999e+14)\n",
            "weights: tensor([1.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([26, 26, 26,  ..., 26, 26, 26])\n",
            "rhos: tensor([0.9815, 0.9815, 0.9815,  ..., 0.9815, 0.9815, 0.9815])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9464)\n",
            "new_rho_t tensor(1.2612e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(2.9900e+17)\n",
            "estimation: tensor(2.9900e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([27, 27, 27,  ..., 27, 27, 27])\n",
            "rhos: tensor([0.9821, 0.9821, 0.9821,  ..., 0.9821, 0.9821, 0.9821])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9483)\n",
            "new_rho_t tensor(1.2612e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.1050e+17)\n",
            "estimation: tensor(3.1050e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([28, 28, 28,  ..., 28, 28, 28])\n",
            "rhos: tensor([0.9828, 0.9828, 0.9828,  ..., 0.9828, 0.9828, 0.9828])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9500)\n",
            "new_rho_t tensor(1.2612e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.2200e+17)\n",
            "estimation: tensor(3.2200e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([29, 29, 29,  ..., 29, 29, 29])\n",
            "rhos: tensor([0.9833, 0.9833, 0.9833,  ..., 0.9833, 0.9833, 0.9833])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9516)\n",
            "new_rho_t tensor(1.4013e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.3350e+17)\n",
            "estimation: tensor(3.3350e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([30, 30, 30,  ..., 30, 30, 30])\n",
            "rhos: tensor([0.9839, 0.9839, 0.9839,  ..., 0.9839, 0.9839, 0.9839])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9531)\n",
            "new_rho_t tensor(1.4013e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.4500e+17)\n",
            "estimation: tensor(3.4500e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([31, 31, 31,  ..., 31, 31, 31])\n",
            "rhos: tensor([0.9844, 0.9844, 0.9844,  ..., 0.9844, 0.9844, 0.9844])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9545)\n",
            "new_rho_t tensor(1.4013e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.5650e+17)\n",
            "estimation: tensor(3.5650e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([32, 32, 32,  ..., 32, 32, 32])\n",
            "rhos: tensor([0.9848, 0.9848, 0.9848,  ..., 0.9848, 0.9848, 0.9848])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9559)\n",
            "new_rho_t tensor(1.5414e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.6800e+17)\n",
            "estimation: tensor(3.6800e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([33, 33, 33,  ..., 33, 33, 33])\n",
            "rhos: tensor([0.9853, 0.9853, 0.9853,  ..., 0.9853, 0.9853, 0.9853])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9571)\n",
            "new_rho_t tensor(1.5414e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.7950e+17)\n",
            "estimation: tensor(3.7950e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([34, 34, 34,  ..., 34, 34, 34])\n",
            "rhos: tensor([0.9857, 0.9857, 0.9857,  ..., 0.9857, 0.9857, 0.9857])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9583)\n",
            "new_rho_t tensor(1.5414e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(3.9100e+17)\n",
            "estimation: tensor(3.9100e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([35, 35, 35,  ..., 35, 35, 35])\n",
            "rhos: tensor([0.9861, 0.9861, 0.9861,  ..., 0.9861, 0.9861, 0.9861])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9595)\n",
            "new_rho_t tensor(1.6816e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.0250e+17)\n",
            "estimation: tensor(4.0250e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([36, 36, 36,  ..., 36, 36, 36])\n",
            "rhos: tensor([0.9865, 0.9865, 0.9865,  ..., 0.9865, 0.9865, 0.9865])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9605)\n",
            "new_rho_t tensor(1.6816e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.1400e+17)\n",
            "estimation: tensor(4.1400e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([37, 37, 37,  ..., 37, 37, 37])\n",
            "rhos: tensor([0.9868, 0.9868, 0.9868,  ..., 0.9868, 0.9868, 0.9868])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9615)\n",
            "new_rho_t tensor(1.6816e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.2550e+17)\n",
            "estimation: tensor(4.2550e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([38, 38, 38,  ..., 38, 38, 38])\n",
            "rhos: tensor([0.9872, 0.9872, 0.9872,  ..., 0.9872, 0.9872, 0.9872])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9625)\n",
            "new_rho_t tensor(1.8217e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.3700e+17)\n",
            "estimation: tensor(4.3700e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([1.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([39, 39, 39,  ..., 39, 39, 39])\n",
            "rhos: tensor([0.9875, 0.9875, 0.9875,  ..., 0.9875, 0.9875, 0.9875])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9634)\n",
            "new_rho_t tensor(1.8217e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([1.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.4850e+17)\n",
            "estimation: tensor(4.4850e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([40, 40, 40,  ..., 40, 40, 40])\n",
            "rhos: tensor([0.9878, 0.9878, 0.9878,  ..., 0.9878, 0.9878, 0.9878])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9643)\n",
            "new_rho_t tensor(1.9618e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.6000e+17)\n",
            "estimation: tensor(4.6000e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([41, 41, 41,  ..., 41, 41, 41])\n",
            "rhos: tensor([0.9881, 0.9881, 0.9881,  ..., 0.9881, 0.9881, 0.9881])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9651)\n",
            "new_rho_t tensor(1.9618e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.7150e+17)\n",
            "estimation: tensor(4.7150e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([42, 42, 42,  ..., 42, 42, 42])\n",
            "rhos: tensor([0.9884, 0.9884, 0.9884,  ..., 0.9884, 0.9884, 0.9884])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9659)\n",
            "new_rho_t tensor(1.9618e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.8300e+17)\n",
            "estimation: tensor(4.8300e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([43, 43, 43,  ..., 43, 43, 43])\n",
            "rhos: tensor([0.9886, 0.9886, 0.9886,  ..., 0.9886, 0.9886, 0.9886])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9667)\n",
            "new_rho_t tensor(1.9618e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(4.9450e+17)\n",
            "estimation: tensor(4.9450e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([44, 44, 44,  ..., 44, 44, 44])\n",
            "rhos: tensor([0.9889, 0.9889, 0.9889,  ..., 0.9889, 0.9889, 0.9889])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9674)\n",
            "new_rho_t tensor(2.1019e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.0600e+17)\n",
            "estimation: tensor(5.0600e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([45, 45, 45,  ..., 45, 45, 45])\n",
            "rhos: tensor([0.9891, 0.9891, 0.9891,  ..., 0.9891, 0.9891, 0.9891])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9681)\n",
            "new_rho_t tensor(2.1019e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.1750e+17)\n",
            "estimation: tensor(5.1750e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([46, 46, 46,  ..., 46, 46, 46])\n",
            "rhos: tensor([0.9894, 0.9894, 0.9894,  ..., 0.9894, 0.9894, 0.9894])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9688)\n",
            "new_rho_t tensor(2.2421e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.2900e+17)\n",
            "estimation: tensor(5.2900e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([47, 47, 47,  ..., 47, 47, 47])\n",
            "rhos: tensor([0.9896, 0.9896, 0.9896,  ..., 0.9896, 0.9896, 0.9896])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9694)\n",
            "new_rho_t tensor(2.2421e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.4050e+17)\n",
            "estimation: tensor(5.4050e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([48, 48, 48,  ..., 48, 48, 48])\n",
            "rhos: tensor([0.9898, 0.9898, 0.9898,  ..., 0.9898, 0.9898, 0.9898])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9700)\n",
            "new_rho_t tensor(2.2421e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.5200e+17)\n",
            "estimation: tensor(5.5200e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([49, 49, 49,  ..., 49, 49, 49])\n",
            "rhos: tensor([0.9900, 0.9900, 0.9900,  ..., 0.9900, 0.9900, 0.9900])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9706)\n",
            "new_rho_t tensor(2.2421e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.6350e+17)\n",
            "estimation: tensor(5.6350e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([50, 50, 50,  ..., 50, 50, 50])\n",
            "rhos: tensor([0.9902, 0.9902, 0.9902,  ..., 0.9902, 0.9902, 0.9902])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9712)\n",
            "new_rho_t tensor(2.3822e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.7500e+17)\n",
            "estimation: tensor(5.7500e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([51, 51, 51,  ..., 51, 51, 51])\n",
            "rhos: tensor([0.9904, 0.9904, 0.9904,  ..., 0.9904, 0.9904, 0.9904])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9717)\n",
            "new_rho_t tensor(2.3822e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.8650e+17)\n",
            "estimation: tensor(5.8650e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([52, 52, 52,  ..., 52, 52, 52])\n",
            "rhos: tensor([0.9906, 0.9906, 0.9906,  ..., 0.9906, 0.9906, 0.9906])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9722)\n",
            "new_rho_t tensor(2.3822e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(5.9800e+17)\n",
            "estimation: tensor(5.9800e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([53, 53, 53,  ..., 53, 53, 53])\n",
            "rhos: tensor([0.9907, 0.9907, 0.9907,  ..., 0.9907, 0.9907, 0.9907])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9727)\n",
            "new_rho_t tensor(2.5223e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.0950e+17)\n",
            "estimation: tensor(6.0950e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([54, 54, 54,  ..., 54, 54, 54])\n",
            "rhos: tensor([0.9909, 0.9909, 0.9909,  ..., 0.9909, 0.9909, 0.9909])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9732)\n",
            "new_rho_t tensor(2.5223e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.2100e+17)\n",
            "estimation: tensor(6.2100e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([55, 55, 55,  ..., 55, 55, 55])\n",
            "rhos: tensor([0.9911, 0.9911, 0.9911,  ..., 0.9911, 0.9911, 0.9911])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9737)\n",
            "new_rho_t tensor(2.5223e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.3250e+17)\n",
            "estimation: tensor(6.3250e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([56, 56, 56,  ..., 56, 56, 56])\n",
            "rhos: tensor([0.9912, 0.9912, 0.9912,  ..., 0.9912, 0.9912, 0.9912])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9741)\n",
            "new_rho_t tensor(2.6625e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.4400e+17)\n",
            "estimation: tensor(6.4400e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([57, 57, 57,  ..., 57, 57, 57])\n",
            "rhos: tensor([0.9914, 0.9914, 0.9914,  ..., 0.9914, 0.9914, 0.9914])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9746)\n",
            "new_rho_t tensor(2.6625e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.5550e+17)\n",
            "estimation: tensor(6.5550e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([58, 58, 58,  ..., 58, 58, 58])\n",
            "rhos: tensor([0.9915, 0.9915, 0.9915,  ..., 0.9915, 0.9915, 0.9915])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9750)\n",
            "new_rho_t tensor(2.8026e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.6700e+17)\n",
            "estimation: tensor(6.6700e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([2.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([59, 59, 59,  ..., 59, 59, 59])\n",
            "rhos: tensor([0.9917, 0.9917, 0.9917,  ..., 0.9917, 0.9917, 0.9917])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9754)\n",
            "new_rho_t tensor(2.8026e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([2.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.7850e+17)\n",
            "estimation: tensor(6.7850e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([60, 60, 60,  ..., 60, 60, 60])\n",
            "rhos: tensor([0.9918, 0.9918, 0.9918,  ..., 0.9918, 0.9918, 0.9918])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9758)\n",
            "new_rho_t tensor(2.8026e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(6.9000e+17)\n",
            "estimation: tensor(6.9000e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([61, 61, 61,  ..., 61, 61, 61])\n",
            "rhos: tensor([0.9919, 0.9919, 0.9919,  ..., 0.9919, 0.9919, 0.9919])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9762)\n",
            "new_rho_t tensor(2.8026e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.0150e+17)\n",
            "estimation: tensor(7.0150e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([62, 62, 62,  ..., 62, 62, 62])\n",
            "rhos: tensor([0.9921, 0.9921, 0.9921,  ..., 0.9921, 0.9921, 0.9921])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9766)\n",
            "new_rho_t tensor(2.9427e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.1300e+17)\n",
            "estimation: tensor(7.1300e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([63, 63, 63,  ..., 63, 63, 63])\n",
            "rhos: tensor([0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9769)\n",
            "new_rho_t tensor(2.9427e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.2450e+17)\n",
            "estimation: tensor(7.2450e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([64, 64, 64,  ..., 64, 64, 64])\n",
            "rhos: tensor([0.9923, 0.9923, 0.9923,  ..., 0.9923, 0.9923, 0.9923])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9773)\n",
            "new_rho_t tensor(3.0829e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.3600e+17)\n",
            "estimation: tensor(7.3600e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([65, 65, 65,  ..., 65, 65, 65])\n",
            "rhos: tensor([0.9924, 0.9924, 0.9924,  ..., 0.9924, 0.9924, 0.9924])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9776)\n",
            "new_rho_t tensor(3.0829e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.4750e+17)\n",
            "estimation: tensor(7.4750e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([66, 66, 66,  ..., 66, 66, 66])\n",
            "rhos: tensor([0.9925, 0.9925, 0.9925,  ..., 0.9925, 0.9925, 0.9925])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9779)\n",
            "new_rho_t tensor(3.0829e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.5900e+17)\n",
            "estimation: tensor(7.5900e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([67, 67, 67,  ..., 67, 67, 67])\n",
            "rhos: tensor([0.9926, 0.9926, 0.9926,  ..., 0.9926, 0.9926, 0.9926])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9783)\n",
            "new_rho_t tensor(3.2230e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.7050e+17)\n",
            "estimation: tensor(7.7050e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([68, 68, 68,  ..., 68, 68, 68])\n",
            "rhos: tensor([0.9928, 0.9928, 0.9928,  ..., 0.9928, 0.9928, 0.9928])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9786)\n",
            "new_rho_t tensor(3.2230e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.8200e+17)\n",
            "estimation: tensor(7.8200e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([69, 69, 69,  ..., 69, 69, 69])\n",
            "rhos: tensor([0.9929, 0.9929, 0.9929,  ..., 0.9929, 0.9929, 0.9929])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9789)\n",
            "new_rho_t tensor(3.2230e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(7.9350e+17)\n",
            "estimation: tensor(7.9350e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([70, 70, 70,  ..., 70, 70, 70])\n",
            "rhos: tensor([0.9930, 0.9930, 0.9930,  ..., 0.9930, 0.9930, 0.9930])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9792)\n",
            "new_rho_t tensor(3.3631e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.0500e+17)\n",
            "estimation: tensor(8.0500e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([71, 71, 71,  ..., 71, 71, 71])\n",
            "rhos: tensor([0.9931, 0.9931, 0.9931,  ..., 0.9931, 0.9931, 0.9931])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9795)\n",
            "new_rho_t tensor(3.3631e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.1650e+17)\n",
            "estimation: tensor(8.1650e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([72, 72, 72,  ..., 72, 72, 72])\n",
            "rhos: tensor([0.9932, 0.9932, 0.9932,  ..., 0.9932, 0.9932, 0.9932])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9797)\n",
            "new_rho_t tensor(3.3631e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.2800e+17)\n",
            "estimation: tensor(8.2800e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([73, 73, 73,  ..., 73, 73, 73])\n",
            "rhos: tensor([0.9932, 0.9932, 0.9932,  ..., 0.9932, 0.9932, 0.9932])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9800)\n",
            "new_rho_t tensor(3.5032e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.3950e+17)\n",
            "estimation: tensor(8.3950e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([74, 74, 74,  ..., 74, 74, 74])\n",
            "rhos: tensor([0.9933, 0.9933, 0.9933,  ..., 0.9933, 0.9933, 0.9933])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9803)\n",
            "new_rho_t tensor(3.5032e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.5100e+17)\n",
            "estimation: tensor(8.5100e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([75, 75, 75,  ..., 75, 75, 75])\n",
            "rhos: tensor([0.9934, 0.9934, 0.9934,  ..., 0.9934, 0.9934, 0.9934])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9805)\n",
            "new_rho_t tensor(3.5032e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.6250e+17)\n",
            "estimation: tensor(8.6250e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([76, 76, 76,  ..., 76, 76, 76])\n",
            "rhos: tensor([0.9935, 0.9935, 0.9935,  ..., 0.9935, 0.9935, 0.9935])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9808)\n",
            "new_rho_t tensor(3.5032e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.7400e+17)\n",
            "estimation: tensor(8.7400e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([77, 77, 77,  ..., 77, 77, 77])\n",
            "rhos: tensor([0.9936, 0.9936, 0.9936,  ..., 0.9936, 0.9936, 0.9936])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9810)\n",
            "new_rho_t tensor(3.6434e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.8550e+17)\n",
            "estimation: tensor(8.8550e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([78, 78, 78,  ..., 78, 78, 78])\n",
            "rhos: tensor([0.9937, 0.9937, 0.9937,  ..., 0.9937, 0.9937, 0.9937])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9812)\n",
            "new_rho_t tensor(3.6434e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(8.9700e+17)\n",
            "estimation: tensor(8.9700e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([3.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([79, 79, 79,  ..., 79, 79, 79])\n",
            "rhos: tensor([0.9937, 0.9937, 0.9937,  ..., 0.9937, 0.9937, 0.9937])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9815)\n",
            "new_rho_t tensor(3.7835e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([3.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.0850e+17)\n",
            "estimation: tensor(9.0850e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([80, 80, 80,  ..., 80, 80, 80])\n",
            "rhos: tensor([0.9938, 0.9938, 0.9938,  ..., 0.9938, 0.9938, 0.9938])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9817)\n",
            "new_rho_t tensor(3.7835e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.2000e+17)\n",
            "estimation: tensor(9.2000e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([81, 81, 81,  ..., 81, 81, 81])\n",
            "rhos: tensor([0.9939, 0.9939, 0.9939,  ..., 0.9939, 0.9939, 0.9939])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9819)\n",
            "new_rho_t tensor(3.7835e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.3150e+17)\n",
            "estimation: tensor(9.3150e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([82, 82, 82,  ..., 82, 82, 82])\n",
            "rhos: tensor([0.9940, 0.9940, 0.9940,  ..., 0.9940, 0.9940, 0.9940])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9821)\n",
            "new_rho_t tensor(3.9236e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.4301e+17)\n",
            "estimation: tensor(9.4301e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([83, 83, 83,  ..., 83, 83, 83])\n",
            "rhos: tensor([0.9940, 0.9940, 0.9940,  ..., 0.9940, 0.9940, 0.9940])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9824)\n",
            "new_rho_t tensor(3.9236e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.5451e+17)\n",
            "estimation: tensor(9.5451e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([84, 84, 84,  ..., 84, 84, 84])\n",
            "rhos: tensor([0.9941, 0.9941, 0.9941,  ..., 0.9941, 0.9941, 0.9941])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9826)\n",
            "new_rho_t tensor(4.0638e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.6601e+17)\n",
            "estimation: tensor(9.6601e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([85, 85, 85,  ..., 85, 85, 85])\n",
            "rhos: tensor([0.9942, 0.9942, 0.9942,  ..., 0.9942, 0.9942, 0.9942])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9828)\n",
            "new_rho_t tensor(4.2039e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.7751e+17)\n",
            "estimation: tensor(9.7751e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([86, 86, 86,  ..., 86, 86, 86])\n",
            "rhos: tensor([0.9943, 0.9943, 0.9943,  ..., 0.9943, 0.9943, 0.9943])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9830)\n",
            "new_rho_t tensor(4.6243e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(9.8901e+17)\n",
            "estimation: tensor(9.8901e+17)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([87, 87, 87,  ..., 87, 87, 87])\n",
            "rhos: tensor([0.9943, 0.9943, 0.9943,  ..., 0.9943, 0.9943, 0.9943])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9831)\n",
            "new_rho_t tensor(4.9045e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0005e+18)\n",
            "estimation: tensor(1.0005e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([88, 88, 88,  ..., 88, 88, 88])\n",
            "rhos: tensor([0.9944, 0.9944, 0.9944,  ..., 0.9944, 0.9944, 0.9944])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9833)\n",
            "new_rho_t tensor(5.0447e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0120e+18)\n",
            "estimation: tensor(1.0120e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.LEFT\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([89, 89, 89,  ..., 89, 89, 89])\n",
            "rhos: tensor([0.9944, 0.9944, 0.9944,  ..., 0.9944, 0.9944, 0.9944])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9835)\n",
            "new_rho_t tensor(5.3249e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0235e+18)\n",
            "estimation: tensor(1.0235e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([90, 90, 90,  ..., 90, 90, 90])\n",
            "rhos: tensor([0.9945, 0.9945, 0.9945,  ..., 0.9945, 0.9945, 0.9945])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9837)\n",
            "new_rho_t tensor(5.6052e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0350e+18)\n",
            "estimation: tensor(1.0350e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([91, 91, 91,  ..., 91, 91, 91])\n",
            "rhos: tensor([0.9946, 0.9946, 0.9946,  ..., 0.9946, 0.9946, 0.9946])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9839)\n",
            "new_rho_t tensor(6.1657e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0465e+18)\n",
            "estimation: tensor(1.0465e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([92, 92, 92,  ..., 92, 92, 92])\n",
            "rhos: tensor([0.9946, 0.9946, 0.9946,  ..., 0.9946, 0.9946, 0.9946])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9840)\n",
            "new_rho_t tensor(6.3058e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0580e+18)\n",
            "estimation: tensor(1.0580e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([93, 93, 93,  ..., 93, 93, 93])\n",
            "rhos: tensor([0.9947, 0.9947, 0.9947,  ..., 0.9947, 0.9947, 0.9947])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9842)\n",
            "new_rho_t tensor(6.7262e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0695e+18)\n",
            "estimation: tensor(1.0695e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([94, 94, 94,  ..., 94, 94, 94])\n",
            "rhos: tensor([0.9947, 0.9947, 0.9947,  ..., 0.9947, 0.9947, 0.9947])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9844)\n",
            "new_rho_t tensor(6.8664e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0810e+18)\n",
            "estimation: tensor(1.0810e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([95, 95, 95,  ..., 95, 95, 95])\n",
            "rhos: tensor([0.9948, 0.9948, 0.9948,  ..., 0.9948, 0.9948, 0.9948])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9845)\n",
            "new_rho_t tensor(7.4269e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.0925e+18)\n",
            "estimation: tensor(1.0925e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([96, 96, 96,  ..., 96, 96, 96])\n",
            "rhos: tensor([0.9948, 0.9948, 0.9948,  ..., 0.9948, 0.9948, 0.9948])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9847)\n",
            "new_rho_t tensor(7.5670e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1040e+18)\n",
            "estimation: tensor(1.1040e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([97, 97, 97,  ..., 97, 97, 97])\n",
            "rhos: tensor([0.9949, 0.9949, 0.9949,  ..., 0.9949, 0.9949, 0.9949])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9848)\n",
            "new_rho_t tensor(7.9874e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1155e+18)\n",
            "estimation: tensor(1.1155e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([98, 98, 98,  ..., 98, 98, 98])\n",
            "rhos: tensor([0.9949, 0.9949, 0.9949,  ..., 0.9949, 0.9949, 0.9949])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9850)\n",
            "new_rho_t tensor(8.2677e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1270e+18)\n",
            "estimation: tensor(1.1270e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([4.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([99, 99, 99,  ..., 99, 99, 99])\n",
            "rhos: tensor([0.9950, 0.9950, 0.9950,  ..., 0.9950, 0.9950, 0.9950])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9851)\n",
            "new_rho_t tensor(8.5479e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([4.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1385e+18)\n",
            "estimation: tensor(1.1385e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([100, 100, 100,  ..., 100, 100, 100])\n",
            "rhos: tensor([0.9950, 0.9950, 0.9950,  ..., 0.9950, 0.9950, 0.9950])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9853)\n",
            "new_rho_t tensor(8.6881e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1500e+18)\n",
            "estimation: tensor(1.1500e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([101, 101, 101,  ..., 101, 101, 101])\n",
            "rhos: tensor([0.9951, 0.9951, 0.9951,  ..., 0.9951, 0.9951, 0.9951])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9854)\n",
            "new_rho_t tensor(9.1084e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1615e+18)\n",
            "estimation: tensor(1.1615e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([102, 102, 102,  ..., 102, 102, 102])\n",
            "rhos: tensor([0.9951, 0.9951, 0.9951,  ..., 0.9951, 0.9951, 0.9951])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9856)\n",
            "new_rho_t tensor(9.3887e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1730e+18)\n",
            "estimation: tensor(1.1730e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([103, 103, 103,  ..., 103, 103, 103])\n",
            "rhos: tensor([0.9952, 0.9952, 0.9952,  ..., 0.9952, 0.9952, 0.9952])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9857)\n",
            "new_rho_t tensor(9.6690e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1845e+18)\n",
            "estimation: tensor(1.1845e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([104, 104, 104,  ..., 104, 104, 104])\n",
            "rhos: tensor([0.9952, 0.9952, 0.9952,  ..., 0.9952, 0.9952, 0.9952])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9858)\n",
            "new_rho_t tensor(9.9492e-44)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.1960e+18)\n",
            "estimation: tensor(1.1960e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([105, 105, 105,  ..., 105, 105, 105])\n",
            "rhos: tensor([0.9953, 0.9953, 0.9953,  ..., 0.9953, 0.9953, 0.9953])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9860)\n",
            "new_rho_t tensor(1.0370e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2075e+18)\n",
            "estimation: tensor(1.2075e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([106, 106, 106,  ..., 106, 106, 106])\n",
            "rhos: tensor([0.9953, 0.9953, 0.9953,  ..., 0.9953, 0.9953, 0.9953])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9861)\n",
            "new_rho_t tensor(1.0650e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2190e+18)\n",
            "estimation: tensor(1.2190e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([107, 107, 107,  ..., 107, 107, 107])\n",
            "rhos: tensor([0.9954, 0.9954, 0.9954,  ..., 0.9954, 0.9954, 0.9954])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9862)\n",
            "new_rho_t tensor(1.0930e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2305e+18)\n",
            "estimation: tensor(1.2305e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([108, 108, 108,  ..., 108, 108, 108])\n",
            "rhos: tensor([0.9954, 0.9954, 0.9954,  ..., 0.9954, 0.9954, 0.9954])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9864)\n",
            "new_rho_t tensor(1.1351e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2420e+18)\n",
            "estimation: tensor(1.2420e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([109, 109, 109,  ..., 109, 109, 109])\n",
            "rhos: tensor([0.9955, 0.9955, 0.9955,  ..., 0.9955, 0.9955, 0.9955])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9865)\n",
            "new_rho_t tensor(1.1771e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2535e+18)\n",
            "estimation: tensor(1.2535e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([110, 110, 110,  ..., 110, 110, 110])\n",
            "rhos: tensor([0.9955, 0.9955, 0.9955,  ..., 0.9955, 0.9955, 0.9955])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9866)\n",
            "new_rho_t tensor(1.1771e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2650e+18)\n",
            "estimation: tensor(1.2650e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([111, 111, 111,  ..., 111, 111, 111])\n",
            "rhos: tensor([0.9955, 0.9955, 0.9955,  ..., 0.9955, 0.9955, 0.9955])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9867)\n",
            "new_rho_t tensor(1.2331e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2765e+18)\n",
            "estimation: tensor(1.2765e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([112, 112, 112,  ..., 112, 112, 112])\n",
            "rhos: tensor([0.9956, 0.9956, 0.9956,  ..., 0.9956, 0.9956, 0.9956])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9868)\n",
            "new_rho_t tensor(1.2472e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2880e+18)\n",
            "estimation: tensor(1.2880e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([113, 113, 113,  ..., 113, 113, 113])\n",
            "rhos: tensor([0.9956, 0.9956, 0.9956,  ..., 0.9956, 0.9956, 0.9956])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9870)\n",
            "new_rho_t tensor(1.3032e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.2995e+18)\n",
            "estimation: tensor(1.2995e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([114, 114, 114,  ..., 114, 114, 114])\n",
            "rhos: tensor([0.9957, 0.9957, 0.9957,  ..., 0.9957, 0.9957, 0.9957])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9871)\n",
            "new_rho_t tensor(1.3032e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3110e+18)\n",
            "estimation: tensor(1.3110e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([115, 115, 115,  ..., 115, 115, 115])\n",
            "rhos: tensor([0.9957, 0.9957, 0.9957,  ..., 0.9957, 0.9957, 0.9957])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9872)\n",
            "new_rho_t tensor(1.3452e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3225e+18)\n",
            "estimation: tensor(1.3225e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([116, 116, 116,  ..., 116, 116, 116])\n",
            "rhos: tensor([0.9957, 0.9957, 0.9957,  ..., 0.9957, 0.9957, 0.9957])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9873)\n",
            "new_rho_t tensor(1.3733e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3340e+18)\n",
            "estimation: tensor(1.3340e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([117, 117, 117,  ..., 117, 117, 117])\n",
            "rhos: tensor([0.9958, 0.9958, 0.9958,  ..., 0.9958, 0.9958, 0.9958])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9874)\n",
            "new_rho_t tensor(1.4013e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3455e+18)\n",
            "estimation: tensor(1.3455e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([118, 118, 118,  ..., 118, 118, 118])\n",
            "rhos: tensor([0.9958, 0.9958, 0.9958,  ..., 0.9958, 0.9958, 0.9958])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9875)\n",
            "new_rho_t tensor(1.4433e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3570e+18)\n",
            "estimation: tensor(1.3570e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([5.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([119, 119, 119,  ..., 119, 119, 119])\n",
            "rhos: tensor([0.9958, 0.9958, 0.9958,  ..., 0.9958, 0.9958, 0.9958])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9876)\n",
            "new_rho_t tensor(1.4854e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([5.9500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3685e+18)\n",
            "estimation: tensor(1.3685e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([120, 120, 120,  ..., 120, 120, 120])\n",
            "rhos: tensor([0.9959, 0.9959, 0.9959,  ..., 0.9959, 0.9959, 0.9959])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9877)\n",
            "new_rho_t tensor(1.5134e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.0000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3800e+18)\n",
            "estimation: tensor(1.3800e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([121, 121, 121,  ..., 121, 121, 121])\n",
            "rhos: tensor([0.9959, 0.9959, 0.9959,  ..., 0.9959, 0.9959, 0.9959])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9878)\n",
            "new_rho_t tensor(1.5414e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.0500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.3915e+18)\n",
            "estimation: tensor(1.3915e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([122, 122, 122,  ..., 122, 122, 122])\n",
            "rhos: tensor([0.9959, 0.9959, 0.9959,  ..., 0.9959, 0.9959, 0.9959])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9879)\n",
            "new_rho_t tensor(1.5695e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.1000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4030e+18)\n",
            "estimation: tensor(1.4030e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([123, 123, 123,  ..., 123, 123, 123])\n",
            "rhos: tensor([0.9960, 0.9960, 0.9960,  ..., 0.9960, 0.9960, 0.9960])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9880)\n",
            "new_rho_t tensor(1.5835e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.1500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4145e+18)\n",
            "estimation: tensor(1.4145e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([124, 124, 124,  ..., 124, 124, 124])\n",
            "rhos: tensor([0.9960, 0.9960, 0.9960,  ..., 0.9960, 0.9960, 0.9960])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9881)\n",
            "new_rho_t tensor(1.6115e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.2000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4260e+18)\n",
            "estimation: tensor(1.4260e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([125, 125, 125,  ..., 125, 125, 125])\n",
            "rhos: tensor([0.9960, 0.9960, 0.9960,  ..., 0.9960, 0.9960, 0.9960])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9882)\n",
            "new_rho_t tensor(1.6535e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.2500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4375e+18)\n",
            "estimation: tensor(1.4375e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([126, 126, 126,  ..., 126, 126, 126])\n",
            "rhos: tensor([0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9883)\n",
            "new_rho_t tensor(1.6675e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.3000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4490e+18)\n",
            "estimation: tensor(1.4490e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([127, 127, 127,  ..., 127, 127, 127])\n",
            "rhos: tensor([0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9884)\n",
            "new_rho_t tensor(1.7096e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.3500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4605e+18)\n",
            "estimation: tensor(1.4605e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([128, 128, 128,  ..., 128, 128, 128])\n",
            "rhos: tensor([0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9885)\n",
            "new_rho_t tensor(1.7236e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.4000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4720e+18)\n",
            "estimation: tensor(1.4720e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([129, 129, 129,  ..., 129, 129, 129])\n",
            "rhos: tensor([0.9962, 0.9962, 0.9962,  ..., 0.9962, 0.9962, 0.9962])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9885)\n",
            "new_rho_t tensor(1.7656e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.4500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4835e+18)\n",
            "estimation: tensor(1.4835e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([130, 130, 130,  ..., 130, 130, 130])\n",
            "rhos: tensor([0.9962, 0.9962, 0.9962,  ..., 0.9962, 0.9962, 0.9962])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9886)\n",
            "new_rho_t tensor(1.8077e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.5000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.4950e+18)\n",
            "estimation: tensor(1.4950e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([131, 131, 131,  ..., 131, 131, 131])\n",
            "rhos: tensor([0.9962, 0.9962, 0.9962,  ..., 0.9962, 0.9962, 0.9962])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9887)\n",
            "new_rho_t tensor(1.8217e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.5500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5065e+18)\n",
            "estimation: tensor(1.5065e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([132, 132, 132,  ..., 132, 132, 132])\n",
            "rhos: tensor([0.9962, 0.9962, 0.9962,  ..., 0.9962, 0.9962, 0.9962])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9888)\n",
            "new_rho_t tensor(1.8357e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.6000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5180e+18)\n",
            "estimation: tensor(1.5180e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([133, 133, 133,  ..., 133, 133, 133])\n",
            "rhos: tensor([0.9963, 0.9963, 0.9963,  ..., 0.9963, 0.9963, 0.9963])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9889)\n",
            "new_rho_t tensor(1.8497e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.6500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5295e+18)\n",
            "estimation: tensor(1.5295e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([134, 134, 134,  ..., 134, 134, 134])\n",
            "rhos: tensor([0.9963, 0.9963, 0.9963,  ..., 0.9963, 0.9963, 0.9963])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9890)\n",
            "new_rho_t tensor(1.8777e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.7000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5410e+18)\n",
            "estimation: tensor(1.5410e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([135, 135, 135,  ..., 135, 135, 135])\n",
            "rhos: tensor([0.9963, 0.9963, 0.9963,  ..., 0.9963, 0.9963, 0.9963])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9891)\n",
            "new_rho_t tensor(1.9058e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.7500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5525e+18)\n",
            "estimation: tensor(1.5525e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([136, 136, 136,  ..., 136, 136, 136])\n",
            "rhos: tensor([0.9964, 0.9964, 0.9964,  ..., 0.9964, 0.9964, 0.9964])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9891)\n",
            "new_rho_t tensor(1.9338e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.8000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5640e+18)\n",
            "estimation: tensor(1.5640e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([137, 137, 137,  ..., 137, 137, 137])\n",
            "rhos: tensor([0.9964, 0.9964, 0.9964,  ..., 0.9964, 0.9964, 0.9964])\n",
            "rho_t tensor(0.)\n",
            "min rho_i_t: tensor(0.9892)\n",
            "new_rho_t tensor(1.9338e-43)\n",
            "reward:  1000000000000000.0\n",
            "weights: tensor([6.8500e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5755e+18)\n",
            "estimation: tensor(1.5755e+18)\n",
            "delta: tensor(1.0000e+15)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([138, 138, 138,  ..., 138, 138, 138])\n",
            "rhos: tensor([0.9964, 0.9964, 0.9964,  ..., 0.9964, 0.9964, 0.9964])\n",
            "rho_t tensor(1.4013e-45)\n",
            "min rho_i_t: tensor(0.9893)\n",
            "new_rho_t tensor(1.9478e-43)\n",
            "reward:  tensor(0.5874)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([139, 139, 139,  ..., 139, 139, 139])\n",
            "rhos: tensor([0.9964, 0.9964, 0.9964,  ..., 0.9964, 0.9964, 0.9964])\n",
            "rho_t tensor(1.4013e-45)\n",
            "min rho_i_t: tensor(0.9894)\n",
            "new_rho_t tensor(1.9618e-43)\n",
            "reward:  tensor(0.5895)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([140, 140, 140,  ..., 140, 140, 140])\n",
            "rhos: tensor([0.9965, 0.9965, 0.9965,  ..., 0.9965, 0.9965, 0.9965])\n",
            "rho_t tensor(4.2039e-45)\n",
            "min rho_i_t: tensor(0.9894)\n",
            "new_rho_t tensor(1.9758e-43)\n",
            "reward:  tensor(0.3391)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([141, 141, 141,  ..., 141, 141, 141])\n",
            "rhos: tensor([0.9965, 0.9965, 0.9965,  ..., 0.9965, 0.9965, 0.9965])\n",
            "rho_t tensor(8.4078e-45)\n",
            "min rho_i_t: tensor(0.9895)\n",
            "new_rho_t tensor(1.9898e-43)\n",
            "reward:  tensor(0.2380)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([142, 142, 142,  ..., 142, 142, 142])\n",
            "rhos: tensor([0.9965, 0.9965, 0.9965,  ..., 0.9965, 0.9965, 0.9965])\n",
            "rho_t tensor(1.6816e-44)\n",
            "min rho_i_t: tensor(0.9896)\n",
            "new_rho_t tensor(2.0179e-43)\n",
            "reward:  tensor(0.1658)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([143, 143, 143,  ..., 143, 143, 143])\n",
            "rhos: tensor([0.9965, 0.9965, 0.9965,  ..., 0.9965, 0.9965, 0.9965])\n",
            "rho_t tensor(3.3631e-44)\n",
            "min rho_i_t: tensor(0.9897)\n",
            "new_rho_t tensor(2.0319e-43)\n",
            "reward:  tensor(0.1123)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([144, 144, 144,  ..., 144, 144, 144])\n",
            "rhos: tensor([0.9966, 0.9966, 0.9966,  ..., 0.9966, 0.9966, 0.9966])\n",
            "rho_t tensor(6.5861e-44)\n",
            "min rho_i_t: tensor(0.9897)\n",
            "new_rho_t tensor(2.0459e-43)\n",
            "reward:  tensor(0.0726)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([145, 145, 145,  ..., 145, 145, 145])\n",
            "rhos: tensor([0.9966, 0.9966, 0.9966,  ..., 0.9966, 0.9966, 0.9966])\n",
            "rho_t tensor(1.3032e-43)\n",
            "min rho_i_t: tensor(0.9898)\n",
            "new_rho_t tensor(2.4803e-43)\n",
            "reward:  tensor(0.0475)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([146, 146, 146,  ..., 146, 146, 146])\n",
            "rhos: tensor([0.9966, 0.9966, 0.9966,  ..., 0.9966, 0.9966, 0.9966])\n",
            "rho_t tensor(2.5504e-43)\n",
            "min rho_i_t: tensor(0.9899)\n",
            "new_rho_t tensor(5.1988e-43)\n",
            "reward:  tensor(0.0510)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([147, 147, 147,  ..., 147, 147, 147])\n",
            "rhos: tensor([0.9966, 0.9966, 0.9966,  ..., 0.9966, 0.9966, 0.9966])\n",
            "rho_t tensor(4.9606e-43)\n",
            "min rho_i_t: tensor(0.9899)\n",
            "new_rho_t tensor(9.6549e-43)\n",
            "reward:  tensor(0.0486)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([148, 148, 148,  ..., 148, 148, 148])\n",
            "rhos: tensor([0.9966, 0.9966, 0.9966,  ..., 0.9966, 0.9966, 0.9966])\n",
            "rho_t tensor(9.5569e-43)\n",
            "min rho_i_t: tensor(0.9900)\n",
            "new_rho_t tensor(1.8245e-42)\n",
            "reward:  tensor(0.0477)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([149, 149, 149,  ..., 149, 149, 149])\n",
            "rhos: tensor([0.9967, 0.9967, 0.9967,  ..., 0.9967, 0.9967, 0.9967])\n",
            "rho_t tensor(1.8217e-42)\n",
            "min rho_i_t: tensor(0.9901)\n",
            "new_rho_t tensor(3.4500e-42)\n",
            "reward:  tensor(0.0473)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([150, 150, 150,  ..., 150, 150, 150])\n",
            "rhos: tensor([0.9967, 0.9967, 0.9967,  ..., 0.9967, 0.9967, 0.9967])\n",
            "rho_t tensor(3.4444e-42)\n",
            "min rho_i_t: tensor(0.9901)\n",
            "new_rho_t tensor(6.4726e-42)\n",
            "reward:  tensor(0.0469)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([151, 151, 151,  ..., 151, 151, 151])\n",
            "rhos: tensor([0.9967, 0.9967, 0.9967,  ..., 0.9967, 0.9967, 0.9967])\n",
            "rho_t tensor(6.4684e-42)\n",
            "min rho_i_t: tensor(0.9902)\n",
            "new_rho_t tensor(1.2020e-41)\n",
            "reward:  tensor(0.0463)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([152, 152, 152,  ..., 152, 152, 152])\n",
            "rhos: tensor([0.9967, 0.9967, 0.9967,  ..., 0.9967, 0.9967, 0.9967])\n",
            "rho_t tensor(1.2019e-41)\n",
            "min rho_i_t: tensor(0.9903)\n",
            "new_rho_t tensor(2.2220e-41)\n",
            "reward:  tensor(0.0461)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([153, 153, 153,  ..., 153, 153, 153])\n",
            "rhos: tensor([0.9968, 0.9968, 0.9968,  ..., 0.9968, 0.9968, 0.9968])\n",
            "rho_t tensor(2.2219e-41)\n",
            "min rho_i_t: tensor(0.9903)\n",
            "new_rho_t tensor(4.0661e-41)\n",
            "reward:  tensor(0.0456)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([154, 154, 154,  ..., 154, 154, 154])\n",
            "rhos: tensor([0.9968, 0.9968, 0.9968,  ..., 0.9968, 0.9968, 0.9968])\n",
            "rho_t tensor(4.0656e-41)\n",
            "min rho_i_t: tensor(0.9904)\n",
            "new_rho_t tensor(7.3885e-41)\n",
            "reward:  tensor(0.0452)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([155, 155, 155,  ..., 155, 155, 155])\n",
            "rhos: tensor([0.9968, 0.9968, 0.9968,  ..., 0.9968, 0.9968, 0.9968])\n",
            "rho_t tensor(7.3885e-41)\n",
            "min rho_i_t: tensor(0.9904)\n",
            "new_rho_t tensor(1.3311e-40)\n",
            "reward:  tensor(0.0448)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([156, 156, 156,  ..., 156, 156, 156])\n",
            "rhos: tensor([0.9968, 0.9968, 0.9968,  ..., 0.9968, 0.9968, 0.9968])\n",
            "rho_t tensor(1.3311e-40)\n",
            "min rho_i_t: tensor(0.9905)\n",
            "new_rho_t tensor(2.3856e-40)\n",
            "reward:  tensor(0.0445)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([157, 157, 157,  ..., 157, 157, 157])\n",
            "rhos: tensor([0.9968, 0.9968, 0.9968,  ..., 0.9968, 0.9968, 0.9968])\n",
            "rho_t tensor(2.3857e-40)\n",
            "min rho_i_t: tensor(0.9906)\n",
            "new_rho_t tensor(4.2316e-40)\n",
            "reward:  tensor(0.0440)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([158, 158, 158,  ..., 158, 158, 158])\n",
            "rhos: tensor([0.9969, 0.9969, 0.9969,  ..., 0.9969, 0.9969, 0.9969])\n",
            "rho_t tensor(4.2317e-40)\n",
            "min rho_i_t: tensor(0.9906)\n",
            "new_rho_t tensor(7.4675e-40)\n",
            "reward:  tensor(0.0437)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([159, 159, 159,  ..., 159, 159, 159])\n",
            "rhos: tensor([0.9969, 0.9969, 0.9969,  ..., 0.9969, 0.9969, 0.9969])\n",
            "rho_t tensor(7.4671e-40)\n",
            "min rho_i_t: tensor(0.9907)\n",
            "new_rho_t tensor(1.3087e-39)\n",
            "reward:  tensor(0.0434)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([160, 160, 160,  ..., 160, 160, 160])\n",
            "rhos: tensor([0.9969, 0.9969, 0.9969,  ..., 0.9969, 0.9969, 0.9969])\n",
            "rho_t tensor(1.3088e-39)\n",
            "min rho_i_t: tensor(0.9907)\n",
            "new_rho_t tensor(2.2739e-39)\n",
            "reward:  tensor(0.0429)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([161, 161, 161,  ..., 161, 161, 161])\n",
            "rhos: tensor([0.9969, 0.9969, 0.9969,  ..., 0.9969, 0.9969, 0.9969])\n",
            "rho_t tensor(2.2740e-39)\n",
            "min rho_i_t: tensor(0.9908)\n",
            "new_rho_t tensor(3.9306e-39)\n",
            "reward:  tensor(0.0427)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([162, 162, 162,  ..., 162, 162, 162])\n",
            "rhos: tensor([0.9969, 0.9969, 0.9969,  ..., 0.9969, 0.9969, 0.9969])\n",
            "rho_t tensor(3.9306e-39)\n",
            "min rho_i_t: tensor(0.9909)\n",
            "new_rho_t tensor(6.7476e-39)\n",
            "reward:  tensor(0.0423)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([163, 163, 163,  ..., 163, 163, 163])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(6.7477e-39)\n",
            "min rho_i_t: tensor(0.9909)\n",
            "new_rho_t tensor(1.1504e-38)\n",
            "reward:  tensor(0.0420)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([164, 164, 164,  ..., 164, 164, 164])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(1.1504e-38)\n",
            "min rho_i_t: tensor(0.9910)\n",
            "new_rho_t tensor(1.9478e-38)\n",
            "reward:  tensor(0.0416)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([165, 165, 165,  ..., 165, 165, 165])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(1.9477e-38)\n",
            "min rho_i_t: tensor(0.9910)\n",
            "new_rho_t tensor(3.2809e-38)\n",
            "reward:  tensor(0.0414)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([166, 166, 166,  ..., 166, 166, 166])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(3.2808e-38)\n",
            "min rho_i_t: tensor(0.9911)\n",
            "new_rho_t tensor(5.4885e-38)\n",
            "reward:  tensor(0.0410)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([167, 167, 167,  ..., 167, 167, 167])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(5.4883e-38)\n",
            "min rho_i_t: tensor(0.9911)\n",
            "new_rho_t tensor(9.1185e-38)\n",
            "reward:  tensor(0.0407)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([168, 168, 168,  ..., 168, 168, 168])\n",
            "rhos: tensor([0.9970, 0.9970, 0.9970,  ..., 0.9970, 0.9970, 0.9970])\n",
            "rho_t tensor(9.1182e-38)\n",
            "min rho_i_t: tensor(0.9912)\n",
            "new_rho_t tensor(1.5071e-37)\n",
            "reward:  tensor(0.0404)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([169, 169, 169,  ..., 169, 169, 169])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(1.5071e-37)\n",
            "min rho_i_t: tensor(0.9912)\n",
            "new_rho_t tensor(2.4781e-37)\n",
            "reward:  tensor(0.0401)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([170, 170, 170,  ..., 170, 170, 170])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(2.4781e-37)\n",
            "min rho_i_t: tensor(0.9913)\n",
            "new_rho_t tensor(4.0467e-37)\n",
            "reward:  tensor(0.0398)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([171, 171, 171,  ..., 171, 171, 171])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(4.0467e-37)\n",
            "min rho_i_t: tensor(0.9913)\n",
            "new_rho_t tensor(6.5741e-37)\n",
            "reward:  tensor(0.0395)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([172, 172, 172,  ..., 172, 172, 172])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(6.5740e-37)\n",
            "min rho_i_t: tensor(0.9914)\n",
            "new_rho_t tensor(1.0625e-36)\n",
            "reward:  tensor(0.0392)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([173, 173, 173,  ..., 173, 173, 173])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(1.0625e-36)\n",
            "min rho_i_t: tensor(0.9914)\n",
            "new_rho_t tensor(1.7054e-36)\n",
            "reward:  tensor(0.0389)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([174, 174, 174,  ..., 174, 174, 174])\n",
            "rhos: tensor([0.9971, 0.9971, 0.9971,  ..., 0.9971, 0.9971, 0.9971])\n",
            "rho_t tensor(1.7054e-36)\n",
            "min rho_i_t: tensor(0.9915)\n",
            "new_rho_t tensor(2.7232e-36)\n",
            "reward:  tensor(0.0386)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([175, 175, 175,  ..., 175, 175, 175])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(2.7233e-36)\n",
            "min rho_i_t: tensor(0.9915)\n",
            "new_rho_t tensor(4.3335e-36)\n",
            "reward:  tensor(0.0384)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([176, 176, 176,  ..., 176, 176, 176])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(4.3334e-36)\n",
            "min rho_i_t: tensor(0.9916)\n",
            "new_rho_t tensor(6.8486e-36)\n",
            "reward:  tensor(0.0381)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([177, 177, 177,  ..., 177, 177, 177])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(6.8485e-36)\n",
            "min rho_i_t: tensor(0.9916)\n",
            "new_rho_t tensor(1.0768e-35)\n",
            "reward:  tensor(0.0378)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([178, 178, 178,  ..., 178, 178, 178])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(1.0768e-35)\n",
            "min rho_i_t: tensor(0.9917)\n",
            "new_rho_t tensor(1.6871e-35)\n",
            "reward:  tensor(0.0376)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([179, 179, 179,  ..., 179, 179, 179])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(1.6871e-35)\n",
            "min rho_i_t: tensor(0.9917)\n",
            "new_rho_t tensor(2.6253e-35)\n",
            "reward:  tensor(0.0373)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([180, 180, 180,  ..., 180, 180, 180])\n",
            "rhos: tensor([0.9972, 0.9972, 0.9972,  ..., 0.9972, 0.9972, 0.9972])\n",
            "rho_t tensor(2.6252e-35)\n",
            "min rho_i_t: tensor(0.9918)\n",
            "new_rho_t tensor(4.0710e-35)\n",
            "reward:  tensor(0.0371)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([181, 181, 181,  ..., 181, 181, 181])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(4.0712e-35)\n",
            "min rho_i_t: tensor(0.9918)\n",
            "new_rho_t tensor(6.2804e-35)\n",
            "reward:  tensor(0.0368)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([182, 182, 182,  ..., 182, 182, 182])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(6.2805e-35)\n",
            "min rho_i_t: tensor(0.9918)\n",
            "new_rho_t tensor(9.6390e-35)\n",
            "reward:  tensor(0.0366)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([183, 183, 183,  ..., 183, 183, 183])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(9.6392e-35)\n",
            "min rho_i_t: tensor(0.9919)\n",
            "new_rho_t tensor(1.4718e-34)\n",
            "reward:  tensor(0.0363)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([184, 184, 184,  ..., 184, 184, 184])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(1.4717e-34)\n",
            "min rho_i_t: tensor(0.9919)\n",
            "new_rho_t tensor(2.2394e-34)\n",
            "reward:  tensor(0.0361)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([185, 185, 185,  ..., 185, 185, 185])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(2.2394e-34)\n",
            "min rho_i_t: tensor(0.9920)\n",
            "new_rho_t tensor(3.3899e-34)\n",
            "reward:  tensor(0.0358)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([186, 186, 186,  ..., 186, 186, 186])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(3.3900e-34)\n",
            "min rho_i_t: tensor(0.9920)\n",
            "new_rho_t tensor(5.1139e-34)\n",
            "reward:  tensor(0.0357)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([187, 187, 187,  ..., 187, 187, 187])\n",
            "rhos: tensor([0.9973, 0.9973, 0.9973,  ..., 0.9973, 0.9973, 0.9973])\n",
            "rho_t tensor(5.1138e-34)\n",
            "min rho_i_t: tensor(0.9921)\n",
            "new_rho_t tensor(7.6749e-34)\n",
            "reward:  tensor(0.0354)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([188, 188, 188,  ..., 188, 188, 188])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(7.6751e-34)\n",
            "min rho_i_t: tensor(0.9921)\n",
            "new_rho_t tensor(1.1459e-33)\n",
            "reward:  tensor(0.0351)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([189, 189, 189,  ..., 189, 189, 189])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(1.1459e-33)\n",
            "min rho_i_t: tensor(0.9921)\n",
            "new_rho_t tensor(1.7079e-33)\n",
            "reward:  tensor(0.0350)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([190, 190, 190,  ..., 190, 190, 190])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(1.7079e-33)\n",
            "min rho_i_t: tensor(0.9922)\n",
            "new_rho_t tensor(2.5282e-33)\n",
            "reward:  tensor(0.0346)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([191, 191, 191,  ..., 191, 191, 191])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(2.5281e-33)\n",
            "min rho_i_t: tensor(0.9922)\n",
            "new_rho_t tensor(3.7358e-33)\n",
            "reward:  tensor(0.0346)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([192, 192, 192,  ..., 192, 192, 192])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(3.7358e-33)\n",
            "min rho_i_t: tensor(0.9923)\n",
            "new_rho_t tensor(5.4919e-33)\n",
            "reward:  tensor(0.0343)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([193, 193, 193,  ..., 193, 193, 193])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(5.4922e-33)\n",
            "min rho_i_t: tensor(0.9923)\n",
            "new_rho_t tensor(8.0320e-33)\n",
            "reward:  tensor(0.0340)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([194, 194, 194,  ..., 194, 194, 194])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(8.0320e-33)\n",
            "min rho_i_t: tensor(0.9923)\n",
            "new_rho_t tensor(1.1727e-32)\n",
            "reward:  tensor(0.0339)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([195, 195, 195,  ..., 195, 195, 195])\n",
            "rhos: tensor([0.9974, 0.9974, 0.9974,  ..., 0.9974, 0.9974, 0.9974])\n",
            "rho_t tensor(1.1726e-32)\n",
            "min rho_i_t: tensor(0.9924)\n",
            "new_rho_t tensor(1.7032e-32)\n",
            "reward:  tensor(0.0336)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([196, 196, 196,  ..., 196, 196, 196])\n",
            "rhos: tensor([0.9975, 0.9975, 0.9975,  ..., 0.9975, 0.9975, 0.9975])\n",
            "rho_t tensor(1.7033e-32)\n",
            "min rho_i_t: tensor(0.9924)\n",
            "new_rho_t tensor(2.4654e-32)\n",
            "reward:  tensor(0.0334)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([197, 197, 197,  ..., 197, 197, 197])\n",
            "rhos: tensor([0.9975, 0.9975, 0.9975,  ..., 0.9975, 0.9975, 0.9975])\n",
            "rho_t tensor(2.4654e-32)\n",
            "min rho_i_t: tensor(0.9925)\n",
            "new_rho_t tensor(3.5563e-32)\n",
            "reward:  tensor(0.0333)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([198, 198, 198,  ..., 198, 198, 198])\n",
            "rhos: tensor([0.9975, 0.9975, 0.9975,  ..., 0.9975, 0.9975, 0.9975])\n",
            "rho_t tensor(3.5562e-32)\n",
            "min rho_i_t: tensor(0.9925)\n",
            "new_rho_t tensor(5.1122e-32)\n",
            "reward:  tensor(0.0331)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "--------------------------------------------------------------\n",
            "took action:  Action.NOOP\n",
            "phi: tensor([ True, False, False,  ..., False, False, False])\n",
            "tensor([199, 199, 199,  ..., 199, 199, 199])\n",
            "rhos: tensor([0.9975, 0.9975, 0.9975,  ..., 0.9975, 0.9975, 0.9975])\n",
            "rho_t tensor(5.1120e-32)\n",
            "min rho_i_t: tensor(0.9925)\n",
            "new_rho_t tensor(7.3237e-32)\n",
            "reward:  tensor(0.0329)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n",
            "state value: tensor(1.5870e+18)\n",
            "estimation: tensor(1.5870e+18)\n",
            "delta: tensor(0.)\n",
            "weights: tensor([6.9000e+15, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##optimisation tests\n",
        "# %%timeit\n",
        "# t = 1\n",
        "# M = 28000\n",
        "# counts = np.zeros(M)\n",
        "# rhos = np.ones(M)\n",
        "# for i in range(M): #M is the number of features of phi\n",
        "#   counts[i] += 1 #since we add phi to the seen states, all the counts are increased by one for t+1\n",
        "#   rhos[i] = (counts[i]+0.5)/(t+1)"
      ],
      "metadata": {
        "id": "7cKj8q7PjAT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #best one\n",
        "# %%timeit\n",
        "# t = 1\n",
        "# M = 28000\n",
        "# counts = np.zeros(M)\n",
        "# rhos = np.ones(M)\n",
        "# rhos = (counts+1.5)/(t+1)"
      ],
      "metadata": {
        "id": "wphENKYrjSD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #compute rho_t(phi) (feature visit-density)\n",
        "# %%timeit\n",
        "# t = 0\n",
        "# t_end = 30\n",
        "# M = 10000\n",
        "# phis = np.zeros((t_end,M))\n",
        "# counts = np.zeros(M)\n",
        "# states = np.zeros((t_end,M))\n",
        "# rhos = np.ones(M)\n",
        "# while t < t_end:\n",
        "#   phi = phis[t]\n",
        "#   if t > 0:\n",
        "#     rho_t = 1\n",
        "#     for i in range(M):\n",
        "#       counts[i] = 0\n",
        "#       for step in range(t):\n",
        "#         if phi[i] == states[step,i]:\n",
        "#           counts[i] += 1\n",
        "#       rhos[i] = (counts[i]+0.5)/(t+1)\n",
        "#       rho_t = rho_t*rhos[i]\n",
        "#   else:\n",
        "#     rho_t = 0.5**M\n",
        "\n",
        "#   #updating rho (other method)\n",
        "#   states[t] = phi\n",
        "#   counts += 1\n",
        "#   rhos = (counts+0.5)/(t+2)\n",
        "  \n",
        "#   t += 1"
      ],
      "metadata": {
        "id": "sqH7kGYDk2Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #compute rho_t(phi) (feature visit-density)\n",
        "# %%timeit\n",
        "# t = 0\n",
        "# t_end = 5000\n",
        "# M = 1000\n",
        "# phis = np.zeros((t_end,M))\n",
        "# counts = np.zeros(M)\n",
        "# states = np.zeros((t_end,M))\n",
        "# rhos = np.ones(M)\n",
        "# while t < t_end:\n",
        "#   phi = phis[t]\n",
        "#   if t > 0:\n",
        "#     rho_t = 1\n",
        "#     counts = np.zeros(M)\n",
        "#     for step in range(t):\n",
        "#       counts[np.where(phi == states[step])] += 1\n",
        "#     rhos = (counts+0.5)/(t+1)\n",
        "#     rho_t = np.prod(rhos)\n",
        "#   else:\n",
        "#     rho_t = 0.5**M\n",
        "\n",
        "#   #updating rho (other method)\n",
        "#   states[t] = phi\n",
        "#   counts += 1\n",
        "#   rhos = (counts+0.5)/(t+2)\n",
        "  \n",
        "#   t += 1"
      ],
      "metadata": {
        "id": "j82o_Tzqoi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #version 3 of optimisation\n",
        "# %%timeit\n",
        "# t = 0\n",
        "# t_end = 5000\n",
        "# M = 1000\n",
        "# #phis = [[0,1,0],[0,1,0],[0,1,0],[1,1,0]]\n",
        "# phis = np.zeros((t_end,M))\n",
        "# counts = np.zeros(M)\n",
        "# states = np.zeros((t_end,M))\n",
        "# rhos = np.ones(M)\n",
        "# while t < t_end:\n",
        "#   phi = phis[t]\n",
        "#   if t > 0:\n",
        "#     rho_t = 1\n",
        "#     counts = np.sum(np.where(phi == states[0:t],1,0),axis=0)\n",
        "#     rhos = (counts+0.5)/(t+1)\n",
        "#     rho_t = np.prod(rhos)\n",
        "#   else:\n",
        "#     rho_t = 0.5**M\n",
        "\n",
        "#   #updating rho (other method)\n",
        "#   states[t] = phi\n",
        "#   counts += 1\n",
        "#   rhos = (counts+0.5)/(t+2)\n",
        "  \n",
        "#   t += 1"
      ],
      "metadata": {
        "id": "1irC6C3no0gV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}